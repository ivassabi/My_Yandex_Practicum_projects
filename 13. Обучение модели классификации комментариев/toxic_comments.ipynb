{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njgLCwluck4G",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-и-предобработка\" data-toc-modified-id=\"Загрузка-и-предобработка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Загрузка и предобработка</a></span></li><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Мешок-слов\" data-toc-modified-id=\"Мешок-слов-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Мешок слов</a></span><ul class=\"toc-item\"><li><span><a href=\"#Downsample\" data-toc-modified-id=\"Downsample-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Downsample</a></span></li></ul></li><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>TF-IDF</a></span><ul class=\"toc-item\"><li><span><a href=\"#Downsample\" data-toc-modified-id=\"Downsample-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Downsample</a></span></li></ul></li></ul></li><li><span><a href=\"#Обучение-моделей\" data-toc-modified-id=\"Обучение-моделей-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>LogisticRegression</a></span><ul class=\"toc-item\"><li><span><a href=\"#CountVectorizer\" data-toc-modified-id=\"CountVectorizer-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>CountVectorizer</a></span></li><li><span><a href=\"#TfidfVectorizer\" data-toc-modified-id=\"TfidfVectorizer-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>TfidfVectorizer</a></span></li></ul></li><li><span><a href=\"#CatBoostClassifier\" data-toc-modified-id=\"CatBoostClassifier-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>CatBoostClassifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#CountVectorizer\" data-toc-modified-id=\"CountVectorizer-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>CountVectorizer</a></span></li><li><span><a href=\"#TfidfVectorizer\" data-toc-modified-id=\"TfidfVectorizer-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>TfidfVectorizer</a></span></li></ul></li><li><span><a href=\"#LightGBMClissifier\" data-toc-modified-id=\"LightGBMClissifier-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>LightGBMClissifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#CountVectorizer\" data-toc-modified-id=\"CountVectorizer-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>CountVectorizer</a></span></li><li><span><a href=\"#TfidfVectorizer\" data-toc-modified-id=\"TfidfVectorizer-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>TfidfVectorizer</a></span></li></ul></li></ul></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Тестирование</a></span><ul class=\"toc-item\"><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>CatBoost</a></span></li></ul></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wi_Or7mUYSgs"
   },
   "source": [
    "**Описание проекта**  \n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.  \n",
    "Постройте модель со значением метрики качества F1 не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lw0BuzfAYgS9"
   },
   "source": [
    "**Описание данных**\n",
    "\n",
    "`text` - содержит текст комментария  \n",
    "`toxic` - целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "mh4PpMsKCZmZ",
    "outputId": "451521eb-562a-4608-f6e2-191bf64ca129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\anaconda\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\anaconda\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\anaconda\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\anaconda\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    " !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "cCd5qCNMck4W",
    "outputId": "876a0edd-fb7a-4152-9c36-d6bd63a7d55a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\anaconda\\lib\\site-packages (1.0.6)\n",
      "Requirement already satisfied: graphviz in c:\\anaconda\\lib\\site-packages (from catboost) (0.20)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\anaconda\\lib\\site-packages (from catboost) (1.3.4)\n",
      "Requirement already satisfied: six in c:\\anaconda\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: plotly in c:\\anaconda\\lib\\site-packages (from catboost) (5.8.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\anaconda\\lib\\site-packages (from catboost) (1.20.3)\n",
      "Requirement already satisfied: scipy in c:\\anaconda\\lib\\site-packages (from catboost) (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\anaconda\\lib\\site-packages (from catboost) (3.4.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\anaconda\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\anaconda\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\anaconda\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "3AQcxQA4fmX5",
    "outputId": "fdd57969-2b76-4809-e0ce-09a5749f0418"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\79119\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\79119\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\79119\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wDJvnPhEDwhS"
   },
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IjWvq2d1CJVZ",
    "outputId": "5838e207-d092-43ed-93d5-89467e96747a"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.remove('not')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poqnSNS4JRsQ"
   },
   "source": [
    "## Загрузка и предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BL7BR-Skfr2e"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv(r'C:\\Users\\79119\\Desktop\\DF\\comments\\toxic_comments.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uQOKsEVIdLvY"
   },
   "outputs": [],
   "source": [
    "def info_df(df):\n",
    "    print('Ознакомление')\n",
    "    display(df.head())\n",
    "    print(' ')\n",
    "    print('Общая информация')\n",
    "    print(df.info())\n",
    "    print(' ')\n",
    "    print('Дубликаты')\n",
    "    print(df.duplicated().sum())\n",
    "    print(' ')\n",
    "    print('Пропуски')\n",
    "    print(df.isna().sum())\n",
    "    print(' ')\n",
    "    print('Проверка баланса классов')\n",
    "    print(df['toxic'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 903
    },
    "id": "GtzrbHxjgB-P",
    "outputId": "5767fdc1-b09e-4a66-c0b7-6a96ece24f0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ознакомление\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "3           3   \n",
       "4           4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                           Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                           Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Общая информация\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "None\n",
      " \n",
      "Дубликаты\n",
      "0\n",
      " \n",
      "Пропуски\n",
      "Unnamed: 0    0\n",
      "text          0\n",
      "toxic         0\n",
      "dtype: int64\n",
      " \n",
      "Проверка баланса классов\n",
      "0    0.898388\n",
      "1    0.101612\n",
      "Name: toxic, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "info_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iTJS-rOZJhJ"
   },
   "source": [
    "1. Удалим все лишние знаки и пробелы.  \n",
    "2. Приведем к нижнему регистру. \n",
    "4. Проведем токенизацию\n",
    "3. Произведем лемматизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9]+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    text = [word for word in tokens if word not in stop_words]\n",
    "    text = [stemmer.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemm_text'] = df['text'].apply(lambda text: data_processing(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9VFvOwPEck4p",
    "outputId": "714eed27-3ae1-431b-a2eb-cf2d8ffaa283",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metallica fan reverted vandalism closure gas voted new york doll fac please remove template talk page since retired 89 205 38 27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>aww match background colour seemingly stuck thanks talk 21 51 january 11 2016 utc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really not trying edit war guy constantly removing relevant information talking edits instead talk page seems care formatting actual info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestion improvement wondered section statistic later subsection type accident think reference may need tidying exact format ie date format etc later one else first preference formatting style reference want please let know appears backlog article review guess may delay reviewer turn listed relevant form eg wikipedia good article nomination transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "3           3   \n",
       "4           4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                           Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                           Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "   toxic  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2      0   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                      lemm_text  \n",
       "0                                                                                                                                                                                                     explanation edits made username hardcore metallica fan reverted vandalism closure gas voted new york doll fac please remove template talk page since retired 89 205 38 27  \n",
       "1                                                                                                                                                                                                                                                                                             aww match background colour seemingly stuck thanks talk 21 51 january 11 2016 utc  \n",
       "2                                                                                                                                                                                                                             hey man really not trying edit war guy constantly removing relevant information talking edits instead talk page seems care formatting actual info  \n",
       "3  make real suggestion improvement wondered section statistic later subsection type accident think reference may need tidying exact format ie date format etc later one else first preference formatting style reference want please let know appears backlog article review guess may delay reviewer turn listed relevant form eg wikipedia good article nomination transport  \n",
       "4                                                                                                                                                                                                                                                                                                                                                 sir hero chance remember page  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybCe1fUpGfYY",
    "outputId": "9eaaae68-1d84-4c28-eb45-a2f011f424d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159292, 4)\n",
      "\n",
      "Unnamed: 0    0\n",
      "text          0\n",
      "toxic         0\n",
      "lemm_text     0\n",
      "dtype: int64\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print( )\n",
    "print(df.isna().sum())\n",
    "print( )\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFyxc-c4fuD0"
   },
   "source": [
    "**Вывод:**  \n",
    "1. Нам представлен датафрейм, состоящий из 159571 строк и 2 столбцов. Столбец `text` содержит комментарии, столбец `toxic` содержит целевой признак.  \n",
    "2. При анализе выявлени дисбаланс классов в соотношении 9:1  \n",
    "3. В данных нет ни дубликатов, ни прпусков.\n",
    "4. В столбце `lemm_text` размещены очищенные от лишних знакои и пробелов и лемматизированные комментарии для дальнейшей работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rP5dhpsAck4r"
   },
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BmaoNQxcI4xR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['lemm_text']\n",
    "y = df['toxic']\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PHy5UCIWLgi7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк в y_train по классам: [100174  11330]\n",
      "Количество строк в y_valid по классам: [21466  2428]\n",
      "Количество строк в y_test по классам: [21466  2428]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid_test, y_train, y_valid_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size = 0.3, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_valid_test,\n",
    "    y_valid_test,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_valid_test\n",
    ")\n",
    "print(f\"Количество строк в y_train по классам: {np.bincount(y_train)}\")\n",
    "print(f\"Количество строк в y_valid по классам: {np.bincount(y_valid)}\")\n",
    "print(f\"Количество строк в y_test по классам: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_vvCS_oJHE8"
   },
   "source": [
    "### Мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JIunROnCJ59P"
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_vect = count_vect.fit_transform(X_train)\n",
    "X_valid_vect = count_vect.transform(X_valid)\n",
    "X_test_vect = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_vect.shape[0] + X_valid_vect.shape[0] + X_test_vect.shape[0])- X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMoc5Yo3ck4v"
   },
   "source": [
    "#### Downsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0Y5ZrGTaaez"
   },
   "source": [
    "Чтобы сбалансировать целевой признак, уменьшим выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2gPHzEXfck4v"
   },
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=42)] + [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=42)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled,\n",
    "                                                       target_downsampled,\n",
    "                                                       random_state=42)\n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Q6HSP-2Cck4x"
   },
   "outputs": [],
   "source": [
    "X_train_down, y_train_down = downsample(X_train, y_train, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21347,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_down.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "SfpkEmGmck4x"
   },
   "outputs": [],
   "source": [
    "X_train_down_vect = count_vect.fit_transform(X_train_down)\n",
    "X_valid_down_vect = count_vect.transform(X_valid)\n",
    "X_test_down_vect = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21347, 45732)\n",
      "(23894, 45732)\n",
      "(23894, 45732)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_down_vect.shape)\n",
    "print(X_valid_down_vect.shape)\n",
    "print(X_test_down_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Gm5Rz4WMexJ"
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Y-Gk3KZRMUkb"
   },
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer()\n",
    "X_train_tf = count_tf_idf.fit_transform(X_train)\n",
    "X_valid_tf = count_tf_idf.transform(X_valid)\n",
    "X_test_tf = count_tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_tf.shape[0] + X_valid_tf.shape[0] + X_test_tf.shape[0])- X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111504, 138174)\n",
      "(23894, 138174)\n",
      "(23894, 138174)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tf.shape)\n",
    "print(X_valid_tf.shape)\n",
    "print(X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kylFiReck4z"
   },
   "source": [
    "#### Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "5Tqh6sC6ck40"
   },
   "outputs": [],
   "source": [
    "X_train_down_tf = count_tf_idf.fit_transform(X_train_down)\n",
    "X_valid_down_tf = count_tf_idf.transform(X_valid)\n",
    "X_test_down_tf = count_tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21347, 45732)\n",
      "(23894, 45732)\n",
      "(23894, 45732)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_down_tf.shape)\n",
    "print(X_valid_down_tf.shape)\n",
    "print(X_test_down_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_V3OIVsg_tO"
   },
   "source": [
    "**Вывод:**  \n",
    "Подтовили данные при помощи CountVectorizer и TfidfVectorizer и подготовили наборы данных на уменьшенной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXkZSFnbck40"
   },
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8L2T6ZU0R63f"
   },
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JP_B8q5baWv"
   },
   "source": [
    "Здесь и далее напишем функции, которые будут проводить обучение модели и расчет f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RN4WCBYrck41"
   },
   "outputs": [],
   "source": [
    "def lr(X_train, y_train, X_valid, y_valid, class_weight):\n",
    "    model = LogisticRegression(random_state=42, class_weight=class_weight)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_valid)\n",
    "    f1 = f1_score(y_valid, pred)\n",
    "    print(f'Значение f1 логистической регрессии {f1:.2f}')\n",
    "    return model, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZL73fcjOYxG4"
   },
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение f1 логистической регрессии 0.77\n"
     ]
    }
   ],
   "source": [
    "lr_model_vect1, lr_f1_vect1 = lr(X_train_vect, y_train, X_valid_vect, y_valid, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сбалансированные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение f1 логистической регрессии 0.76\n"
     ]
    }
   ],
   "source": [
    "lr_model_vect2, lr_f1_vect2 = lr(X_train_vect, y_train, X_valid_vect, y_valid, 'balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшенная выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение f1 логистической регрессии 0.67\n"
     ]
    }
   ],
   "source": [
    "lr_model_vect3, lr_f1_vect3 = lr(X_train_down_vect, y_train_down, X_valid_down_vect, y_valid, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SqDy_lJY2ue"
   },
   "source": [
    "#### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIk9iAilck43",
    "outputId": "cad0f6fb-809f-4a10-ea51-e4f5b3d16ab7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение f1 логистической регрессии 0.73\n"
     ]
    }
   ],
   "source": [
    "lr_model_tf1, lr_f1_tf1 = lr(X_train_tf, y_train, X_valid_tf, y_valid, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2esdpY8Cck44"
   },
   "source": [
    "Сбалансированные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pWwji2Cck44",
    "outputId": "97b87081-a06b-42c2-d9e1-be9f28700329",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение f1 логистической регрессии 0.75\n"
     ]
    }
   ],
   "source": [
    "lr_model_tf2, lr_f1_tf2 = lr(X_train_tf, y_train, X_valid_tf, y_valid, 'balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшенная выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение f1 логистической регрессии 0.64\n"
     ]
    }
   ],
   "source": [
    "lr_model_tf3, lr_f1_tf3 = lr(X_train_down_tf, y_train_down, X_valid_down_tf, y_valid, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['CountVectorizer', 'CountVectorizer_balanced', 'CountVectorizer_downsample',\n",
    "         'TfidfVectorizer', 'TfidfVectorizer_balanced', 'TfidfVectorizer_downsample']\n",
    "data = {'LogisticRegression': [lr_f1_vect1, lr_f1_vect2, lr_f1_vect3,\n",
    "                               lr_f1_tf1, lr_f1_tf2, lr_f1_tf3]}\n",
    "lr_values = pd.DataFrame(index=index, data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговые значения f1 модели LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CountVectorizer</th>\n",
       "      <td>0.767012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer_balanced</th>\n",
       "      <td>0.756386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer_downsample</th>\n",
       "      <td>0.670285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer</th>\n",
       "      <td>0.727181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer_balanced</th>\n",
       "      <td>0.746410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer_downsample</th>\n",
       "      <td>0.643192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            LogisticRegression\n",
       "CountVectorizer                       0.767012\n",
       "CountVectorizer_balanced              0.756386\n",
       "CountVectorizer_downsample            0.670285\n",
       "TfidfVectorizer                       0.727181\n",
       "TfidfVectorizer_balanced              0.746410\n",
       "TfidfVectorizer_downsample            0.643192"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MY0Dprngck5I"
   },
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APxv5G4mck5K"
   },
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0368d611cf48b79cdb942733fe34d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.101529\n",
      "0:\tlearn: 0.4514270\ttest: 0.4561952\tbest: 0.4561952 (0)\ttotal: 804ms\tremaining: 13m 22s\n",
      "1:\tlearn: 0.4032359\ttest: 0.4029997\tbest: 0.4561952 (0)\ttotal: 1.46s\tremaining: 12m 10s\n",
      "2:\tlearn: 0.4341927\ttest: 0.4413531\tbest: 0.4561952 (0)\ttotal: 2.15s\tremaining: 11m 55s\n",
      "3:\tlearn: 0.4597977\ttest: 0.4639303\tbest: 0.4639303 (3)\ttotal: 2.79s\tremaining: 11m 36s\n",
      "4:\tlearn: 0.4787791\ttest: 0.4828431\tbest: 0.4828431 (4)\ttotal: 3.44s\tremaining: 11m 25s\n",
      "5:\tlearn: 0.4311607\ttest: 0.4279308\tbest: 0.4828431 (4)\ttotal: 4.08s\tremaining: 11m 15s\n",
      "6:\tlearn: 0.4851408\ttest: 0.4891735\tbest: 0.4891735 (6)\ttotal: 4.72s\tremaining: 11m 9s\n",
      "7:\tlearn: 0.4845159\ttest: 0.4888482\tbest: 0.4891735 (6)\ttotal: 5.38s\tremaining: 11m 7s\n",
      "8:\tlearn: 0.4733955\ttest: 0.4845329\tbest: 0.4891735 (6)\ttotal: 6.05s\tremaining: 11m 6s\n",
      "9:\tlearn: 0.5036360\ttest: 0.5125899\tbest: 0.5125899 (9)\ttotal: 6.69s\tremaining: 11m 2s\n",
      "10:\tlearn: 0.4895005\ttest: 0.4939099\tbest: 0.5125899 (9)\ttotal: 7.34s\tremaining: 10m 59s\n",
      "11:\tlearn: 0.4932218\ttest: 0.4984839\tbest: 0.5125899 (9)\ttotal: 7.98s\tremaining: 10m 56s\n",
      "12:\tlearn: 0.4963409\ttest: 0.5003028\tbest: 0.5125899 (9)\ttotal: 8.62s\tremaining: 10m 54s\n",
      "13:\tlearn: 0.5065598\ttest: 0.5111648\tbest: 0.5125899 (9)\ttotal: 9.26s\tremaining: 10m 52s\n",
      "14:\tlearn: 0.4888074\ttest: 0.4940458\tbest: 0.5125899 (9)\ttotal: 9.92s\tremaining: 10m 51s\n",
      "15:\tlearn: 0.4873409\ttest: 0.4891071\tbest: 0.5125899 (9)\ttotal: 10.6s\tremaining: 10m 49s\n",
      "16:\tlearn: 0.5148426\ttest: 0.5172310\tbest: 0.5172310 (16)\ttotal: 11.2s\tremaining: 10m 48s\n",
      "17:\tlearn: 0.5154123\ttest: 0.5178518\tbest: 0.5178518 (17)\ttotal: 11.9s\tremaining: 10m 47s\n",
      "18:\tlearn: 0.5163692\ttest: 0.5188736\tbest: 0.5188736 (18)\ttotal: 12.5s\tremaining: 10m 45s\n",
      "19:\tlearn: 0.5148578\ttest: 0.5169619\tbest: 0.5188736 (18)\ttotal: 13.1s\tremaining: 10m 43s\n",
      "20:\tlearn: 0.5165546\ttest: 0.5198685\tbest: 0.5198685 (20)\ttotal: 13.8s\tremaining: 10m 42s\n",
      "21:\tlearn: 0.5177119\ttest: 0.5229851\tbest: 0.5229851 (21)\ttotal: 14.4s\tremaining: 10m 41s\n",
      "22:\tlearn: 0.5301587\ttest: 0.5374631\tbest: 0.5374631 (22)\ttotal: 15.2s\tremaining: 10m 43s\n",
      "23:\tlearn: 0.5322775\ttest: 0.5384389\tbest: 0.5384389 (23)\ttotal: 15.8s\tremaining: 10m 42s\n",
      "24:\tlearn: 0.5060179\ttest: 0.5081571\tbest: 0.5384389 (23)\ttotal: 16.4s\tremaining: 10m 41s\n",
      "25:\tlearn: 0.5066322\ttest: 0.5108696\tbest: 0.5384389 (23)\ttotal: 17.1s\tremaining: 10m 40s\n",
      "26:\tlearn: 0.5236698\ttest: 0.5265039\tbest: 0.5384389 (23)\ttotal: 17.8s\tremaining: 10m 39s\n",
      "27:\tlearn: 0.5279685\ttest: 0.5336496\tbest: 0.5384389 (23)\ttotal: 18.4s\tremaining: 10m 38s\n",
      "28:\tlearn: 0.5313747\ttest: 0.5349112\tbest: 0.5384389 (23)\ttotal: 19s\tremaining: 10m 37s\n",
      "29:\tlearn: 0.5328014\ttest: 0.5353446\tbest: 0.5384389 (23)\ttotal: 19.7s\tremaining: 10m 36s\n",
      "30:\tlearn: 0.5428014\ttest: 0.5450808\tbest: 0.5450808 (30)\ttotal: 20.3s\tremaining: 10m 34s\n",
      "31:\tlearn: 0.5420996\ttest: 0.5422432\tbest: 0.5450808 (30)\ttotal: 21s\tremaining: 10m 34s\n",
      "32:\tlearn: 0.5441638\ttest: 0.5440141\tbest: 0.5450808 (30)\ttotal: 21.7s\tremaining: 10m 34s\n",
      "33:\tlearn: 0.5468104\ttest: 0.5466276\tbest: 0.5466276 (33)\ttotal: 22.3s\tremaining: 10m 33s\n",
      "34:\tlearn: 0.5593063\ttest: 0.5630058\tbest: 0.5630058 (34)\ttotal: 22.9s\tremaining: 10m 32s\n",
      "35:\tlearn: 0.5605695\ttest: 0.5635838\tbest: 0.5635838 (35)\ttotal: 23.6s\tremaining: 10m 32s\n",
      "36:\tlearn: 0.5628979\ttest: 0.5653303\tbest: 0.5653303 (36)\ttotal: 24.3s\tremaining: 10m 31s\n",
      "37:\tlearn: 0.5718146\ttest: 0.5739679\tbest: 0.5739679 (37)\ttotal: 24.9s\tremaining: 10m 30s\n",
      "38:\tlearn: 0.5719894\ttest: 0.5761741\tbest: 0.5761741 (38)\ttotal: 25.6s\tremaining: 10m 29s\n",
      "39:\tlearn: 0.5740004\ttest: 0.5779555\tbest: 0.5779555 (39)\ttotal: 26.2s\tremaining: 10m 28s\n",
      "40:\tlearn: 0.5736349\ttest: 0.5782857\tbest: 0.5782857 (40)\ttotal: 26.8s\tremaining: 10m 27s\n",
      "41:\tlearn: 0.5752099\ttest: 0.5792631\tbest: 0.5792631 (41)\ttotal: 27.5s\tremaining: 10m 26s\n",
      "42:\tlearn: 0.5859285\ttest: 0.5903683\tbest: 0.5903683 (42)\ttotal: 28.2s\tremaining: 10m 26s\n",
      "43:\tlearn: 0.5864853\ttest: 0.5905356\tbest: 0.5905356 (43)\ttotal: 28.9s\tremaining: 10m 26s\n",
      "44:\tlearn: 0.5881427\ttest: 0.5929904\tbest: 0.5929904 (44)\ttotal: 29.5s\tremaining: 10m 26s\n",
      "45:\tlearn: 0.5891614\ttest: 0.5939086\tbest: 0.5939086 (45)\ttotal: 30.2s\tremaining: 10m 25s\n",
      "46:\tlearn: 0.5894953\ttest: 0.5939086\tbest: 0.5939086 (45)\ttotal: 30.8s\tremaining: 10m 25s\n",
      "47:\tlearn: 0.5899080\ttest: 0.5941824\tbest: 0.5941824 (47)\ttotal: 31.5s\tremaining: 10m 25s\n",
      "48:\tlearn: 0.5915408\ttest: 0.5983099\tbest: 0.5983099 (48)\ttotal: 32.2s\tremaining: 10m 24s\n",
      "49:\tlearn: 0.5919304\ttest: 0.5969560\tbest: 0.5983099 (48)\ttotal: 32.8s\tremaining: 10m 23s\n",
      "50:\tlearn: 0.5929861\ttest: 0.5977465\tbest: 0.5983099 (48)\ttotal: 33.5s\tremaining: 10m 22s\n",
      "51:\tlearn: 0.5951220\ttest: 0.5986509\tbest: 0.5986509 (51)\ttotal: 34.1s\tremaining: 10m 21s\n",
      "52:\tlearn: 0.5961978\ttest: 0.5991016\tbest: 0.5991016 (52)\ttotal: 34.7s\tremaining: 10m 20s\n",
      "53:\tlearn: 0.5977758\ttest: 0.6002246\tbest: 0.6002246 (53)\ttotal: 35.3s\tremaining: 10m 19s\n",
      "54:\tlearn: 0.5995198\ttest: 0.6006730\tbest: 0.6006730 (54)\ttotal: 36s\tremaining: 10m 17s\n",
      "55:\tlearn: 0.5993759\ttest: 0.6001681\tbest: 0.6006730 (54)\ttotal: 36.6s\tremaining: 10m 17s\n",
      "56:\tlearn: 0.6004915\ttest: 0.6007839\tbest: 0.6007839 (56)\ttotal: 37.3s\tremaining: 10m 16s\n",
      "57:\tlearn: 0.6037172\ttest: 0.6059086\tbest: 0.6059086 (57)\ttotal: 37.9s\tremaining: 10m 15s\n",
      "58:\tlearn: 0.6041455\ttest: 0.6071230\tbest: 0.6071230 (58)\ttotal: 38.5s\tremaining: 10m 14s\n",
      "59:\tlearn: 0.6051202\ttest: 0.6090581\tbest: 0.6090581 (59)\ttotal: 39.2s\tremaining: 10m 13s\n",
      "60:\tlearn: 0.6058581\ttest: 0.6094921\tbest: 0.6094921 (60)\ttotal: 39.8s\tremaining: 10m 12s\n",
      "61:\tlearn: 0.6062772\ttest: 0.6104796\tbest: 0.6104796 (61)\ttotal: 40.4s\tremaining: 10m 11s\n",
      "62:\tlearn: 0.6070238\ttest: 0.6100943\tbest: 0.6104796 (61)\ttotal: 41.1s\tremaining: 10m 10s\n",
      "63:\tlearn: 0.6070345\ttest: 0.6105263\tbest: 0.6105263 (63)\ttotal: 41.7s\tremaining: 10m 10s\n",
      "64:\tlearn: 0.6084165\ttest: 0.6120642\tbest: 0.6120642 (64)\ttotal: 42.4s\tremaining: 10m 9s\n",
      "65:\tlearn: 0.6092227\ttest: 0.6116800\tbest: 0.6120642 (64)\ttotal: 43s\tremaining: 10m 8s\n",
      "66:\tlearn: 0.6103950\ttest: 0.6117257\tbest: 0.6120642 (64)\ttotal: 43.6s\tremaining: 10m 7s\n",
      "67:\tlearn: 0.6105801\ttest: 0.6128765\tbest: 0.6128765 (67)\ttotal: 44.3s\tremaining: 10m 6s\n",
      "68:\tlearn: 0.6128784\ttest: 0.6152150\tbest: 0.6152150 (68)\ttotal: 44.9s\tremaining: 10m 5s\n",
      "69:\tlearn: 0.6140818\ttest: 0.6163591\tbest: 0.6163591 (69)\ttotal: 45.5s\tremaining: 10m 5s\n",
      "70:\tlearn: 0.6215486\ttest: 0.6212370\tbest: 0.6212370 (70)\ttotal: 46.2s\tremaining: 10m 4s\n",
      "71:\tlearn: 0.6221518\ttest: 0.6219912\tbest: 0.6219912 (71)\ttotal: 46.8s\tremaining: 10m 3s\n",
      "72:\tlearn: 0.6218932\ttest: 0.6231211\tbest: 0.6231211 (72)\ttotal: 47.5s\tremaining: 10m 3s\n",
      "73:\tlearn: 0.6220708\ttest: 0.6234973\tbest: 0.6234973 (73)\ttotal: 48.1s\tremaining: 10m 2s\n",
      "74:\tlearn: 0.6267696\ttest: 0.6272480\tbest: 0.6272480 (74)\ttotal: 48.8s\tremaining: 10m 1s\n",
      "75:\tlearn: 0.6274487\ttest: 0.6279640\tbest: 0.6279640 (75)\ttotal: 49.4s\tremaining: 10m 1s\n",
      "76:\tlearn: 0.6282576\ttest: 0.6281352\tbest: 0.6281352 (76)\ttotal: 50.1s\tremaining: 10m\n",
      "77:\tlearn: 0.6281842\ttest: 0.6295993\tbest: 0.6295993 (77)\ttotal: 50.7s\tremaining: 9m 59s\n",
      "78:\tlearn: 0.6287950\ttest: 0.6309200\tbest: 0.6309200 (78)\ttotal: 51.4s\tremaining: 9m 58s\n",
      "79:\tlearn: 0.6293224\ttest: 0.6309491\tbest: 0.6309491 (79)\ttotal: 52s\tremaining: 9m 58s\n",
      "80:\tlearn: 0.6292922\ttest: 0.6311208\tbest: 0.6311208 (80)\ttotal: 52.6s\tremaining: 9m 57s\n",
      "81:\tlearn: 0.6305350\ttest: 0.6320652\tbest: 0.6320652 (81)\ttotal: 53.3s\tremaining: 9m 56s\n",
      "82:\tlearn: 0.6308607\ttest: 0.6331795\tbest: 0.6331795 (82)\ttotal: 53.9s\tremaining: 9m 55s\n",
      "83:\tlearn: 0.6319226\ttest: 0.6331795\tbest: 0.6331795 (82)\ttotal: 54.6s\tremaining: 9m 55s\n",
      "84:\tlearn: 0.6325663\ttest: 0.6337225\tbest: 0.6337225 (84)\ttotal: 55.2s\tremaining: 9m 54s\n",
      "85:\tlearn: 0.6328908\ttest: 0.6337225\tbest: 0.6337225 (84)\ttotal: 55.9s\tremaining: 9m 53s\n",
      "86:\tlearn: 0.6325164\ttest: 0.6339213\tbest: 0.6339213 (86)\ttotal: 56.5s\tremaining: 9m 52s\n",
      "87:\tlearn: 0.6337946\ttest: 0.6342919\tbest: 0.6342919 (87)\ttotal: 57.1s\tremaining: 9m 51s\n",
      "88:\tlearn: 0.6341066\ttest: 0.6350325\tbest: 0.6350325 (88)\ttotal: 57.8s\tremaining: 9m 51s\n",
      "89:\tlearn: 0.6341860\ttest: 0.6361668\tbest: 0.6361668 (89)\ttotal: 58.4s\tremaining: 9m 50s\n",
      "90:\tlearn: 0.6349797\ttest: 0.6365359\tbest: 0.6365359 (90)\ttotal: 59.1s\tremaining: 9m 50s\n",
      "91:\tlearn: 0.6360842\ttest: 0.6382059\tbest: 0.6382059 (91)\ttotal: 59.7s\tremaining: 9m 49s\n",
      "92:\tlearn: 0.6364953\ttest: 0.6391363\tbest: 0.6391363 (92)\ttotal: 1m\tremaining: 9m 48s\n",
      "93:\tlearn: 0.6374008\ttest: 0.6393089\tbest: 0.6393089 (93)\ttotal: 1m 1s\tremaining: 9m 48s\n",
      "94:\tlearn: 0.6379580\ttest: 0.6400432\tbest: 0.6400432 (94)\ttotal: 1m 1s\tremaining: 9m 47s\n",
      "95:\tlearn: 0.6387635\ttest: 0.6404100\tbest: 0.6404100 (95)\ttotal: 1m 2s\tremaining: 9m 46s\n",
      "96:\tlearn: 0.6416489\ttest: 0.6449879\tbest: 0.6449879 (96)\ttotal: 1m 2s\tremaining: 9m 45s\n",
      "97:\tlearn: 0.6422717\ttest: 0.6451613\tbest: 0.6451613 (97)\ttotal: 1m 3s\tremaining: 9m 44s\n",
      "98:\tlearn: 0.6426676\ttest: 0.6455254\tbest: 0.6455254 (98)\ttotal: 1m 4s\tremaining: 9m 44s\n",
      "99:\tlearn: 0.6427542\ttest: 0.6458893\tbest: 0.6458893 (99)\ttotal: 1m 4s\tremaining: 9m 43s\n",
      "100:\tlearn: 0.6434211\ttest: 0.6477059\tbest: 0.6477059 (100)\ttotal: 1m 5s\tremaining: 9m 42s\n",
      "101:\tlearn: 0.6436556\ttest: 0.6477059\tbest: 0.6477059 (100)\ttotal: 1m 6s\tremaining: 9m 41s\n",
      "102:\tlearn: 0.6441244\ttest: 0.6476907\tbest: 0.6477059 (100)\ttotal: 1m 6s\tremaining: 9m 40s\n",
      "103:\tlearn: 0.6444739\ttest: 0.6473430\tbest: 0.6477059 (100)\ttotal: 1m 7s\tremaining: 9m 40s\n",
      "104:\tlearn: 0.6460106\ttest: 0.6488079\tbest: 0.6488079 (104)\ttotal: 1m 7s\tremaining: 9m 39s\n",
      "105:\tlearn: 0.6468696\ttest: 0.6495315\tbest: 0.6495315 (105)\ttotal: 1m 8s\tremaining: 9m 38s\n",
      "106:\tlearn: 0.6472581\ttest: 0.6506153\tbest: 0.6506153 (106)\ttotal: 1m 9s\tremaining: 9m 38s\n",
      "107:\tlearn: 0.6471838\ttest: 0.6513369\tbest: 0.6513369 (107)\ttotal: 1m 9s\tremaining: 9m 37s\n",
      "108:\tlearn: 0.6469136\ttest: 0.6518717\tbest: 0.6518717 (108)\ttotal: 1m 10s\tremaining: 9m 36s\n",
      "109:\tlearn: 0.6474572\ttest: 0.6527778\tbest: 0.6527778 (109)\ttotal: 1m 11s\tremaining: 9m 35s\n",
      "110:\tlearn: 0.6474977\ttest: 0.6529522\tbest: 0.6529522 (110)\ttotal: 1m 11s\tremaining: 9m 35s\n",
      "111:\tlearn: 0.6485123\ttest: 0.6533120\tbest: 0.6533120 (111)\ttotal: 1m 12s\tremaining: 9m 34s\n",
      "112:\tlearn: 0.6488685\ttest: 0.6534971\tbest: 0.6534971 (112)\ttotal: 1m 13s\tremaining: 9m 33s\n",
      "113:\tlearn: 0.6498654\ttest: 0.6535076\tbest: 0.6535076 (113)\ttotal: 1m 13s\tremaining: 9m 32s\n",
      "114:\tlearn: 0.6506410\ttest: 0.6538667\tbest: 0.6538667 (114)\ttotal: 1m 14s\tremaining: 9m 31s\n",
      "115:\tlearn: 0.6511042\ttest: 0.6526147\tbest: 0.6538667 (114)\ttotal: 1m 14s\tremaining: 9m 31s\n",
      "116:\tlearn: 0.6512187\ttest: 0.6522551\tbest: 0.6538667 (114)\ttotal: 1m 15s\tremaining: 9m 30s\n",
      "117:\tlearn: 0.6514475\ttest: 0.6528000\tbest: 0.6538667 (114)\ttotal: 1m 16s\tremaining: 9m 29s\n",
      "118:\tlearn: 0.6516417\ttest: 0.6535286\tbest: 0.6538667 (114)\ttotal: 1m 16s\tremaining: 9m 28s\n",
      "119:\tlearn: 0.6522211\ttest: 0.6538871\tbest: 0.6538871 (119)\ttotal: 1m 17s\tremaining: 9m 28s\n",
      "120:\tlearn: 0.6522957\ttest: 0.6538871\tbest: 0.6538871 (119)\ttotal: 1m 18s\tremaining: 9m 27s\n",
      "121:\tlearn: 0.6565311\ttest: 0.6565817\tbest: 0.6565817 (121)\ttotal: 1m 18s\tremaining: 9m 26s\n",
      "122:\tlearn: 0.6569900\ttest: 0.6578249\tbest: 0.6578249 (122)\ttotal: 1m 19s\tremaining: 9m 26s\n",
      "123:\tlearn: 0.6580983\ttest: 0.6587175\tbest: 0.6587175 (123)\ttotal: 1m 20s\tremaining: 9m 25s\n",
      "124:\tlearn: 0.6587861\ttest: 0.6596083\tbest: 0.6596083 (124)\ttotal: 1m 20s\tremaining: 9m 24s\n",
      "125:\tlearn: 0.6593956\ttest: 0.6594337\tbest: 0.6596083 (124)\ttotal: 1m 21s\tremaining: 9m 24s\n",
      "126:\tlearn: 0.6597013\ttest: 0.6612051\tbest: 0.6612051 (126)\ttotal: 1m 21s\tremaining: 9m 23s\n",
      "127:\tlearn: 0.6600806\ttest: 0.6612051\tbest: 0.6612051 (126)\ttotal: 1m 22s\tremaining: 9m 22s\n",
      "128:\tlearn: 0.6603484\ttest: 0.6612051\tbest: 0.6612051 (126)\ttotal: 1m 23s\tremaining: 9m 22s\n",
      "129:\tlearn: 0.6608459\ttest: 0.6613840\tbest: 0.6613840 (129)\ttotal: 1m 23s\tremaining: 9m 21s\n",
      "130:\tlearn: 0.6608449\ttest: 0.6619123\tbest: 0.6619123 (130)\ttotal: 1m 24s\tremaining: 9m 20s\n",
      "131:\tlearn: 0.6614539\ttest: 0.6631468\tbest: 0.6631468 (131)\ttotal: 1m 25s\tremaining: 9m 20s\n",
      "132:\tlearn: 0.6617572\ttest: 0.6626188\tbest: 0.6631468 (131)\ttotal: 1m 25s\tremaining: 9m 19s\n",
      "133:\tlearn: 0.6621346\ttest: 0.6626188\tbest: 0.6631468 (131)\ttotal: 1m 26s\tremaining: 9m 18s\n",
      "134:\tlearn: 0.6629309\ttest: 0.6620908\tbest: 0.6631468 (131)\ttotal: 1m 27s\tremaining: 9m 17s\n",
      "135:\tlearn: 0.6635731\ttest: 0.6617375\tbest: 0.6631468 (131)\ttotal: 1m 27s\tremaining: 9m 17s\n",
      "136:\tlearn: 0.6638760\ttest: 0.6624439\tbest: 0.6631468 (131)\ttotal: 1m 28s\tremaining: 9m 16s\n",
      "137:\tlearn: 0.6640276\ttest: 0.6634996\tbest: 0.6634996 (137)\ttotal: 1m 28s\tremaining: 9m 15s\n",
      "138:\tlearn: 0.6661397\ttest: 0.6670176\tbest: 0.6670176 (138)\ttotal: 1m 29s\tremaining: 9m 15s\n",
      "139:\tlearn: 0.6666667\ttest: 0.6673684\tbest: 0.6673684 (139)\ttotal: 1m 30s\tremaining: 9m 14s\n",
      "140:\tlearn: 0.6693712\ttest: 0.6687697\tbest: 0.6687697 (140)\ttotal: 1m 30s\tremaining: 9m 13s\n",
      "141:\tlearn: 0.6701954\ttest: 0.6687697\tbest: 0.6687697 (140)\ttotal: 1m 31s\tremaining: 9m 12s\n",
      "142:\tlearn: 0.6707928\ttest: 0.6691176\tbest: 0.6691176 (142)\ttotal: 1m 32s\tremaining: 9m 12s\n",
      "143:\tlearn: 0.6734786\ttest: 0.6715596\tbest: 0.6715596 (143)\ttotal: 1m 32s\tremaining: 9m 11s\n",
      "144:\tlearn: 0.6738142\ttest: 0.6720839\tbest: 0.6720839 (144)\ttotal: 1m 33s\tremaining: 9m 10s\n",
      "145:\tlearn: 0.6741523\ttest: 0.6710354\tbest: 0.6720839 (144)\ttotal: 1m 34s\tremaining: 9m 10s\n",
      "146:\tlearn: 0.6747475\ttest: 0.6713836\tbest: 0.6720839 (144)\ttotal: 1m 34s\tremaining: 9m 9s\n",
      "147:\tlearn: 0.6750435\ttest: 0.6722513\tbest: 0.6722513 (147)\ttotal: 1m 35s\tremaining: 9m 8s\n",
      "148:\tlearn: 0.6751907\ttest: 0.6722513\tbest: 0.6722513 (147)\ttotal: 1m 35s\tremaining: 9m 7s\n",
      "149:\tlearn: 0.6735198\ttest: 0.6708595\tbest: 0.6722513 (147)\ttotal: 1m 36s\tremaining: 9m 7s\n",
      "150:\tlearn: 0.6777535\ttest: 0.6758873\tbest: 0.6758873 (150)\ttotal: 1m 37s\tremaining: 9m 6s\n",
      "151:\tlearn: 0.6759379\ttest: 0.6741573\tbest: 0.6758873 (150)\ttotal: 1m 37s\tremaining: 9m 5s\n",
      "152:\tlearn: 0.6766074\ttest: 0.6739812\tbest: 0.6758873 (150)\ttotal: 1m 38s\tremaining: 9m 5s\n",
      "153:\tlearn: 0.6767541\ttest: 0.6758801\tbest: 0.6758873 (150)\ttotal: 1m 39s\tremaining: 9m 4s\n",
      "154:\tlearn: 0.6771248\ttest: 0.6762252\tbest: 0.6762252 (154)\ttotal: 1m 39s\tremaining: 9m 3s\n",
      "155:\tlearn: 0.6774609\ttest: 0.6762252\tbest: 0.6762252 (154)\ttotal: 1m 40s\tremaining: 9m 2s\n",
      "156:\tlearn: 0.6775350\ttest: 0.6762252\tbest: 0.6762252 (154)\ttotal: 1m 40s\tremaining: 9m 2s\n",
      "157:\tlearn: 0.6782375\ttest: 0.6776042\tbest: 0.6776042 (157)\ttotal: 1m 41s\tremaining: 9m 1s\n",
      "158:\tlearn: 0.6786733\ttest: 0.6779485\tbest: 0.6779485 (158)\ttotal: 1m 42s\tremaining: 9m\n",
      "159:\tlearn: 0.6790786\ttest: 0.6779485\tbest: 0.6779485 (158)\ttotal: 1m 42s\tremaining: 9m\n",
      "160:\tlearn: 0.6794141\ttest: 0.6784599\tbest: 0.6784599 (160)\ttotal: 1m 43s\tremaining: 8m 59s\n",
      "161:\tlearn: 0.6802615\ttest: 0.6782926\tbest: 0.6784599 (160)\ttotal: 1m 44s\tremaining: 8m 58s\n",
      "162:\tlearn: 0.6807037\ttest: 0.6791569\tbest: 0.6791569 (162)\ttotal: 1m 44s\tremaining: 8m 57s\n",
      "163:\tlearn: 0.6814377\ttest: 0.6798440\tbest: 0.6798440 (163)\ttotal: 1m 45s\tremaining: 8m 57s\n",
      "164:\tlearn: 0.6819881\ttest: 0.6800104\tbest: 0.6800104 (164)\ttotal: 1m 46s\tremaining: 8m 56s\n",
      "165:\tlearn: 0.6822388\ttest: 0.6810390\tbest: 0.6810390 (165)\ttotal: 1m 46s\tremaining: 8m 56s\n",
      "166:\tlearn: 0.6819094\ttest: 0.6801767\tbest: 0.6810390 (165)\ttotal: 1m 47s\tremaining: 8m 55s\n",
      "167:\tlearn: 0.6823070\ttest: 0.6801767\tbest: 0.6810390 (165)\ttotal: 1m 47s\tremaining: 8m 54s\n",
      "168:\tlearn: 0.6821956\ttest: 0.6808621\tbest: 0.6810390 (165)\ttotal: 1m 48s\tremaining: 8m 53s\n",
      "169:\tlearn: 0.6825706\ttest: 0.6808621\tbest: 0.6810390 (165)\ttotal: 1m 49s\tremaining: 8m 53s\n",
      "170:\tlearn: 0.6846526\ttest: 0.6822309\tbest: 0.6822309 (170)\ttotal: 1m 49s\tremaining: 8m 52s\n",
      "171:\tlearn: 0.6849041\ttest: 0.6823834\tbest: 0.6823834 (171)\ttotal: 1m 50s\tremaining: 8m 51s\n",
      "172:\tlearn: 0.6858540\ttest: 0.6823712\tbest: 0.6823834 (171)\ttotal: 1m 51s\tremaining: 8m 51s\n",
      "173:\tlearn: 0.6858540\ttest: 0.6827122\tbest: 0.6827122 (173)\ttotal: 1m 51s\tremaining: 8m 50s\n",
      "174:\tlearn: 0.6858921\ttest: 0.6830530\tbest: 0.6830530 (174)\ttotal: 1m 52s\tremaining: 8m 49s\n",
      "175:\tlearn: 0.6860381\ttest: 0.6833937\tbest: 0.6833937 (175)\ttotal: 1m 53s\tremaining: 8m 49s\n",
      "176:\tlearn: 0.6861111\ttest: 0.6847545\tbest: 0.6847545 (176)\ttotal: 1m 53s\tremaining: 8m 48s\n",
      "177:\tlearn: 0.6869449\ttest: 0.6847545\tbest: 0.6847545 (176)\ttotal: 1m 54s\tremaining: 8m 47s\n",
      "178:\tlearn: 0.6871220\ttest: 0.6849174\tbest: 0.6849174 (178)\ttotal: 1m 54s\tremaining: 8m 46s\n",
      "179:\tlearn: 0.6876664\ttest: 0.6847405\tbest: 0.6849174 (178)\ttotal: 1m 55s\tremaining: 8m 46s\n",
      "180:\tlearn: 0.6876699\ttest: 0.6844008\tbest: 0.6849174 (178)\ttotal: 1m 56s\tremaining: 8m 45s\n",
      "181:\tlearn: 0.6884391\ttest: 0.6847405\tbest: 0.6849174 (178)\ttotal: 1m 56s\tremaining: 8m 44s\n",
      "182:\tlearn: 0.6887226\ttest: 0.6849032\tbest: 0.6849174 (178)\ttotal: 1m 57s\tremaining: 8m 44s\n",
      "183:\tlearn: 0.6889406\ttest: 0.6857585\tbest: 0.6857585 (183)\ttotal: 1m 58s\tremaining: 8m 43s\n",
      "184:\tlearn: 0.6890514\ttest: 0.6855816\tbest: 0.6857585 (183)\ttotal: 1m 58s\tremaining: 8m 42s\n",
      "185:\tlearn: 0.6896361\ttest: 0.6852425\tbest: 0.6857585 (183)\ttotal: 1m 59s\tremaining: 8m 42s\n",
      "186:\tlearn: 0.6908306\ttest: 0.6857437\tbest: 0.6857585 (183)\ttotal: 1m 59s\tremaining: 8m 41s\n",
      "187:\tlearn: 0.6911545\ttest: 0.6857290\tbest: 0.6857585 (183)\ttotal: 2m\tremaining: 8m 40s\n",
      "188:\tlearn: 0.6915547\ttest: 0.6858908\tbest: 0.6858908 (188)\ttotal: 2m 1s\tremaining: 8m 40s\n",
      "189:\tlearn: 0.6937265\ttest: 0.6875804\tbest: 0.6875804 (189)\ttotal: 2m 1s\tremaining: 8m 39s\n",
      "190:\tlearn: 0.6940150\ttest: 0.6882549\tbest: 0.6882549 (190)\ttotal: 2m 2s\tremaining: 8m 38s\n",
      "191:\tlearn: 0.6940533\ttest: 0.6882549\tbest: 0.6882549 (190)\ttotal: 2m 3s\tremaining: 8m 38s\n",
      "192:\tlearn: 0.6944429\ttest: 0.6889288\tbest: 0.6889288 (192)\ttotal: 2m 3s\tremaining: 8m 37s\n",
      "193:\tlearn: 0.6951630\ttest: 0.6880946\tbest: 0.6889288 (192)\ttotal: 2m 4s\tremaining: 8m 36s\n",
      "194:\tlearn: 0.6951341\ttest: 0.6889288\tbest: 0.6889288 (192)\ttotal: 2m 4s\tremaining: 8m 36s\n",
      "195:\tlearn: 0.6952444\ttest: 0.6894426\tbest: 0.6894426 (195)\ttotal: 2m 5s\tremaining: 8m 35s\n",
      "196:\tlearn: 0.6959303\ttest: 0.6892655\tbest: 0.6894426 (195)\ttotal: 2m 6s\tremaining: 8m 34s\n",
      "197:\tlearn: 0.6963951\ttest: 0.6892481\tbest: 0.6894426 (195)\ttotal: 2m 6s\tremaining: 8m 34s\n",
      "198:\tlearn: 0.6978101\ttest: 0.6912442\tbest: 0.6912442 (198)\ttotal: 2m 7s\tremaining: 8m 33s\n",
      "199:\tlearn: 0.6979149\ttest: 0.6915792\tbest: 0.6915792 (199)\ttotal: 2m 8s\tremaining: 8m 32s\n",
      "200:\tlearn: 0.6983446\ttest: 0.6919140\tbest: 0.6919140 (200)\ttotal: 2m 8s\tremaining: 8m 32s\n",
      "201:\tlearn: 0.6980530\ttest: 0.6919140\tbest: 0.6919140 (200)\ttotal: 2m 9s\tremaining: 8m 31s\n",
      "202:\tlearn: 0.6987687\ttest: 0.6917370\tbest: 0.6919140 (200)\ttotal: 2m 10s\tremaining: 8m 30s\n",
      "203:\tlearn: 0.6987687\ttest: 0.6915601\tbest: 0.6919140 (200)\ttotal: 2m 10s\tremaining: 8m 30s\n",
      "204:\tlearn: 0.6991593\ttest: 0.6915601\tbest: 0.6919140 (200)\ttotal: 2m 11s\tremaining: 8m 29s\n",
      "205:\tlearn: 0.6993022\ttest: 0.6915601\tbest: 0.6919140 (200)\ttotal: 2m 11s\tremaining: 8m 28s\n",
      "206:\tlearn: 0.6994451\ttest: 0.6917178\tbest: 0.6919140 (200)\ttotal: 2m 12s\tremaining: 8m 27s\n",
      "207:\tlearn: 0.6994451\ttest: 0.6917178\tbest: 0.6919140 (200)\ttotal: 2m 13s\tremaining: 8m 27s\n",
      "208:\tlearn: 0.6999451\ttest: 0.6917178\tbest: 0.6919140 (200)\ttotal: 2m 13s\tremaining: 8m 26s\n",
      "209:\tlearn: 0.7005271\ttest: 0.6930744\tbest: 0.6930744 (209)\ttotal: 2m 14s\tremaining: 8m 26s\n",
      "210:\tlearn: 0.7011475\ttest: 0.6937420\tbest: 0.6937420 (210)\ttotal: 2m 15s\tremaining: 8m 25s\n",
      "211:\tlearn: 0.7012573\ttest: 0.6940756\tbest: 0.6940756 (211)\ttotal: 2m 15s\tremaining: 8m 24s\n",
      "212:\tlearn: 0.7029991\ttest: 0.6944090\tbest: 0.6944090 (212)\ttotal: 2m 16s\tremaining: 8m 23s\n",
      "213:\tlearn: 0.7029931\ttest: 0.6937213\tbest: 0.6944090 (212)\ttotal: 2m 17s\tremaining: 8m 23s\n",
      "214:\tlearn: 0.7034845\ttest: 0.6945436\tbest: 0.6945436 (214)\ttotal: 2m 17s\tremaining: 8m 22s\n",
      "215:\tlearn: 0.7037950\ttest: 0.6945436\tbest: 0.6945436 (214)\ttotal: 2m 18s\tremaining: 8m 21s\n",
      "216:\tlearn: 0.7040911\ttest: 0.6945649\tbest: 0.6945649 (216)\ttotal: 2m 18s\tremaining: 8m 21s\n",
      "217:\tlearn: 0.7049037\ttest: 0.6952308\tbest: 0.6952308 (217)\ttotal: 2m 19s\tremaining: 8m 20s\n",
      "218:\tlearn: 0.7053288\ttest: 0.6943878\tbest: 0.6952308 (217)\ttotal: 2m 20s\tremaining: 8m 20s\n",
      "219:\tlearn: 0.7061010\ttest: 0.6958737\tbest: 0.6958737 (219)\ttotal: 2m 20s\tremaining: 8m 19s\n",
      "220:\tlearn: 0.7063839\ttest: 0.6958737\tbest: 0.6958737 (219)\ttotal: 2m 21s\tremaining: 8m 18s\n",
      "221:\tlearn: 0.7064546\ttest: 0.6958737\tbest: 0.6958737 (219)\ttotal: 2m 22s\tremaining: 8m 17s\n",
      "222:\tlearn: 0.7064546\ttest: 0.6958737\tbest: 0.6958737 (219)\ttotal: 2m 22s\tremaining: 8m 17s\n",
      "223:\tlearn: 0.7069050\ttest: 0.6963831\tbest: 0.6963831 (223)\ttotal: 2m 23s\tremaining: 8m 16s\n",
      "224:\tlearn: 0.7076889\ttest: 0.6965377\tbest: 0.6965377 (224)\ttotal: 2m 24s\tremaining: 8m 16s\n",
      "225:\tlearn: 0.7077915\ttest: 0.6966921\tbest: 0.6966921 (225)\ttotal: 2m 24s\tremaining: 8m 15s\n",
      "226:\tlearn: 0.7079646\ttest: 0.6966921\tbest: 0.6966921 (225)\ttotal: 2m 25s\tremaining: 8m 14s\n",
      "227:\tlearn: 0.7077848\ttest: 0.6971777\tbest: 0.6971777 (227)\ttotal: 2m 25s\tremaining: 8m 14s\n",
      "228:\tlearn: 0.7084835\ttest: 0.6976626\tbest: 0.6976626 (228)\ttotal: 2m 26s\tremaining: 8m 13s\n",
      "229:\tlearn: 0.7088359\ttest: 0.6976626\tbest: 0.6976626 (228)\ttotal: 2m 27s\tremaining: 8m 12s\n",
      "230:\tlearn: 0.7089450\ttest: 0.6973316\tbest: 0.6976626 (228)\ttotal: 2m 27s\tremaining: 8m 12s\n",
      "231:\tlearn: 0.7090651\ttest: 0.6976390\tbest: 0.6976626 (228)\ttotal: 2m 28s\tremaining: 8m 11s\n",
      "232:\tlearn: 0.7092059\ttest: 0.6976390\tbest: 0.6976626 (228)\ttotal: 2m 29s\tremaining: 8m 10s\n",
      "233:\tlearn: 0.7094628\ttest: 0.6979695\tbest: 0.6979695 (233)\ttotal: 2m 29s\tremaining: 8m 10s\n",
      "234:\tlearn: 0.7098533\ttest: 0.6979695\tbest: 0.6979695 (233)\ttotal: 2m 30s\tremaining: 8m 9s\n",
      "235:\tlearn: 0.7099940\ttest: 0.6979695\tbest: 0.6979695 (233)\ttotal: 2m 30s\tremaining: 8m 8s\n",
      "236:\tlearn: 0.7100256\ttest: 0.6976154\tbest: 0.6979695 (233)\ttotal: 2m 31s\tremaining: 8m 7s\n",
      "237:\tlearn: 0.7106023\ttest: 0.6979457\tbest: 0.6979695 (233)\ttotal: 2m 32s\tremaining: 8m 7s\n",
      "238:\tlearn: 0.7107429\ttest: 0.6979457\tbest: 0.6979695 (233)\ttotal: 2m 32s\tremaining: 8m 6s\n",
      "239:\tlearn: 0.7113048\ttest: 0.6989356\tbest: 0.6989356 (239)\ttotal: 2m 33s\tremaining: 8m 6s\n",
      "240:\tlearn: 0.7116097\ttest: 0.6989356\tbest: 0.6989356 (239)\ttotal: 2m 34s\tremaining: 8m 5s\n",
      "241:\tlearn: 0.7114233\ttest: 0.6992405\tbest: 0.6992405 (241)\ttotal: 2m 34s\tremaining: 8m 4s\n",
      "242:\tlearn: 0.7117352\ttest: 0.6994176\tbest: 0.6994176 (242)\ttotal: 2m 35s\tremaining: 8m 4s\n",
      "243:\tlearn: 0.7121171\ttest: 0.7017189\tbest: 0.7017189 (243)\ttotal: 2m 36s\tremaining: 8m 3s\n",
      "244:\tlearn: 0.7125061\ttest: 0.7025524\tbest: 0.7025524 (244)\ttotal: 2m 36s\tremaining: 8m 2s\n",
      "245:\tlearn: 0.7125061\ttest: 0.7028802\tbest: 0.7028802 (245)\ttotal: 2m 37s\tremaining: 8m 2s\n",
      "246:\tlearn: 0.7126774\ttest: 0.7028802\tbest: 0.7028802 (245)\ttotal: 2m 37s\tremaining: 8m 1s\n",
      "247:\tlearn: 0.7126774\ttest: 0.7028802\tbest: 0.7028802 (245)\ttotal: 2m 38s\tremaining: 8m\n",
      "248:\tlearn: 0.7128950\ttest: 0.7037131\tbest: 0.7037131 (248)\ttotal: 2m 39s\tremaining: 8m\n",
      "249:\tlearn: 0.7129650\ttest: 0.7033855\tbest: 0.7037131 (248)\ttotal: 2m 39s\tremaining: 7m 59s\n",
      "250:\tlearn: 0.7134160\ttest: 0.7035354\tbest: 0.7037131 (248)\ttotal: 2m 40s\tremaining: 7m 58s\n",
      "251:\tlearn: 0.7137421\ttest: 0.7040404\tbest: 0.7040404 (251)\ttotal: 2m 41s\tremaining: 7m 58s\n",
      "252:\tlearn: 0.7170547\ttest: 0.7064451\tbest: 0.7064451 (252)\ttotal: 2m 41s\tremaining: 7m 57s\n",
      "253:\tlearn: 0.7173019\ttest: 0.7070961\tbest: 0.7070961 (253)\ttotal: 2m 42s\tremaining: 7m 56s\n",
      "254:\tlearn: 0.7174490\ttest: 0.7082495\tbest: 0.7082495 (254)\ttotal: 2m 42s\tremaining: 7m 56s\n",
      "255:\tlearn: 0.7181735\ttest: 0.7090452\tbest: 0.7090452 (255)\ttotal: 2m 43s\tremaining: 7m 55s\n",
      "256:\tlearn: 0.7182123\ttest: 0.7090452\tbest: 0.7090452 (255)\ttotal: 2m 44s\tremaining: 7m 54s\n",
      "257:\tlearn: 0.7153483\ttest: 0.7061492\tbest: 0.7090452 (255)\ttotal: 2m 44s\tremaining: 7m 54s\n",
      "258:\tlearn: 0.7153483\ttest: 0.7061492\tbest: 0.7090452 (255)\ttotal: 2m 45s\tremaining: 7m 53s\n",
      "259:\tlearn: 0.7189139\ttest: 0.7096612\tbest: 0.7096612 (259)\ttotal: 2m 46s\tremaining: 7m 52s\n",
      "260:\tlearn: 0.7190525\ttest: 0.7096612\tbest: 0.7096612 (259)\ttotal: 2m 46s\tremaining: 7m 52s\n",
      "261:\tlearn: 0.7193295\ttest: 0.7100176\tbest: 0.7100176 (261)\ttotal: 2m 47s\tremaining: 7m 51s\n",
      "262:\tlearn: 0.7198141\ttest: 0.7100176\tbest: 0.7100176 (261)\ttotal: 2m 47s\tremaining: 7m 50s\n",
      "263:\tlearn: 0.7171284\ttest: 0.7069791\tbest: 0.7100176 (261)\ttotal: 2m 48s\tremaining: 7m 50s\n",
      "264:\tlearn: 0.7205445\ttest: 0.7096936\tbest: 0.7100176 (261)\ttotal: 2m 49s\tremaining: 7m 49s\n",
      "265:\tlearn: 0.7205445\ttest: 0.7096936\tbest: 0.7100176 (261)\ttotal: 2m 49s\tremaining: 7m 48s\n",
      "266:\tlearn: 0.7205445\ttest: 0.7096936\tbest: 0.7100176 (261)\ttotal: 2m 50s\tremaining: 7m 47s\n",
      "267:\tlearn: 0.7173289\ttest: 0.7071267\tbest: 0.7100176 (261)\ttotal: 2m 51s\tremaining: 7m 47s\n",
      "268:\tlearn: 0.7180626\ttest: 0.7080714\tbest: 0.7100176 (261)\ttotal: 2m 51s\tremaining: 7m 46s\n",
      "269:\tlearn: 0.7183015\ttest: 0.7080714\tbest: 0.7100176 (261)\ttotal: 2m 52s\tremaining: 7m 46s\n",
      "270:\tlearn: 0.7182626\ttest: 0.7090452\tbest: 0.7100176 (261)\ttotal: 2m 53s\tremaining: 7m 45s\n",
      "271:\tlearn: 0.7182626\ttest: 0.7090452\tbest: 0.7100176 (261)\ttotal: 2m 53s\tremaining: 7m 44s\n",
      "272:\tlearn: 0.7184844\ttest: 0.7096936\tbest: 0.7100176 (261)\ttotal: 2m 54s\tremaining: 7m 44s\n",
      "273:\tlearn: 0.7184151\ttest: 0.7093695\tbest: 0.7100176 (261)\ttotal: 2m 54s\tremaining: 7m 43s\n",
      "274:\tlearn: 0.7183457\ttest: 0.7093695\tbest: 0.7100176 (261)\ttotal: 2m 55s\tremaining: 7m 42s\n",
      "275:\tlearn: 0.7183457\ttest: 0.7093695\tbest: 0.7100176 (261)\ttotal: 2m 56s\tremaining: 7m 42s\n",
      "276:\tlearn: 0.7183457\ttest: 0.7093695\tbest: 0.7100176 (261)\ttotal: 2m 56s\tremaining: 7m 41s\n",
      "277:\tlearn: 0.7183457\ttest: 0.7093695\tbest: 0.7100176 (261)\ttotal: 2m 57s\tremaining: 7m 40s\n",
      "278:\tlearn: 0.7180126\ttest: 0.7093695\tbest: 0.7100176 (261)\ttotal: 2m 58s\tremaining: 7m 40s\n",
      "279:\tlearn: 0.7185758\ttest: 0.7093695\tbest: 0.7100176 (261)\ttotal: 2m 58s\tremaining: 7m 39s\n",
      "280:\tlearn: 0.7191996\ttest: 0.7093695\tbest: 0.7100176 (261)\ttotal: 2m 59s\tremaining: 7m 38s\n",
      "281:\tlearn: 0.7191996\ttest: 0.7101959\tbest: 0.7101959 (281)\ttotal: 2m 59s\tremaining: 7m 38s\n",
      "282:\tlearn: 0.7197924\ttest: 0.7101959\tbest: 0.7101959 (281)\ttotal: 3m\tremaining: 7m 37s\n",
      "283:\tlearn: 0.7197924\ttest: 0.7101959\tbest: 0.7101959 (281)\ttotal: 3m 1s\tremaining: 7m 36s\n",
      "284:\tlearn: 0.7197707\ttest: 0.7098719\tbest: 0.7101959 (281)\ttotal: 3m 1s\tremaining: 7m 36s\n",
      "285:\tlearn: 0.7197318\ttest: 0.7098719\tbest: 0.7101959 (281)\ttotal: 3m 2s\tremaining: 7m 35s\n",
      "286:\tlearn: 0.7195761\ttest: 0.7098719\tbest: 0.7101959 (281)\ttotal: 3m 3s\tremaining: 7m 34s\n",
      "287:\tlearn: 0.7198833\ttest: 0.7098719\tbest: 0.7101959 (281)\ttotal: 3m 3s\tremaining: 7m 34s\n",
      "288:\tlearn: 0.7199524\ttest: 0.7098719\tbest: 0.7101959 (281)\ttotal: 3m 4s\tremaining: 7m 33s\n",
      "289:\tlearn: 0.7203069\ttest: 0.7098719\tbest: 0.7101959 (281)\ttotal: 3m 4s\tremaining: 7m 32s\n",
      "290:\tlearn: 0.7237111\ttest: 0.7128564\tbest: 0.7128564 (290)\ttotal: 3m 5s\tremaining: 7m 32s\n",
      "291:\tlearn: 0.7241639\ttest: 0.7130000\tbest: 0.7130000 (291)\ttotal: 3m 6s\tremaining: 7m 31s\n",
      "292:\tlearn: 0.7244772\ttest: 0.7133217\tbest: 0.7133217 (292)\ttotal: 3m 6s\tremaining: 7m 30s\n",
      "293:\tlearn: 0.7244772\ttest: 0.7133217\tbest: 0.7133217 (292)\ttotal: 3m 7s\tremaining: 7m 30s\n",
      "294:\tlearn: 0.7246626\ttest: 0.7140719\tbest: 0.7140719 (294)\ttotal: 3m 8s\tremaining: 7m 29s\n",
      "295:\tlearn: 0.7245940\ttest: 0.7140719\tbest: 0.7140719 (294)\ttotal: 3m 8s\tremaining: 7m 28s\n",
      "296:\tlearn: 0.7248575\ttest: 0.7147132\tbest: 0.7147132 (296)\ttotal: 3m 9s\tremaining: 7m 28s\n",
      "297:\tlearn: 0.7252003\ttest: 0.7156741\tbest: 0.7156741 (297)\ttotal: 3m 9s\tremaining: 7m 27s\n",
      "298:\tlearn: 0.7252794\ttest: 0.7161724\tbest: 0.7161724 (298)\ttotal: 3m 10s\tremaining: 7m 26s\n",
      "299:\tlearn: 0.7256219\ttest: 0.7162095\tbest: 0.7162095 (299)\ttotal: 3m 11s\tremaining: 7m 26s\n",
      "300:\tlearn: 0.7260715\ttest: 0.7162095\tbest: 0.7162095 (299)\ttotal: 3m 11s\tremaining: 7m 25s\n",
      "301:\tlearn: 0.7260811\ttest: 0.7165295\tbest: 0.7165295 (301)\ttotal: 3m 12s\tremaining: 7m 24s\n",
      "302:\tlearn: 0.7261495\ttest: 0.7168495\tbest: 0.7168495 (302)\ttotal: 3m 13s\tremaining: 7m 24s\n",
      "303:\tlearn: 0.7262768\ttest: 0.7169905\tbest: 0.7169905 (303)\ttotal: 3m 13s\tremaining: 7m 23s\n",
      "304:\tlearn: 0.7262768\ttest: 0.7169905\tbest: 0.7169905 (303)\ttotal: 3m 14s\tremaining: 7m 22s\n",
      "305:\tlearn: 0.7264136\ttest: 0.7168120\tbest: 0.7169905 (303)\ttotal: 3m 15s\tremaining: 7m 22s\n",
      "306:\tlearn: 0.7266967\ttest: 0.7164923\tbest: 0.7169905 (303)\ttotal: 3m 15s\tremaining: 7m 21s\n",
      "307:\tlearn: 0.7269702\ttest: 0.7161724\tbest: 0.7169905 (303)\ttotal: 3m 16s\tremaining: 7m 21s\n",
      "308:\tlearn: 0.7271361\ttest: 0.7166335\tbest: 0.7169905 (303)\ttotal: 3m 16s\tremaining: 7m 20s\n",
      "309:\tlearn: 0.7275459\ttest: 0.7166335\tbest: 0.7169905 (303)\ttotal: 3m 17s\tremaining: 7m 19s\n",
      "310:\tlearn: 0.7276141\ttest: 0.7166335\tbest: 0.7169905 (303)\ttotal: 3m 18s\tremaining: 7m 19s\n",
      "311:\tlearn: 0.7275361\ttest: 0.7164551\tbest: 0.7169905 (303)\ttotal: 3m 18s\tremaining: 7m 18s\n",
      "312:\tlearn: 0.7280137\ttest: 0.7164551\tbest: 0.7169905 (303)\ttotal: 3m 19s\tremaining: 7m 17s\n",
      "313:\tlearn: 0.7282183\ttest: 0.7167745\tbest: 0.7169905 (303)\ttotal: 3m 20s\tremaining: 7m 17s\n",
      "314:\tlearn: 0.7283156\ttest: 0.7166335\tbest: 0.7169905 (303)\ttotal: 3m 20s\tremaining: 7m 16s\n",
      "315:\tlearn: 0.7283156\ttest: 0.7166335\tbest: 0.7169905 (303)\ttotal: 3m 21s\tremaining: 7m 15s\n",
      "316:\tlearn: 0.7283156\ttest: 0.7166335\tbest: 0.7169905 (303)\ttotal: 3m 22s\tremaining: 7m 15s\n",
      "317:\tlearn: 0.7283838\ttest: 0.7169529\tbest: 0.7169905 (303)\ttotal: 3m 22s\tremaining: 7m 14s\n",
      "318:\tlearn: 0.7288317\ttest: 0.7169154\tbest: 0.7169905 (303)\ttotal: 3m 23s\tremaining: 7m 13s\n",
      "319:\tlearn: 0.7288317\ttest: 0.7169154\tbest: 0.7169905 (303)\ttotal: 3m 23s\tremaining: 7m 13s\n",
      "320:\tlearn: 0.7288898\ttest: 0.7172345\tbest: 0.7172345 (320)\ttotal: 3m 24s\tremaining: 7m 12s\n",
      "321:\tlearn: 0.7292403\ttest: 0.7167371\tbest: 0.7172345 (320)\ttotal: 3m 25s\tremaining: 7m 12s\n",
      "322:\tlearn: 0.7293765\ttest: 0.7167371\tbest: 0.7172345 (320)\ttotal: 3m 25s\tremaining: 7m 11s\n",
      "323:\tlearn: 0.7300958\ttest: 0.7176938\tbest: 0.7176938 (323)\ttotal: 3m 26s\tremaining: 7m 10s\n",
      "324:\tlearn: 0.7304050\ttest: 0.7183308\tbest: 0.7183308 (324)\ttotal: 3m 27s\tremaining: 7m 10s\n",
      "325:\tlearn: 0.7302794\ttest: 0.7178341\tbest: 0.7183308 (324)\ttotal: 3m 27s\tremaining: 7m 9s\n",
      "326:\tlearn: 0.7302301\ttest: 0.7184707\tbest: 0.7184707 (326)\ttotal: 3m 28s\tremaining: 7m 8s\n",
      "327:\tlearn: 0.7302878\ttest: 0.7182924\tbest: 0.7184707 (326)\ttotal: 3m 28s\tremaining: 7m 8s\n",
      "328:\tlearn: 0.7302878\ttest: 0.7182924\tbest: 0.7184707 (326)\ttotal: 3m 29s\tremaining: 7m 7s\n",
      "329:\tlearn: 0.7302878\ttest: 0.7182924\tbest: 0.7184707 (326)\ttotal: 3m 30s\tremaining: 7m 6s\n",
      "330:\tlearn: 0.7302878\ttest: 0.7182924\tbest: 0.7184707 (326)\ttotal: 3m 30s\tremaining: 7m 6s\n",
      "331:\tlearn: 0.7302878\ttest: 0.7182924\tbest: 0.7184707 (326)\ttotal: 3m 31s\tremaining: 7m 5s\n",
      "332:\tlearn: 0.7302589\ttest: 0.7184707\tbest: 0.7184707 (326)\ttotal: 3m 32s\tremaining: 7m 4s\n",
      "333:\tlearn: 0.7302589\ttest: 0.7184707\tbest: 0.7184707 (326)\ttotal: 3m 32s\tremaining: 7m 4s\n",
      "334:\tlearn: 0.7302589\ttest: 0.7184707\tbest: 0.7184707 (326)\ttotal: 3m 33s\tremaining: 7m 3s\n",
      "335:\tlearn: 0.7305697\ttest: 0.7183308\tbest: 0.7184707 (326)\ttotal: 3m 33s\tremaining: 7m 2s\n",
      "336:\tlearn: 0.7305697\ttest: 0.7183308\tbest: 0.7184707 (326)\ttotal: 3m 34s\tremaining: 7m 2s\n",
      "337:\tlearn: 0.7305697\ttest: 0.7183308\tbest: 0.7184707 (326)\ttotal: 3m 35s\tremaining: 7m 1s\n",
      "338:\tlearn: 0.7309873\ttest: 0.7185093\tbest: 0.7185093 (338)\ttotal: 3m 35s\tremaining: 7m\n",
      "339:\tlearn: 0.7309379\ttest: 0.7183308\tbest: 0.7185093 (338)\ttotal: 3m 36s\tremaining: 7m\n",
      "340:\tlearn: 0.7314805\ttest: 0.7181525\tbest: 0.7185093 (338)\ttotal: 3m 37s\tremaining: 6m 59s\n",
      "341:\tlearn: 0.7313919\ttest: 0.7184707\tbest: 0.7185093 (338)\ttotal: 3m 37s\tremaining: 6m 58s\n",
      "342:\tlearn: 0.7313919\ttest: 0.7184707\tbest: 0.7185093 (338)\ttotal: 3m 38s\tremaining: 6m 58s\n",
      "343:\tlearn: 0.7313919\ttest: 0.7189672\tbest: 0.7189672 (343)\ttotal: 3m 39s\tremaining: 6m 57s\n",
      "344:\tlearn: 0.7313919\ttest: 0.7189672\tbest: 0.7189672 (343)\ttotal: 3m 39s\tremaining: 6m 56s\n",
      "345:\tlearn: 0.7320122\ttest: 0.7192852\tbest: 0.7192852 (345)\ttotal: 3m 40s\tremaining: 6m 56s\n",
      "346:\tlearn: 0.7322544\ttest: 0.7204168\tbest: 0.7204168 (346)\ttotal: 3m 40s\tremaining: 6m 55s\n",
      "347:\tlearn: 0.7323899\ttest: 0.7207341\tbest: 0.7207341 (347)\ttotal: 3m 41s\tremaining: 6m 55s\n",
      "348:\tlearn: 0.7324290\ttest: 0.7207341\tbest: 0.7207341 (347)\ttotal: 3m 42s\tremaining: 6m 54s\n",
      "349:\tlearn: 0.7325252\ttest: 0.7200993\tbest: 0.7207341 (347)\ttotal: 3m 42s\tremaining: 6m 53s\n",
      "350:\tlearn: 0.7326606\ttest: 0.7200993\tbest: 0.7207341 (347)\ttotal: 3m 43s\tremaining: 6m 53s\n",
      "351:\tlearn: 0.7326606\ttest: 0.7202780\tbest: 0.7207341 (347)\ttotal: 3m 44s\tremaining: 6m 52s\n",
      "352:\tlearn: 0.7326606\ttest: 0.7202780\tbest: 0.7207341 (347)\ttotal: 3m 44s\tremaining: 6m 51s\n",
      "353:\tlearn: 0.7329418\ttest: 0.7202780\tbest: 0.7207341 (347)\ttotal: 3m 45s\tremaining: 6m 51s\n",
      "354:\tlearn: 0.7329418\ttest: 0.7202780\tbest: 0.7207341 (347)\ttotal: 3m 45s\tremaining: 6m 50s\n",
      "355:\tlearn: 0.7329418\ttest: 0.7202780\tbest: 0.7207341 (347)\ttotal: 3m 46s\tremaining: 6m 49s\n",
      "356:\tlearn: 0.7329418\ttest: 0.7202780\tbest: 0.7207341 (347)\ttotal: 3m 47s\tremaining: 6m 49s\n",
      "357:\tlearn: 0.7330380\ttest: 0.7205955\tbest: 0.7207341 (347)\ttotal: 3m 47s\tremaining: 6m 48s\n",
      "358:\tlearn: 0.7332515\ttest: 0.7209129\tbest: 0.7209129 (358)\ttotal: 3m 48s\tremaining: 6m 47s\n",
      "359:\tlearn: 0.7332230\ttest: 0.7215472\tbest: 0.7215472 (359)\ttotal: 3m 49s\tremaining: 6m 47s\n",
      "360:\tlearn: 0.7335611\ttest: 0.7213684\tbest: 0.7215472 (359)\ttotal: 3m 49s\tremaining: 6m 46s\n",
      "361:\tlearn: 0.7341475\ttest: 0.7211896\tbest: 0.7215472 (359)\ttotal: 3m 50s\tremaining: 6m 45s\n",
      "362:\tlearn: 0.7341475\ttest: 0.7211896\tbest: 0.7215472 (359)\ttotal: 3m 50s\tremaining: 6m 45s\n",
      "363:\tlearn: 0.7341867\ttest: 0.7211896\tbest: 0.7215472 (359)\ttotal: 3m 51s\tremaining: 6m 44s\n",
      "364:\tlearn: 0.7343892\ttest: 0.7211896\tbest: 0.7215472 (359)\ttotal: 3m 52s\tremaining: 6m 43s\n",
      "365:\tlearn: 0.7343892\ttest: 0.7211896\tbest: 0.7215472 (359)\ttotal: 3m 52s\tremaining: 6m 43s\n",
      "366:\tlearn: 0.7343892\ttest: 0.7211896\tbest: 0.7215472 (359)\ttotal: 3m 53s\tremaining: 6m 42s\n",
      "367:\tlearn: 0.7345524\ttest: 0.7211896\tbest: 0.7215472 (359)\ttotal: 3m 54s\tremaining: 6m 42s\n",
      "368:\tlearn: 0.7345133\ttest: 0.7210109\tbest: 0.7215472 (359)\ttotal: 3m 54s\tremaining: 6m 41s\n",
      "369:\tlearn: 0.7345133\ttest: 0.7210109\tbest: 0.7215472 (359)\ttotal: 3m 55s\tremaining: 6m 40s\n",
      "370:\tlearn: 0.7345699\ttest: 0.7210109\tbest: 0.7215472 (359)\ttotal: 3m 56s\tremaining: 6m 40s\n",
      "371:\tlearn: 0.7345699\ttest: 0.7213277\tbest: 0.7215472 (359)\ttotal: 3m 56s\tremaining: 6m 39s\n",
      "372:\tlearn: 0.7346373\ttest: 0.7218231\tbest: 0.7218231 (372)\ttotal: 3m 57s\tremaining: 6m 38s\n",
      "373:\tlearn: 0.7348004\ttest: 0.7218231\tbest: 0.7218231 (372)\ttotal: 3m 57s\tremaining: 6m 38s\n",
      "374:\tlearn: 0.7351092\ttest: 0.7218231\tbest: 0.7218231 (372)\ttotal: 3m 58s\tremaining: 6m 37s\n",
      "375:\tlearn: 0.7350701\ttest: 0.7221397\tbest: 0.7221397 (375)\ttotal: 3m 59s\tremaining: 6m 36s\n",
      "376:\tlearn: 0.7350309\ttest: 0.7224561\tbest: 0.7224561 (376)\ttotal: 3m 59s\tremaining: 6m 36s\n",
      "377:\tlearn: 0.7349635\ttest: 0.7224561\tbest: 0.7224561 (376)\ttotal: 4m\tremaining: 6m 35s\n",
      "378:\tlearn: 0.7355134\ttest: 0.7221397\tbest: 0.7224561 (376)\ttotal: 4m 1s\tremaining: 6m 34s\n",
      "379:\tlearn: 0.7354852\ttest: 0.7224561\tbest: 0.7224561 (376)\ttotal: 4m 1s\tremaining: 6m 34s\n",
      "380:\tlearn: 0.7354852\ttest: 0.7227723\tbest: 0.7227723 (380)\ttotal: 4m 2s\tremaining: 6m 33s\n",
      "381:\tlearn: 0.7357265\ttest: 0.7227723\tbest: 0.7227723 (380)\ttotal: 4m 2s\tremaining: 6m 33s\n",
      "382:\tlearn: 0.7357265\ttest: 0.7230883\tbest: 0.7230883 (382)\ttotal: 4m 3s\tremaining: 6m 32s\n",
      "383:\tlearn: 0.7359003\ttest: 0.7230883\tbest: 0.7230883 (382)\ttotal: 4m 4s\tremaining: 6m 31s\n",
      "384:\tlearn: 0.7357767\ttest: 0.7232673\tbest: 0.7232673 (384)\ttotal: 4m 4s\tremaining: 6m 31s\n",
      "385:\tlearn: 0.7357767\ttest: 0.7232673\tbest: 0.7232673 (384)\ttotal: 4m 5s\tremaining: 6m 30s\n",
      "386:\tlearn: 0.7360852\ttest: 0.7230883\tbest: 0.7232673 (384)\ttotal: 4m 6s\tremaining: 6m 29s\n",
      "387:\tlearn: 0.7360852\ttest: 0.7230883\tbest: 0.7232673 (384)\ttotal: 4m 6s\tremaining: 6m 29s\n",
      "388:\tlearn: 0.7366516\ttest: 0.7232253\tbest: 0.7232673 (384)\ttotal: 4m 7s\tremaining: 6m 28s\n",
      "389:\tlearn: 0.7369878\ttest: 0.7239931\tbest: 0.7239931 (389)\ttotal: 4m 8s\tremaining: 6m 28s\n",
      "390:\tlearn: 0.7369878\ttest: 0.7239931\tbest: 0.7239931 (389)\ttotal: 4m 8s\tremaining: 6m 27s\n",
      "391:\tlearn: 0.7371894\ttest: 0.7243083\tbest: 0.7243083 (391)\ttotal: 4m 9s\tremaining: 6m 26s\n",
      "392:\tlearn: 0.7373238\ttest: 0.7243083\tbest: 0.7243083 (391)\ttotal: 4m 9s\tremaining: 6m 26s\n",
      "393:\tlearn: 0.7376430\ttest: 0.7243083\tbest: 0.7243083 (391)\ttotal: 4m 10s\tremaining: 6m 25s\n",
      "394:\tlearn: 0.7380294\ttest: 0.7243083\tbest: 0.7243083 (391)\ttotal: 4m 11s\tremaining: 6m 24s\n",
      "395:\tlearn: 0.7381636\ttest: 0.7243083\tbest: 0.7243083 (391)\ttotal: 4m 11s\tremaining: 6m 24s\n",
      "396:\tlearn: 0.7381636\ttest: 0.7249383\tbest: 0.7249383 (396)\ttotal: 4m 12s\tremaining: 6m 23s\n",
      "397:\tlearn: 0.7381636\ttest: 0.7249383\tbest: 0.7249383 (396)\ttotal: 4m 13s\tremaining: 6m 22s\n",
      "398:\tlearn: 0.7381636\ttest: 0.7255676\tbest: 0.7255676 (398)\ttotal: 4m 13s\tremaining: 6m 22s\n",
      "399:\tlearn: 0.7381636\ttest: 0.7252530\tbest: 0.7255676 (398)\ttotal: 4m 14s\tremaining: 6m 21s\n",
      "400:\tlearn: 0.7381636\ttest: 0.7252530\tbest: 0.7255676 (398)\ttotal: 4m 15s\tremaining: 6m 20s\n",
      "401:\tlearn: 0.7384043\ttest: 0.7255676\tbest: 0.7255676 (398)\ttotal: 4m 15s\tremaining: 6m 20s\n",
      "402:\tlearn: 0.7387119\ttest: 0.7255676\tbest: 0.7255676 (398)\ttotal: 4m 16s\tremaining: 6m 19s\n",
      "403:\tlearn: 0.7389131\ttest: 0.7255676\tbest: 0.7255676 (398)\ttotal: 4m 16s\tremaining: 6m 19s\n",
      "404:\tlearn: 0.7390472\ttest: 0.7261963\tbest: 0.7261963 (404)\ttotal: 4m 17s\tremaining: 6m 18s\n",
      "405:\tlearn: 0.7393153\ttest: 0.7260173\tbest: 0.7261963 (404)\ttotal: 4m 18s\tremaining: 6m 17s\n",
      "406:\tlearn: 0.7396226\ttest: 0.7260173\tbest: 0.7261963 (404)\ttotal: 4m 18s\tremaining: 6m 17s\n",
      "407:\tlearn: 0.7400127\ttest: 0.7257030\tbest: 0.7261963 (404)\ttotal: 4m 19s\tremaining: 6m 16s\n",
      "408:\tlearn: 0.7400127\ttest: 0.7257030\tbest: 0.7261963 (404)\ttotal: 4m 20s\tremaining: 6m 15s\n",
      "409:\tlearn: 0.7400797\ttest: 0.7257030\tbest: 0.7261963 (404)\ttotal: 4m 20s\tremaining: 6m 15s\n",
      "410:\tlearn: 0.7401583\ttest: 0.7257030\tbest: 0.7261963 (404)\ttotal: 4m 21s\tremaining: 6m 14s\n",
      "411:\tlearn: 0.7403984\ttest: 0.7255240\tbest: 0.7261963 (404)\ttotal: 4m 22s\tremaining: 6m 13s\n",
      "412:\tlearn: 0.7403315\ttest: 0.7257030\tbest: 0.7261963 (404)\ttotal: 4m 22s\tremaining: 6m 13s\n",
      "413:\tlearn: 0.7403984\ttest: 0.7260173\tbest: 0.7261963 (404)\ttotal: 4m 23s\tremaining: 6m 12s\n",
      "414:\tlearn: 0.7404653\ttest: 0.7258383\tbest: 0.7261963 (404)\ttotal: 4m 23s\tremaining: 6m 12s\n",
      "415:\tlearn: 0.7404653\ttest: 0.7258383\tbest: 0.7261963 (404)\ttotal: 4m 24s\tremaining: 6m 11s\n",
      "416:\tlearn: 0.7405046\ttest: 0.7256594\tbest: 0.7261963 (404)\ttotal: 4m 25s\tremaining: 6m 10s\n",
      "417:\tlearn: 0.7404495\ttest: 0.7254805\tbest: 0.7261963 (404)\ttotal: 4m 25s\tremaining: 6m 10s\n",
      "418:\tlearn: 0.7405164\ttest: 0.7254805\tbest: 0.7261963 (404)\ttotal: 4m 26s\tremaining: 6m 9s\n",
      "419:\tlearn: 0.7405833\ttest: 0.7254805\tbest: 0.7261963 (404)\ttotal: 4m 27s\tremaining: 6m 8s\n",
      "420:\tlearn: 0.7406384\ttest: 0.7254805\tbest: 0.7261963 (404)\ttotal: 4m 27s\tremaining: 6m 8s\n",
      "421:\tlearn: 0.7406660\ttest: 0.7254805\tbest: 0.7261963 (404)\ttotal: 4m 28s\tremaining: 6m 7s\n",
      "422:\tlearn: 0.7407879\ttest: 0.7253018\tbest: 0.7261963 (404)\ttotal: 4m 28s\tremaining: 6m 6s\n",
      "423:\tlearn: 0.7406424\ttest: 0.7256594\tbest: 0.7261963 (404)\ttotal: 4m 29s\tremaining: 6m 6s\n",
      "424:\tlearn: 0.7407093\ttest: 0.7256594\tbest: 0.7261963 (404)\ttotal: 4m 30s\tremaining: 6m 5s\n",
      "425:\tlearn: 0.7411103\ttest: 0.7261523\tbest: 0.7261963 (404)\ttotal: 4m 30s\tremaining: 6m 4s\n",
      "426:\tlearn: 0.7411771\ttest: 0.7261523\tbest: 0.7261963 (404)\ttotal: 4m 31s\tremaining: 6m 4s\n",
      "427:\tlearn: 0.7411771\ttest: 0.7261523\tbest: 0.7261963 (404)\ttotal: 4m 32s\tremaining: 6m 3s\n",
      "428:\tlearn: 0.7414443\ttest: 0.7261523\tbest: 0.7261963 (404)\ttotal: 4m 32s\tremaining: 6m 3s\n",
      "429:\tlearn: 0.7415110\ttest: 0.7261523\tbest: 0.7261963 (404)\ttotal: 4m 33s\tremaining: 6m 2s\n",
      "430:\tlearn: 0.7414598\ttest: 0.7264662\tbest: 0.7264662 (430)\ttotal: 4m 34s\tremaining: 6m 1s\n",
      "431:\tlearn: 0.7414991\ttest: 0.7262873\tbest: 0.7264662 (430)\ttotal: 4m 34s\tremaining: 6m 1s\n",
      "432:\tlearn: 0.7417268\ttest: 0.7266453\tbest: 0.7266453 (432)\ttotal: 4m 35s\tremaining: 6m\n",
      "433:\tlearn: 0.7419543\ttest: 0.7269591\tbest: 0.7269591 (433)\ttotal: 4m 35s\tremaining: 5m 59s\n",
      "434:\tlearn: 0.7421664\ttest: 0.7271383\tbest: 0.7271383 (434)\ttotal: 4m 36s\tremaining: 5m 59s\n",
      "435:\tlearn: 0.7421664\ttest: 0.7271383\tbest: 0.7271383 (434)\ttotal: 4m 37s\tremaining: 5m 58s\n",
      "436:\tlearn: 0.7424331\ttest: 0.7271383\tbest: 0.7271383 (434)\ttotal: 4m 37s\tremaining: 5m 57s\n",
      "437:\tlearn: 0.7428057\ttest: 0.7271383\tbest: 0.7271383 (434)\ttotal: 4m 38s\tremaining: 5m 57s\n",
      "438:\tlearn: 0.7428057\ttest: 0.7269591\tbest: 0.7271383 (434)\ttotal: 4m 39s\tremaining: 5m 56s\n",
      "439:\tlearn: 0.7429783\ttest: 0.7269591\tbest: 0.7271383 (434)\ttotal: 4m 39s\tremaining: 5m 56s\n",
      "440:\tlearn: 0.7431115\ttest: 0.7272727\tbest: 0.7272727 (440)\ttotal: 4m 40s\tremaining: 5m 55s\n",
      "441:\tlearn: 0.7432447\ttest: 0.7272727\tbest: 0.7272727 (440)\ttotal: 4m 41s\tremaining: 5m 54s\n",
      "442:\tlearn: 0.7433778\ttest: 0.7272727\tbest: 0.7272727 (440)\ttotal: 4m 41s\tremaining: 5m 54s\n",
      "443:\tlearn: 0.7434050\ttest: 0.7272727\tbest: 0.7272727 (440)\ttotal: 4m 42s\tremaining: 5m 53s\n",
      "444:\tlearn: 0.7435381\ttest: 0.7272727\tbest: 0.7272727 (440)\ttotal: 4m 42s\tremaining: 5m 52s\n",
      "445:\tlearn: 0.7436984\ttest: 0.7272727\tbest: 0.7272727 (440)\ttotal: 4m 43s\tremaining: 5m 52s\n",
      "446:\tlearn: 0.7440580\ttest: 0.7267800\tbest: 0.7272727 (440)\ttotal: 4m 44s\tremaining: 5m 51s\n",
      "447:\tlearn: 0.7440580\ttest: 0.7267800\tbest: 0.7272727 (440)\ttotal: 4m 44s\tremaining: 5m 50s\n",
      "448:\tlearn: 0.7440580\ttest: 0.7267800\tbest: 0.7272727 (440)\ttotal: 4m 45s\tremaining: 5m 50s\n",
      "449:\tlearn: 0.7441787\ttest: 0.7264221\tbest: 0.7272727 (440)\ttotal: 4m 46s\tremaining: 5m 49s\n",
      "450:\tlearn: 0.7442845\ttest: 0.7264221\tbest: 0.7272727 (440)\ttotal: 4m 46s\tremaining: 5m 49s\n",
      "451:\tlearn: 0.7442845\ttest: 0.7264221\tbest: 0.7272727 (440)\ttotal: 4m 47s\tremaining: 5m 48s\n",
      "452:\tlearn: 0.7447349\ttest: 0.7277203\tbest: 0.7277203 (452)\ttotal: 4m 48s\tremaining: 5m 47s\n",
      "453:\tlearn: 0.7446955\ttest: 0.7278543\tbest: 0.7278543 (453)\ttotal: 4m 48s\tremaining: 5m 47s\n",
      "454:\tlearn: 0.7446561\ttest: 0.7275412\tbest: 0.7278543 (453)\ttotal: 4m 49s\tremaining: 5m 46s\n",
      "455:\tlearn: 0.7446561\ttest: 0.7275412\tbest: 0.7278543 (453)\ttotal: 4m 49s\tremaining: 5m 45s\n",
      "456:\tlearn: 0.7447225\ttest: 0.7275412\tbest: 0.7278543 (453)\ttotal: 4m 50s\tremaining: 5m 45s\n",
      "457:\tlearn: 0.7449487\ttest: 0.7270490\tbest: 0.7278543 (453)\ttotal: 4m 51s\tremaining: 5m 44s\n",
      "458:\tlearn: 0.7451478\ttest: 0.7270490\tbest: 0.7278543 (453)\ttotal: 4m 51s\tremaining: 5m 43s\n",
      "459:\tlearn: 0.7452536\ttest: 0.7270490\tbest: 0.7278543 (453)\ttotal: 4m 52s\tremaining: 5m 43s\n",
      "460:\tlearn: 0.7452536\ttest: 0.7274070\tbest: 0.7278543 (453)\ttotal: 4m 53s\tremaining: 5m 42s\n",
      "461:\tlearn: 0.7454920\ttest: 0.7274070\tbest: 0.7278543 (453)\ttotal: 4m 53s\tremaining: 5m 41s\n",
      "462:\tlearn: 0.7453594\ttest: 0.7272280\tbest: 0.7278543 (453)\ttotal: 4m 54s\tremaining: 5m 41s\n",
      "463:\tlearn: 0.7453594\ttest: 0.7272280\tbest: 0.7278543 (453)\ttotal: 4m 54s\tremaining: 5m 40s\n",
      "464:\tlearn: 0.7456910\ttest: 0.7272280\tbest: 0.7278543 (453)\ttotal: 4m 55s\tremaining: 5m 40s\n",
      "465:\tlearn: 0.7456910\ttest: 0.7272280\tbest: 0.7278543 (453)\ttotal: 4m 56s\tremaining: 5m 39s\n",
      "466:\tlearn: 0.7459688\ttest: 0.7274070\tbest: 0.7278543 (453)\ttotal: 4m 56s\tremaining: 5m 38s\n",
      "467:\tlearn: 0.7460351\ttest: 0.7270936\tbest: 0.7278543 (453)\ttotal: 4m 57s\tremaining: 5m 38s\n",
      "468:\tlearn: 0.7465258\ttest: 0.7267356\tbest: 0.7278543 (453)\ttotal: 4m 58s\tremaining: 5m 37s\n",
      "469:\tlearn: 0.7463806\ttest: 0.7265567\tbest: 0.7278543 (453)\ttotal: 4m 58s\tremaining: 5m 36s\n",
      "470:\tlearn: 0.7463806\ttest: 0.7265567\tbest: 0.7278543 (453)\ttotal: 4m 59s\tremaining: 5m 36s\n",
      "471:\tlearn: 0.7464610\ttest: 0.7261084\tbest: 0.7278543 (453)\ttotal: 4m 59s\tremaining: 5m 35s\n",
      "472:\tlearn: 0.7465934\ttest: 0.7261084\tbest: 0.7278543 (453)\ttotal: 5m\tremaining: 5m 34s\n",
      "473:\tlearn: 0.7467652\ttest: 0.7261084\tbest: 0.7278543 (453)\ttotal: 5m 1s\tremaining: 5m 34s\n",
      "474:\tlearn: 0.7470032\ttest: 0.7270490\tbest: 0.7278543 (453)\ttotal: 5m 1s\tremaining: 5m 33s\n",
      "475:\tlearn: 0.7472272\ttest: 0.7273622\tbest: 0.7278543 (453)\ttotal: 5m 2s\tremaining: 5m 33s\n",
      "476:\tlearn: 0.7472133\ttest: 0.7278995\tbest: 0.7278995 (476)\ttotal: 5m 3s\tremaining: 5m 32s\n",
      "477:\tlearn: 0.7472400\ttest: 0.7283465\tbest: 0.7283465 (477)\ttotal: 5m 3s\tremaining: 5m 31s\n",
      "478:\tlearn: 0.7472400\ttest: 0.7283465\tbest: 0.7283465 (477)\ttotal: 5m 4s\tremaining: 5m 31s\n",
      "479:\tlearn: 0.7472400\ttest: 0.7283465\tbest: 0.7283465 (477)\ttotal: 5m 5s\tremaining: 5m 30s\n",
      "480:\tlearn: 0.7473990\ttest: 0.7281673\tbest: 0.7283465 (477)\ttotal: 5m 5s\tremaining: 5m 29s\n",
      "481:\tlearn: 0.7480070\ttest: 0.7279882\tbest: 0.7283465 (477)\ttotal: 5m 6s\tremaining: 5m 29s\n",
      "482:\tlearn: 0.7479932\ttest: 0.7278092\tbest: 0.7283465 (477)\ttotal: 5m 7s\tremaining: 5m 28s\n",
      "483:\tlearn: 0.7479142\ttest: 0.7278092\tbest: 0.7283465 (477)\ttotal: 5m 7s\tremaining: 5m 28s\n",
      "484:\tlearn: 0.7479409\ttest: 0.7281219\tbest: 0.7283465 (477)\ttotal: 5m 8s\tremaining: 5m 27s\n",
      "485:\tlearn: 0.7479142\ttest: 0.7286136\tbest: 0.7286136 (485)\ttotal: 5m 8s\tremaining: 5m 26s\n",
      "486:\tlearn: 0.7486146\ttest: 0.7287927\tbest: 0.7287927 (486)\ttotal: 5m 9s\tremaining: 5m 26s\n",
      "487:\tlearn: 0.7489977\ttest: 0.7286593\tbest: 0.7287927 (486)\ttotal: 5m 10s\tremaining: 5m 25s\n",
      "488:\tlearn: 0.7494994\ttest: 0.7289720\tbest: 0.7289720 (488)\ttotal: 5m 10s\tremaining: 5m 24s\n",
      "489:\tlearn: 0.7496971\ttest: 0.7289720\tbest: 0.7289720 (488)\ttotal: 5m 11s\tremaining: 5m 24s\n",
      "490:\tlearn: 0.7500395\ttest: 0.7295969\tbest: 0.7295969 (490)\ttotal: 5m 12s\tremaining: 5m 23s\n",
      "491:\tlearn: 0.7500132\ttest: 0.7293713\tbest: 0.7295969 (490)\ttotal: 5m 12s\tremaining: 5m 22s\n",
      "492:\tlearn: 0.7500527\ttest: 0.7290592\tbest: 0.7295969 (490)\ttotal: 5m 13s\tremaining: 5m 22s\n",
      "493:\tlearn: 0.7501844\ttest: 0.7293713\tbest: 0.7295969 (490)\ttotal: 5m 14s\tremaining: 5m 21s\n",
      "494:\tlearn: 0.7502502\ttest: 0.7293713\tbest: 0.7295969 (490)\ttotal: 5m 14s\tremaining: 5m 21s\n",
      "495:\tlearn: 0.7503556\ttest: 0.7293713\tbest: 0.7295969 (490)\ttotal: 5m 15s\tremaining: 5m 20s\n",
      "496:\tlearn: 0.7502501\ttest: 0.7296833\tbest: 0.7296833 (496)\ttotal: 5m 16s\tremaining: 5m 19s\n",
      "497:\tlearn: 0.7502501\ttest: 0.7296833\tbest: 0.7296833 (496)\ttotal: 5m 16s\tremaining: 5m 19s\n",
      "498:\tlearn: 0.7508026\ttest: 0.7298160\tbest: 0.7298160 (498)\ttotal: 5m 17s\tremaining: 5m 18s\n",
      "499:\tlearn: 0.7509341\ttest: 0.7295042\tbest: 0.7298160 (498)\ttotal: 5m 17s\tremaining: 5m 17s\n",
      "500:\tlearn: 0.7511707\ttest: 0.7296833\tbest: 0.7298160 (498)\ttotal: 5m 18s\tremaining: 5m 17s\n",
      "501:\tlearn: 0.7511312\ttest: 0.7296833\tbest: 0.7298160 (498)\ttotal: 5m 19s\tremaining: 5m 16s\n",
      "502:\tlearn: 0.7514731\ttest: 0.7293713\tbest: 0.7298160 (498)\ttotal: 5m 19s\tremaining: 5m 16s\n",
      "503:\tlearn: 0.7516440\ttest: 0.7295505\tbest: 0.7298160 (498)\ttotal: 5m 20s\tremaining: 5m 15s\n",
      "504:\tlearn: 0.7517096\ttest: 0.7295505\tbest: 0.7298160 (498)\ttotal: 5m 21s\tremaining: 5m 14s\n",
      "505:\tlearn: 0.7520118\ttest: 0.7295505\tbest: 0.7298160 (498)\ttotal: 5m 21s\tremaining: 5m 14s\n",
      "506:\tlearn: 0.7517753\ttest: 0.7295505\tbest: 0.7298160 (498)\ttotal: 5m 22s\tremaining: 5m 13s\n",
      "507:\tlearn: 0.7519722\ttest: 0.7295505\tbest: 0.7298160 (498)\ttotal: 5m 23s\tremaining: 5m 13s\n",
      "508:\tlearn: 0.7519722\ttest: 0.7295505\tbest: 0.7298160 (498)\ttotal: 5m 23s\tremaining: 5m 12s\n",
      "509:\tlearn: 0.7520118\ttest: 0.7298625\tbest: 0.7298625 (509)\ttotal: 5m 24s\tremaining: 5m 11s\n",
      "510:\tlearn: 0.7520118\ttest: 0.7298625\tbest: 0.7298625 (509)\ttotal: 5m 25s\tremaining: 5m 11s\n",
      "511:\tlearn: 0.7522743\ttest: 0.7304860\tbest: 0.7304860 (511)\ttotal: 5m 25s\tremaining: 5m 10s\n",
      "512:\tlearn: 0.7522087\ttest: 0.7304860\tbest: 0.7304860 (511)\ttotal: 5m 26s\tremaining: 5m 9s\n",
      "513:\tlearn: 0.7521430\ttest: 0.7304860\tbest: 0.7304860 (511)\ttotal: 5m 27s\tremaining: 5m 9s\n",
      "514:\tlearn: 0.7522347\ttest: 0.7304860\tbest: 0.7304860 (511)\ttotal: 5m 27s\tremaining: 5m 8s\n",
      "515:\tlearn: 0.7526407\ttest: 0.7304860\tbest: 0.7304860 (511)\ttotal: 5m 28s\tremaining: 5m 7s\n",
      "516:\tlearn: 0.7527718\ttest: 0.7304860\tbest: 0.7304860 (511)\ttotal: 5m 28s\tremaining: 5m 7s\n",
      "517:\tlearn: 0.7529820\ttest: 0.7304860\tbest: 0.7304860 (511)\ttotal: 5m 29s\tremaining: 5m 6s\n",
      "518:\tlearn: 0.7529820\ttest: 0.7304860\tbest: 0.7304860 (511)\ttotal: 5m 30s\tremaining: 5m 6s\n",
      "519:\tlearn: 0.7530871\ttest: 0.7304860\tbest: 0.7304860 (511)\ttotal: 5m 30s\tremaining: 5m 5s\n",
      "520:\tlearn: 0.7531266\ttest: 0.7304860\tbest: 0.7304860 (511)\ttotal: 5m 31s\tremaining: 5m 4s\n",
      "521:\tlearn: 0.7530871\ttest: 0.7306654\tbest: 0.7306654 (521)\ttotal: 5m 32s\tremaining: 5m 4s\n",
      "522:\tlearn: 0.7530871\ttest: 0.7306654\tbest: 0.7306654 (521)\ttotal: 5m 32s\tremaining: 5m 3s\n",
      "523:\tlearn: 0.7530871\ttest: 0.7306654\tbest: 0.7306654 (521)\ttotal: 5m 33s\tremaining: 5m 2s\n",
      "524:\tlearn: 0.7534937\ttest: 0.7304860\tbest: 0.7306654 (521)\ttotal: 5m 33s\tremaining: 5m 2s\n",
      "525:\tlearn: 0.7535333\ttest: 0.7310615\tbest: 0.7310615 (525)\ttotal: 5m 34s\tremaining: 5m 1s\n",
      "526:\tlearn: 0.7535333\ttest: 0.7310615\tbest: 0.7310615 (525)\ttotal: 5m 35s\tremaining: 5m\n",
      "527:\tlearn: 0.7535333\ttest: 0.7310615\tbest: 0.7310615 (525)\ttotal: 5m 35s\tremaining: 5m\n",
      "528:\tlearn: 0.7537039\ttest: 0.7310615\tbest: 0.7310615 (525)\ttotal: 5m 36s\tremaining: 4m 59s\n",
      "529:\tlearn: 0.7537039\ttest: 0.7310615\tbest: 0.7310615 (525)\ttotal: 5m 37s\tremaining: 4m 58s\n",
      "530:\tlearn: 0.7537694\ttest: 0.7310615\tbest: 0.7310615 (525)\ttotal: 5m 37s\tremaining: 4m 58s\n",
      "531:\tlearn: 0.7537694\ttest: 0.7310615\tbest: 0.7310615 (525)\ttotal: 5m 38s\tremaining: 4m 57s\n",
      "532:\tlearn: 0.7540708\ttest: 0.7309296\tbest: 0.7310615 (525)\ttotal: 5m 39s\tremaining: 4m 57s\n",
      "533:\tlearn: 0.7538744\ttest: 0.7309296\tbest: 0.7310615 (525)\ttotal: 5m 39s\tremaining: 4m 56s\n",
      "534:\tlearn: 0.7538744\ttest: 0.7309296\tbest: 0.7310615 (525)\ttotal: 5m 40s\tremaining: 4m 55s\n",
      "535:\tlearn: 0.7537039\ttest: 0.7309296\tbest: 0.7310615 (525)\ttotal: 5m 40s\tremaining: 4m 55s\n",
      "536:\tlearn: 0.7535851\ttest: 0.7309296\tbest: 0.7310615 (525)\ttotal: 5m 41s\tremaining: 4m 54s\n",
      "537:\tlearn: 0.7535455\ttest: 0.7309296\tbest: 0.7310615 (525)\ttotal: 5m 42s\tremaining: 4m 53s\n",
      "538:\tlearn: 0.7535060\ttest: 0.7315519\tbest: 0.7315519 (538)\ttotal: 5m 42s\tremaining: 4m 53s\n",
      "539:\tlearn: 0.7536369\ttest: 0.7318627\tbest: 0.7318627 (539)\ttotal: 5m 43s\tremaining: 4m 52s\n",
      "540:\tlearn: 0.7538074\ttest: 0.7318627\tbest: 0.7318627 (539)\ttotal: 5m 44s\tremaining: 4m 51s\n",
      "541:\tlearn: 0.7539778\ttest: 0.7316834\tbest: 0.7318627 (539)\ttotal: 5m 44s\tremaining: 4m 51s\n",
      "542:\tlearn: 0.7540829\ttest: 0.7316834\tbest: 0.7318627 (539)\ttotal: 5m 45s\tremaining: 4m 50s\n",
      "543:\tlearn: 0.7541483\ttest: 0.7315519\tbest: 0.7318627 (539)\ttotal: 5m 45s\tremaining: 4m 50s\n",
      "544:\tlearn: 0.7544099\ttest: 0.7318627\tbest: 0.7318627 (539)\ttotal: 5m 46s\tremaining: 4m 49s\n",
      "545:\tlearn: 0.7544099\ttest: 0.7318627\tbest: 0.7318627 (539)\ttotal: 5m 47s\tremaining: 4m 48s\n",
      "546:\tlearn: 0.7545011\ttest: 0.7315042\tbest: 0.7318627 (539)\ttotal: 5m 47s\tremaining: 4m 48s\n",
      "547:\tlearn: 0.7546714\ttest: 0.7318148\tbest: 0.7318627 (539)\ttotal: 5m 48s\tremaining: 4m 47s\n",
      "548:\tlearn: 0.7546714\ttest: 0.7318148\tbest: 0.7318627 (539)\ttotal: 5m 49s\tremaining: 4m 46s\n",
      "549:\tlearn: 0.7546714\ttest: 0.7318148\tbest: 0.7318627 (539)\ttotal: 5m 49s\tremaining: 4m 46s\n",
      "550:\tlearn: 0.7546714\ttest: 0.7318148\tbest: 0.7318627 (539)\ttotal: 5m 50s\tremaining: 4m 45s\n",
      "551:\tlearn: 0.7546714\ttest: 0.7318148\tbest: 0.7318627 (539)\ttotal: 5m 51s\tremaining: 4m 44s\n",
      "552:\tlearn: 0.7547368\ttest: 0.7321254\tbest: 0.7321254 (552)\ttotal: 5m 51s\tremaining: 4m 44s\n",
      "553:\tlearn: 0.7547368\ttest: 0.7321254\tbest: 0.7321254 (552)\ttotal: 5m 52s\tremaining: 4m 43s\n",
      "554:\tlearn: 0.7547229\ttest: 0.7324357\tbest: 0.7324357 (554)\ttotal: 5m 53s\tremaining: 4m 43s\n",
      "555:\tlearn: 0.7547625\ttest: 0.7321254\tbest: 0.7324357 (554)\ttotal: 5m 53s\tremaining: 4m 42s\n",
      "556:\tlearn: 0.7547625\ttest: 0.7321254\tbest: 0.7324357 (554)\ttotal: 5m 54s\tremaining: 4m 41s\n",
      "557:\tlearn: 0.7554180\ttest: 0.7324357\tbest: 0.7324357 (554)\ttotal: 5m 54s\tremaining: 4m 41s\n",
      "558:\tlearn: 0.7552873\ttest: 0.7324357\tbest: 0.7324357 (554)\ttotal: 5m 55s\tremaining: 4m 40s\n",
      "559:\tlearn: 0.7554319\ttest: 0.7324357\tbest: 0.7324357 (554)\ttotal: 5m 56s\tremaining: 4m 39s\n",
      "560:\tlearn: 0.7556022\ttest: 0.7324357\tbest: 0.7324357 (554)\ttotal: 5m 56s\tremaining: 4m 39s\n",
      "561:\tlearn: 0.7561641\ttest: 0.7322565\tbest: 0.7324357 (554)\ttotal: 5m 57s\tremaining: 4m 38s\n",
      "562:\tlearn: 0.7561641\ttest: 0.7322565\tbest: 0.7324357 (554)\ttotal: 5m 58s\tremaining: 4m 37s\n",
      "563:\tlearn: 0.7561244\ttest: 0.7322565\tbest: 0.7324357 (554)\ttotal: 5m 58s\tremaining: 4m 37s\n",
      "564:\tlearn: 0.7560848\ttest: 0.7320773\tbest: 0.7324357 (554)\ttotal: 5m 59s\tremaining: 4m 36s\n",
      "565:\tlearn: 0.7560848\ttest: 0.7320773\tbest: 0.7324357 (554)\ttotal: 5m 59s\tremaining: 4m 36s\n",
      "566:\tlearn: 0.7561500\ttest: 0.7320773\tbest: 0.7324357 (554)\ttotal: 6m\tremaining: 4m 35s\n",
      "567:\tlearn: 0.7561500\ttest: 0.7320773\tbest: 0.7324357 (554)\ttotal: 6m 1s\tremaining: 4m 34s\n",
      "568:\tlearn: 0.7562153\ttest: 0.7320773\tbest: 0.7324357 (554)\ttotal: 6m 1s\tremaining: 4m 34s\n",
      "569:\tlearn: 0.7562153\ttest: 0.7320773\tbest: 0.7324357 (554)\ttotal: 6m 2s\tremaining: 4m 33s\n",
      "570:\tlearn: 0.7562153\ttest: 0.7320773\tbest: 0.7324357 (554)\ttotal: 6m 3s\tremaining: 4m 32s\n",
      "571:\tlearn: 0.7562549\ttest: 0.7320773\tbest: 0.7324357 (554)\ttotal: 6m 3s\tremaining: 4m 32s\n",
      "572:\tlearn: 0.7562549\ttest: 0.7320773\tbest: 0.7324357 (554)\ttotal: 6m 4s\tremaining: 4m 31s\n",
      "573:\tlearn: 0.7563343\ttest: 0.7317670\tbest: 0.7324357 (554)\ttotal: 6m 4s\tremaining: 4m 30s\n",
      "574:\tlearn: 0.7565044\ttest: 0.7317670\tbest: 0.7324357 (554)\ttotal: 6m 5s\tremaining: 4m 30s\n",
      "575:\tlearn: 0.7565441\ttest: 0.7320773\tbest: 0.7324357 (554)\ttotal: 6m 6s\tremaining: 4m 29s\n",
      "576:\tlearn: 0.7566093\ttest: 0.7320773\tbest: 0.7324357 (554)\ttotal: 6m 6s\tremaining: 4m 28s\n",
      "577:\tlearn: 0.7566745\ttest: 0.7317670\tbest: 0.7324357 (554)\ttotal: 6m 7s\tremaining: 4m 28s\n",
      "578:\tlearn: 0.7566745\ttest: 0.7317670\tbest: 0.7324357 (554)\ttotal: 6m 8s\tremaining: 4m 27s\n",
      "579:\tlearn: 0.7566745\ttest: 0.7317670\tbest: 0.7324357 (554)\ttotal: 6m 8s\tremaining: 4m 27s\n",
      "580:\tlearn: 0.7566348\ttest: 0.7317670\tbest: 0.7324357 (554)\ttotal: 6m 9s\tremaining: 4m 26s\n",
      "581:\tlearn: 0.7566348\ttest: 0.7317670\tbest: 0.7324357 (554)\ttotal: 6m 10s\tremaining: 4m 25s\n",
      "582:\tlearn: 0.7566348\ttest: 0.7317670\tbest: 0.7324357 (554)\ttotal: 6m 10s\tremaining: 4m 25s\n",
      "583:\tlearn: 0.7566348\ttest: 0.7317670\tbest: 0.7324357 (554)\ttotal: 6m 11s\tremaining: 4m 24s\n",
      "584:\tlearn: 0.7566348\ttest: 0.7317670\tbest: 0.7324357 (554)\ttotal: 6m 11s\tremaining: 4m 23s\n",
      "585:\tlearn: 0.7566348\ttest: 0.7317670\tbest: 0.7324357 (554)\ttotal: 6m 12s\tremaining: 4m 23s\n",
      "586:\tlearn: 0.7567001\ttest: 0.7317670\tbest: 0.7324357 (554)\ttotal: 6m 13s\tremaining: 4m 22s\n",
      "587:\tlearn: 0.7568956\ttest: 0.7325667\tbest: 0.7325667 (587)\ttotal: 6m 13s\tremaining: 4m 21s\n",
      "588:\tlearn: 0.7568956\ttest: 0.7325667\tbest: 0.7325667 (587)\ttotal: 6m 14s\tremaining: 4m 21s\n",
      "589:\tlearn: 0.7573121\ttest: 0.7331866\tbest: 0.7331866 (589)\ttotal: 6m 15s\tremaining: 4m 20s\n",
      "590:\tlearn: 0.7573121\ttest: 0.7331866\tbest: 0.7331866 (589)\ttotal: 6m 15s\tremaining: 4m 20s\n",
      "591:\tlearn: 0.7573121\ttest: 0.7331866\tbest: 0.7331866 (589)\ttotal: 6m 16s\tremaining: 4m 19s\n",
      "592:\tlearn: 0.7572469\ttest: 0.7328767\tbest: 0.7331866 (589)\ttotal: 6m 16s\tremaining: 4m 18s\n",
      "593:\tlearn: 0.7572469\ttest: 0.7328767\tbest: 0.7331866 (589)\ttotal: 6m 17s\tremaining: 4m 18s\n",
      "594:\tlearn: 0.7572866\ttest: 0.7331866\tbest: 0.7331866 (589)\ttotal: 6m 18s\tremaining: 4m 17s\n",
      "595:\tlearn: 0.7572866\ttest: 0.7331866\tbest: 0.7331866 (589)\ttotal: 6m 18s\tremaining: 4m 16s\n",
      "596:\tlearn: 0.7572866\ttest: 0.7331866\tbest: 0.7331866 (589)\ttotal: 6m 19s\tremaining: 4m 16s\n",
      "597:\tlearn: 0.7572866\ttest: 0.7331866\tbest: 0.7331866 (589)\ttotal: 6m 20s\tremaining: 4m 15s\n",
      "598:\tlearn: 0.7573772\ttest: 0.7328767\tbest: 0.7331866 (589)\ttotal: 6m 20s\tremaining: 4m 14s\n",
      "599:\tlearn: 0.7575472\ttest: 0.7327460\tbest: 0.7331866 (589)\ttotal: 6m 21s\tremaining: 4m 14s\n",
      "600:\tlearn: 0.7575472\ttest: 0.7327460\tbest: 0.7331866 (589)\ttotal: 6m 22s\tremaining: 4m 13s\n",
      "601:\tlearn: 0.7575186\ttest: 0.7331866\tbest: 0.7331866 (589)\ttotal: 6m 22s\tremaining: 4m 12s\n",
      "602:\tlearn: 0.7575583\ttest: 0.7331866\tbest: 0.7331866 (589)\ttotal: 6m 23s\tremaining: 4m 12s\n",
      "603:\tlearn: 0.7575583\ttest: 0.7331866\tbest: 0.7331866 (589)\ttotal: 6m 23s\tremaining: 4m 11s\n",
      "604:\tlearn: 0.7575583\ttest: 0.7331866\tbest: 0.7331866 (589)\ttotal: 6m 24s\tremaining: 4m 11s\n",
      "605:\tlearn: 0.7575583\ttest: 0.7331866\tbest: 0.7331866 (589)\ttotal: 6m 25s\tremaining: 4m 10s\n",
      "606:\tlearn: 0.7575583\ttest: 0.7331866\tbest: 0.7331866 (589)\ttotal: 6m 25s\tremaining: 4m 9s\n",
      "607:\tlearn: 0.7576885\ttest: 0.7331866\tbest: 0.7331866 (589)\ttotal: 6m 26s\tremaining: 4m 9s\n",
      "608:\tlearn: 0.7576488\ttest: 0.7334963\tbest: 0.7334963 (608)\ttotal: 6m 27s\tremaining: 4m 8s\n",
      "609:\tlearn: 0.7575837\ttest: 0.7334963\tbest: 0.7334963 (608)\ttotal: 6m 27s\tremaining: 4m 7s\n",
      "610:\tlearn: 0.7578440\ttest: 0.7334963\tbest: 0.7334963 (608)\ttotal: 6m 28s\tremaining: 4m 7s\n",
      "611:\tlearn: 0.7581042\ttest: 0.7331866\tbest: 0.7334963 (608)\ttotal: 6m 28s\tremaining: 4m 6s\n",
      "612:\tlearn: 0.7582487\ttest: 0.7336757\tbest: 0.7336757 (612)\ttotal: 6m 29s\tremaining: 4m 5s\n",
      "613:\tlearn: 0.7582487\ttest: 0.7336757\tbest: 0.7336757 (612)\ttotal: 6m 30s\tremaining: 4m 5s\n",
      "614:\tlearn: 0.7583137\ttest: 0.7338552\tbest: 0.7338552 (614)\ttotal: 6m 30s\tremaining: 4m 4s\n",
      "615:\tlearn: 0.7583137\ttest: 0.7338552\tbest: 0.7338552 (614)\ttotal: 6m 31s\tremaining: 4m 4s\n",
      "616:\tlearn: 0.7583137\ttest: 0.7338552\tbest: 0.7338552 (614)\ttotal: 6m 32s\tremaining: 4m 3s\n",
      "617:\tlearn: 0.7581186\ttest: 0.7336757\tbest: 0.7338552 (614)\ttotal: 6m 32s\tremaining: 4m 2s\n",
      "618:\tlearn: 0.7581836\ttest: 0.7336757\tbest: 0.7338552 (614)\ttotal: 6m 33s\tremaining: 4m 2s\n",
      "619:\tlearn: 0.7581836\ttest: 0.7336757\tbest: 0.7338552 (614)\ttotal: 6m 34s\tremaining: 4m 1s\n",
      "620:\tlearn: 0.7583931\ttest: 0.7336757\tbest: 0.7338552 (614)\ttotal: 6m 34s\tremaining: 4m\n",
      "621:\tlearn: 0.7583931\ttest: 0.7336757\tbest: 0.7338552 (614)\ttotal: 6m 35s\tremaining: 4m\n",
      "622:\tlearn: 0.7584582\ttest: 0.7336757\tbest: 0.7338552 (614)\ttotal: 6m 35s\tremaining: 3m 59s\n",
      "623:\tlearn: 0.7583931\ttest: 0.7336757\tbest: 0.7338552 (614)\ttotal: 6m 36s\tremaining: 3m 58s\n",
      "624:\tlearn: 0.7583931\ttest: 0.7336757\tbest: 0.7338552 (614)\ttotal: 6m 37s\tremaining: 3m 58s\n",
      "625:\tlearn: 0.7584979\ttest: 0.7336757\tbest: 0.7338552 (614)\ttotal: 6m 37s\tremaining: 3m 57s\n",
      "626:\tlearn: 0.7584582\ttest: 0.7336757\tbest: 0.7338552 (614)\ttotal: 6m 38s\tremaining: 3m 57s\n",
      "627:\tlearn: 0.7583931\ttest: 0.7341648\tbest: 0.7341648 (627)\ttotal: 6m 39s\tremaining: 3m 56s\n",
      "628:\tlearn: 0.7583931\ttest: 0.7341648\tbest: 0.7341648 (627)\ttotal: 6m 39s\tremaining: 3m 55s\n",
      "629:\tlearn: 0.7583931\ttest: 0.7341648\tbest: 0.7341648 (627)\ttotal: 6m 40s\tremaining: 3m 55s\n",
      "630:\tlearn: 0.7584329\ttest: 0.7343444\tbest: 0.7343444 (630)\ttotal: 6m 41s\tremaining: 3m 54s\n",
      "631:\tlearn: 0.7584329\ttest: 0.7343444\tbest: 0.7343444 (630)\ttotal: 6m 41s\tremaining: 3m 53s\n",
      "632:\tlearn: 0.7584329\ttest: 0.7343444\tbest: 0.7343444 (630)\ttotal: 6m 42s\tremaining: 3m 53s\n",
      "633:\tlearn: 0.7584329\ttest: 0.7343444\tbest: 0.7343444 (630)\ttotal: 6m 42s\tremaining: 3m 52s\n",
      "634:\tlearn: 0.7585376\ttest: 0.7343444\tbest: 0.7343444 (630)\ttotal: 6m 43s\tremaining: 3m 51s\n",
      "635:\tlearn: 0.7585376\ttest: 0.7343444\tbest: 0.7343444 (630)\ttotal: 6m 44s\tremaining: 3m 51s\n",
      "636:\tlearn: 0.7583822\ttest: 0.7343444\tbest: 0.7343444 (630)\ttotal: 6m 44s\tremaining: 3m 50s\n",
      "637:\tlearn: 0.7583822\ttest: 0.7343444\tbest: 0.7343444 (630)\ttotal: 6m 45s\tremaining: 3m 50s\n",
      "638:\tlearn: 0.7583822\ttest: 0.7343444\tbest: 0.7343444 (630)\ttotal: 6m 46s\tremaining: 3m 49s\n",
      "639:\tlearn: 0.7583822\ttest: 0.7343444\tbest: 0.7343444 (630)\ttotal: 6m 46s\tremaining: 3m 48s\n",
      "640:\tlearn: 0.7584726\ttest: 0.7346539\tbest: 0.7346539 (640)\ttotal: 6m 47s\tremaining: 3m 48s\n",
      "641:\tlearn: 0.7584726\ttest: 0.7346539\tbest: 0.7346539 (640)\ttotal: 6m 47s\tremaining: 3m 47s\n",
      "642:\tlearn: 0.7587471\ttest: 0.7346539\tbest: 0.7346539 (640)\ttotal: 6m 48s\tremaining: 3m 46s\n",
      "643:\tlearn: 0.7586821\ttest: 0.7346539\tbest: 0.7346539 (640)\ttotal: 6m 49s\tremaining: 3m 46s\n",
      "644:\tlearn: 0.7587471\ttest: 0.7346539\tbest: 0.7346539 (640)\ttotal: 6m 49s\tremaining: 3m 45s\n",
      "645:\tlearn: 0.7587471\ttest: 0.7346539\tbest: 0.7346539 (640)\ttotal: 6m 50s\tremaining: 3m 44s\n",
      "646:\tlearn: 0.7587471\ttest: 0.7346539\tbest: 0.7346539 (640)\ttotal: 6m 51s\tremaining: 3m 44s\n",
      "647:\tlearn: 0.7587471\ttest: 0.7346539\tbest: 0.7346539 (640)\ttotal: 6m 51s\tremaining: 3m 43s\n",
      "648:\tlearn: 0.7587471\ttest: 0.7346539\tbest: 0.7346539 (640)\ttotal: 6m 52s\tremaining: 3m 43s\n",
      "649:\tlearn: 0.7587977\ttest: 0.7346041\tbest: 0.7346539 (640)\ttotal: 6m 52s\tremaining: 3m 42s\n",
      "650:\tlearn: 0.7587977\ttest: 0.7346041\tbest: 0.7346539 (640)\ttotal: 6m 53s\tremaining: 3m 41s\n",
      "651:\tlearn: 0.7587977\ttest: 0.7346041\tbest: 0.7346539 (640)\ttotal: 6m 54s\tremaining: 3m 41s\n",
      "652:\tlearn: 0.7587977\ttest: 0.7346041\tbest: 0.7346539 (640)\ttotal: 6m 54s\tremaining: 3m 40s\n",
      "653:\tlearn: 0.7587977\ttest: 0.7346041\tbest: 0.7346539 (640)\ttotal: 6m 55s\tremaining: 3m 39s\n",
      "654:\tlearn: 0.7587977\ttest: 0.7346041\tbest: 0.7346539 (640)\ttotal: 6m 56s\tremaining: 3m 39s\n",
      "655:\tlearn: 0.7587977\ttest: 0.7346041\tbest: 0.7346539 (640)\ttotal: 6m 56s\tremaining: 3m 38s\n",
      "656:\tlearn: 0.7587977\ttest: 0.7346041\tbest: 0.7346539 (640)\ttotal: 6m 57s\tremaining: 3m 37s\n",
      "657:\tlearn: 0.7587977\ttest: 0.7346041\tbest: 0.7346539 (640)\ttotal: 6m 57s\tremaining: 3m 37s\n",
      "658:\tlearn: 0.7587977\ttest: 0.7347837\tbest: 0.7347837 (658)\ttotal: 6m 58s\tremaining: 3m 36s\n",
      "659:\tlearn: 0.7588229\ttest: 0.7347837\tbest: 0.7347837 (658)\ttotal: 6m 59s\tremaining: 3m 35s\n",
      "660:\tlearn: 0.7588229\ttest: 0.7347837\tbest: 0.7347837 (658)\ttotal: 6m 59s\tremaining: 3m 35s\n",
      "661:\tlearn: 0.7588229\ttest: 0.7347837\tbest: 0.7347837 (658)\ttotal: 7m\tremaining: 3m 34s\n",
      "662:\tlearn: 0.7588229\ttest: 0.7347837\tbest: 0.7347837 (658)\ttotal: 7m 1s\tremaining: 3m 34s\n",
      "663:\tlearn: 0.7588229\ttest: 0.7347837\tbest: 0.7347837 (658)\ttotal: 7m 1s\tremaining: 3m 33s\n",
      "664:\tlearn: 0.7589131\ttest: 0.7346041\tbest: 0.7347837 (658)\ttotal: 7m 2s\tremaining: 3m 32s\n",
      "665:\tlearn: 0.7591080\ttest: 0.7349133\tbest: 0.7349133 (665)\ttotal: 7m 2s\tremaining: 3m 32s\n",
      "666:\tlearn: 0.7594075\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 3s\tremaining: 3m 31s\n",
      "667:\tlearn: 0.7594075\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 4s\tremaining: 3m 30s\n",
      "668:\tlearn: 0.7594831\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 4s\tremaining: 3m 30s\n",
      "669:\tlearn: 0.7594831\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 5s\tremaining: 3m 29s\n",
      "670:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 6s\tremaining: 3m 28s\n",
      "671:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 6s\tremaining: 3m 28s\n",
      "672:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 7s\tremaining: 3m 27s\n",
      "673:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 8s\tremaining: 3m 27s\n",
      "674:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 8s\tremaining: 3m 26s\n",
      "675:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 9s\tremaining: 3m 25s\n",
      "676:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 9s\tremaining: 3m 25s\n",
      "677:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 10s\tremaining: 3m 24s\n",
      "678:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 11s\tremaining: 3m 23s\n",
      "679:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 11s\tremaining: 3m 23s\n",
      "680:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 12s\tremaining: 3m 22s\n",
      "681:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 12s\tremaining: 3m 21s\n",
      "682:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 13s\tremaining: 3m 21s\n",
      "683:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 14s\tremaining: 3m 20s\n",
      "684:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 14s\tremaining: 3m 19s\n",
      "685:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 15s\tremaining: 3m 19s\n",
      "686:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 16s\tremaining: 3m 18s\n",
      "687:\tlearn: 0.7597175\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 16s\tremaining: 3m 18s\n",
      "688:\tlearn: 0.7598221\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 17s\tremaining: 3m 17s\n",
      "689:\tlearn: 0.7598221\ttest: 0.7361484\tbest: 0.7361484 (666)\ttotal: 7m 18s\tremaining: 3m 16s\n",
      "690:\tlearn: 0.7601611\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 18s\tremaining: 3m 16s\n",
      "691:\tlearn: 0.7601611\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 19s\tremaining: 3m 15s\n",
      "692:\tlearn: 0.7601611\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 19s\tremaining: 3m 14s\n",
      "693:\tlearn: 0.7600963\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 20s\tremaining: 3m 14s\n",
      "694:\tlearn: 0.7600963\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 21s\tremaining: 3m 13s\n",
      "695:\tlearn: 0.7600963\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 21s\tremaining: 3m 12s\n",
      "696:\tlearn: 0.7602260\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 22s\tremaining: 3m 12s\n",
      "697:\tlearn: 0.7601611\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 23s\tremaining: 3m 11s\n",
      "698:\tlearn: 0.7601611\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 23s\tremaining: 3m 11s\n",
      "699:\tlearn: 0.7601611\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 24s\tremaining: 3m 10s\n",
      "700:\tlearn: 0.7601611\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 24s\tremaining: 3m 9s\n",
      "701:\tlearn: 0.7601611\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 25s\tremaining: 3m 9s\n",
      "702:\tlearn: 0.7601611\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 26s\tremaining: 3m 8s\n",
      "703:\tlearn: 0.7601611\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 26s\tremaining: 3m 7s\n",
      "704:\tlearn: 0.7601611\ttest: 0.7368934\tbest: 0.7368934 (690)\ttotal: 7m 27s\tremaining: 3m 7s\n",
      "705:\tlearn: 0.7607195\ttest: 0.7376889\tbest: 0.7376889 (705)\ttotal: 7m 28s\tremaining: 3m 6s\n",
      "706:\tlearn: 0.7607195\ttest: 0.7376889\tbest: 0.7376889 (705)\ttotal: 7m 28s\tremaining: 3m 5s\n",
      "707:\tlearn: 0.7607195\ttest: 0.7376889\tbest: 0.7376889 (705)\ttotal: 7m 29s\tremaining: 3m 5s\n",
      "708:\tlearn: 0.7607843\ttest: 0.7376889\tbest: 0.7376889 (705)\ttotal: 7m 30s\tremaining: 3m 4s\n",
      "709:\tlearn: 0.7607843\ttest: 0.7376889\tbest: 0.7376889 (705)\ttotal: 7m 30s\tremaining: 3m 4s\n",
      "710:\tlearn: 0.7607843\ttest: 0.7376889\tbest: 0.7376889 (705)\ttotal: 7m 31s\tremaining: 3m 3s\n",
      "711:\tlearn: 0.7607843\ttest: 0.7376889\tbest: 0.7376889 (705)\ttotal: 7m 31s\tremaining: 3m 2s\n",
      "712:\tlearn: 0.7607843\ttest: 0.7376889\tbest: 0.7376889 (705)\ttotal: 7m 32s\tremaining: 3m 2s\n",
      "713:\tlearn: 0.7607843\ttest: 0.7376889\tbest: 0.7376889 (705)\ttotal: 7m 33s\tremaining: 3m 1s\n",
      "714:\tlearn: 0.7607843\ttest: 0.7376889\tbest: 0.7376889 (705)\ttotal: 7m 33s\tremaining: 3m\n",
      "715:\tlearn: 0.7607843\ttest: 0.7378688\tbest: 0.7378688 (715)\ttotal: 7m 34s\tremaining: 3m\n",
      "716:\tlearn: 0.7608741\ttest: 0.7378168\tbest: 0.7378688 (715)\ttotal: 7m 35s\tremaining: 2m 59s\n",
      "717:\tlearn: 0.7608741\ttest: 0.7378168\tbest: 0.7378688 (715)\ttotal: 7m 35s\tremaining: 2m 58s\n",
      "718:\tlearn: 0.7611082\ttest: 0.7378168\tbest: 0.7378688 (715)\ttotal: 7m 36s\tremaining: 2m 58s\n",
      "719:\tlearn: 0.7611730\ttest: 0.7379966\tbest: 0.7379966 (719)\ttotal: 7m 36s\tremaining: 2m 57s\n",
      "720:\tlearn: 0.7612026\ttest: 0.7381242\tbest: 0.7381242 (720)\ttotal: 7m 37s\tremaining: 2m 57s\n",
      "721:\tlearn: 0.7612026\ttest: 0.7381242\tbest: 0.7381242 (720)\ttotal: 7m 38s\tremaining: 2m 56s\n",
      "722:\tlearn: 0.7612026\ttest: 0.7381242\tbest: 0.7381242 (720)\ttotal: 7m 38s\tremaining: 2m 55s\n",
      "723:\tlearn: 0.7612026\ttest: 0.7381242\tbest: 0.7381242 (720)\ttotal: 7m 39s\tremaining: 2m 55s\n",
      "724:\tlearn: 0.7612026\ttest: 0.7381242\tbest: 0.7381242 (720)\ttotal: 7m 40s\tremaining: 2m 54s\n",
      "725:\tlearn: 0.7612026\ttest: 0.7381242\tbest: 0.7381242 (720)\ttotal: 7m 40s\tremaining: 2m 53s\n",
      "726:\tlearn: 0.7612026\ttest: 0.7381242\tbest: 0.7381242 (720)\ttotal: 7m 41s\tremaining: 2m 53s\n",
      "727:\tlearn: 0.7612026\ttest: 0.7381242\tbest: 0.7381242 (720)\ttotal: 7m 42s\tremaining: 2m 52s\n",
      "728:\tlearn: 0.7612026\ttest: 0.7381242\tbest: 0.7381242 (720)\ttotal: 7m 42s\tremaining: 2m 51s\n",
      "729:\tlearn: 0.7612026\ttest: 0.7381242\tbest: 0.7381242 (720)\ttotal: 7m 43s\tremaining: 2m 51s\n",
      "730:\tlearn: 0.7614866\ttest: 0.7384316\tbest: 0.7384316 (730)\ttotal: 7m 43s\tremaining: 2m 50s\n",
      "731:\tlearn: 0.7616161\ttest: 0.7384316\tbest: 0.7384316 (730)\ttotal: 7m 44s\tremaining: 2m 50s\n",
      "732:\tlearn: 0.7616161\ttest: 0.7384316\tbest: 0.7384316 (730)\ttotal: 7m 45s\tremaining: 2m 49s\n",
      "733:\tlearn: 0.7616161\ttest: 0.7386114\tbest: 0.7386114 (733)\ttotal: 7m 45s\tremaining: 2m 48s\n",
      "734:\tlearn: 0.7616161\ttest: 0.7386114\tbest: 0.7386114 (733)\ttotal: 7m 46s\tremaining: 2m 48s\n",
      "735:\tlearn: 0.7616161\ttest: 0.7386114\tbest: 0.7386114 (733)\ttotal: 7m 47s\tremaining: 2m 47s\n",
      "736:\tlearn: 0.7616161\ttest: 0.7386114\tbest: 0.7386114 (733)\ttotal: 7m 47s\tremaining: 2m 46s\n",
      "737:\tlearn: 0.7617555\ttest: 0.7389187\tbest: 0.7389187 (737)\ttotal: 7m 48s\tremaining: 2m 46s\n",
      "738:\tlearn: 0.7617555\ttest: 0.7389187\tbest: 0.7389187 (737)\ttotal: 7m 48s\tremaining: 2m 45s\n",
      "739:\tlearn: 0.7617555\ttest: 0.7389187\tbest: 0.7389187 (737)\ttotal: 7m 49s\tremaining: 2m 44s\n",
      "740:\tlearn: 0.7617555\ttest: 0.7389187\tbest: 0.7389187 (737)\ttotal: 7m 50s\tremaining: 2m 44s\n",
      "741:\tlearn: 0.7617555\ttest: 0.7386114\tbest: 0.7389187 (737)\ttotal: 7m 50s\tremaining: 2m 43s\n",
      "742:\tlearn: 0.7617555\ttest: 0.7386114\tbest: 0.7389187 (737)\ttotal: 7m 51s\tremaining: 2m 43s\n",
      "743:\tlearn: 0.7617306\ttest: 0.7386114\tbest: 0.7389187 (737)\ttotal: 7m 52s\tremaining: 2m 42s\n",
      "744:\tlearn: 0.7617306\ttest: 0.7386114\tbest: 0.7389187 (737)\ttotal: 7m 52s\tremaining: 2m 41s\n",
      "745:\tlearn: 0.7617306\ttest: 0.7386114\tbest: 0.7389187 (737)\ttotal: 7m 53s\tremaining: 2m 41s\n",
      "746:\tlearn: 0.7617306\ttest: 0.7386114\tbest: 0.7389187 (737)\ttotal: 7m 54s\tremaining: 2m 40s\n",
      "747:\tlearn: 0.7617306\ttest: 0.7386114\tbest: 0.7389187 (737)\ttotal: 7m 54s\tremaining: 2m 39s\n",
      "748:\tlearn: 0.7620789\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 7m 55s\tremaining: 2m 39s\n",
      "749:\tlearn: 0.7620789\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 7m 55s\tremaining: 2m 38s\n",
      "750:\tlearn: 0.7621833\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 7m 56s\tremaining: 2m 37s\n",
      "751:\tlearn: 0.7621833\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 7m 57s\tremaining: 2m 37s\n",
      "752:\tlearn: 0.7621833\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 7m 57s\tremaining: 2m 36s\n",
      "753:\tlearn: 0.7621833\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 7m 58s\tremaining: 2m 36s\n",
      "754:\tlearn: 0.7621833\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 7m 59s\tremaining: 2m 35s\n",
      "755:\tlearn: 0.7621833\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 7m 59s\tremaining: 2m 34s\n",
      "756:\tlearn: 0.7621833\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m\tremaining: 2m 34s\n",
      "757:\tlearn: 0.7621833\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m\tremaining: 2m 33s\n",
      "758:\tlearn: 0.7621833\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 1s\tremaining: 2m 32s\n",
      "759:\tlearn: 0.7621833\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 2s\tremaining: 2m 32s\n",
      "760:\tlearn: 0.7620789\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 2s\tremaining: 2m 31s\n",
      "761:\tlearn: 0.7620789\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 3s\tremaining: 2m 30s\n",
      "762:\tlearn: 0.7620789\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 4s\tremaining: 2m 30s\n",
      "763:\tlearn: 0.7620789\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 4s\tremaining: 2m 29s\n",
      "764:\tlearn: 0.7620789\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 5s\tremaining: 2m 29s\n",
      "765:\tlearn: 0.7620789\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 6s\tremaining: 2m 28s\n",
      "766:\tlearn: 0.7622082\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 6s\tremaining: 2m 27s\n",
      "767:\tlearn: 0.7622878\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 7s\tremaining: 2m 27s\n",
      "768:\tlearn: 0.7622878\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 7s\tremaining: 2m 26s\n",
      "769:\tlearn: 0.7622878\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 8s\tremaining: 2m 25s\n",
      "770:\tlearn: 0.7622878\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 9s\tremaining: 2m 25s\n",
      "771:\tlearn: 0.7622878\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 9s\tremaining: 2m 24s\n",
      "772:\tlearn: 0.7622878\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 10s\tremaining: 2m 24s\n",
      "773:\tlearn: 0.7622878\ttest: 0.7390987\tbest: 0.7390987 (748)\ttotal: 8m 11s\tremaining: 2m 23s\n",
      "774:\tlearn: 0.7625463\ttest: 0.7387914\tbest: 0.7390987 (748)\ttotal: 8m 11s\tremaining: 2m 22s\n",
      "775:\tlearn: 0.7628543\ttest: 0.7392788\tbest: 0.7392788 (775)\ttotal: 8m 12s\tremaining: 2m 22s\n",
      "776:\tlearn: 0.7628543\ttest: 0.7392788\tbest: 0.7392788 (775)\ttotal: 8m 12s\tremaining: 2m 21s\n",
      "777:\tlearn: 0.7634106\ttest: 0.7394589\tbest: 0.7394589 (777)\ttotal: 8m 13s\tremaining: 2m 20s\n",
      "778:\tlearn: 0.7633707\ttest: 0.7394589\tbest: 0.7394589 (777)\ttotal: 8m 14s\tremaining: 2m 20s\n",
      "779:\tlearn: 0.7633707\ttest: 0.7394589\tbest: 0.7394589 (777)\ttotal: 8m 14s\tremaining: 2m 19s\n",
      "780:\tlearn: 0.7634106\ttest: 0.7394589\tbest: 0.7394589 (777)\ttotal: 8m 15s\tremaining: 2m 18s\n",
      "781:\tlearn: 0.7634106\ttest: 0.7394589\tbest: 0.7394589 (777)\ttotal: 8m 16s\tremaining: 2m 18s\n",
      "782:\tlearn: 0.7632719\ttest: 0.7393319\tbest: 0.7394589 (777)\ttotal: 8m 16s\tremaining: 2m 17s\n",
      "783:\tlearn: 0.7632719\ttest: 0.7393319\tbest: 0.7394589 (777)\ttotal: 8m 17s\tremaining: 2m 17s\n",
      "784:\tlearn: 0.7632719\ttest: 0.7393319\tbest: 0.7394589 (777)\ttotal: 8m 17s\tremaining: 2m 16s\n",
      "785:\tlearn: 0.7632719\ttest: 0.7393319\tbest: 0.7394589 (777)\ttotal: 8m 18s\tremaining: 2m 15s\n",
      "786:\tlearn: 0.7632074\ttest: 0.7396392\tbest: 0.7396392 (786)\ttotal: 8m 19s\tremaining: 2m 15s\n",
      "787:\tlearn: 0.7632074\ttest: 0.7396392\tbest: 0.7396392 (786)\ttotal: 8m 19s\tremaining: 2m 14s\n",
      "788:\tlearn: 0.7635301\ttest: 0.7391516\tbest: 0.7396392 (786)\ttotal: 8m 20s\tremaining: 2m 13s\n",
      "789:\tlearn: 0.7635301\ttest: 0.7391516\tbest: 0.7396392 (786)\ttotal: 8m 21s\tremaining: 2m 13s\n",
      "790:\tlearn: 0.7635301\ttest: 0.7391516\tbest: 0.7396392 (786)\ttotal: 8m 21s\tremaining: 2m 12s\n",
      "791:\tlearn: 0.7635301\ttest: 0.7391516\tbest: 0.7396392 (786)\ttotal: 8m 22s\tremaining: 2m 11s\n",
      "792:\tlearn: 0.7635301\ttest: 0.7391516\tbest: 0.7396392 (786)\ttotal: 8m 23s\tremaining: 2m 11s\n",
      "793:\tlearn: 0.7635699\ttest: 0.7391516\tbest: 0.7396392 (786)\ttotal: 8m 23s\tremaining: 2m 10s\n",
      "794:\tlearn: 0.7635699\ttest: 0.7391516\tbest: 0.7396392 (786)\ttotal: 8m 24s\tremaining: 2m 10s\n",
      "795:\tlearn: 0.7642947\ttest: 0.7393319\tbest: 0.7396392 (786)\ttotal: 8m 24s\tremaining: 2m 9s\n",
      "796:\tlearn: 0.7642947\ttest: 0.7393319\tbest: 0.7396392 (786)\ttotal: 8m 25s\tremaining: 2m 8s\n",
      "797:\tlearn: 0.7644880\ttest: 0.7396392\tbest: 0.7396392 (786)\ttotal: 8m 26s\tremaining: 2m 8s\n",
      "798:\tlearn: 0.7644880\ttest: 0.7396392\tbest: 0.7396392 (786)\ttotal: 8m 26s\tremaining: 2m 7s\n",
      "799:\tlearn: 0.7645279\ttest: 0.7394589\tbest: 0.7396392 (786)\ttotal: 8m 27s\tremaining: 2m 6s\n",
      "800:\tlearn: 0.7646169\ttest: 0.7392788\tbest: 0.7396392 (786)\ttotal: 8m 28s\tremaining: 2m 6s\n",
      "801:\tlearn: 0.7646169\ttest: 0.7392788\tbest: 0.7396392 (786)\ttotal: 8m 28s\tremaining: 2m 5s\n",
      "802:\tlearn: 0.7646169\ttest: 0.7392788\tbest: 0.7396392 (786)\ttotal: 8m 29s\tremaining: 2m 4s\n",
      "803:\tlearn: 0.7648102\ttest: 0.7389715\tbest: 0.7396392 (786)\ttotal: 8m 30s\tremaining: 2m 4s\n",
      "804:\tlearn: 0.7648102\ttest: 0.7389715\tbest: 0.7396392 (786)\ttotal: 8m 30s\tremaining: 2m 3s\n",
      "805:\tlearn: 0.7648102\ttest: 0.7389715\tbest: 0.7396392 (786)\ttotal: 8m 31s\tremaining: 2m 3s\n",
      "806:\tlearn: 0.7650678\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 31s\tremaining: 2m 2s\n",
      "807:\tlearn: 0.7650678\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 32s\tremaining: 2m 1s\n",
      "808:\tlearn: 0.7650678\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 33s\tremaining: 2m 1s\n",
      "809:\tlearn: 0.7650678\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 33s\tremaining: 2m\n",
      "810:\tlearn: 0.7650678\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 34s\tremaining: 1m 59s\n",
      "811:\tlearn: 0.7650678\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 34s\tremaining: 1m 59s\n",
      "812:\tlearn: 0.7650678\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 35s\tremaining: 1m 58s\n",
      "813:\tlearn: 0.7651721\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 36s\tremaining: 1m 57s\n",
      "814:\tlearn: 0.7651721\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 36s\tremaining: 1m 57s\n",
      "815:\tlearn: 0.7651721\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 37s\tremaining: 1m 56s\n",
      "816:\tlearn: 0.7651721\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 38s\tremaining: 1m 56s\n",
      "817:\tlearn: 0.7651721\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 38s\tremaining: 1m 55s\n",
      "818:\tlearn: 0.7651721\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 39s\tremaining: 1m 54s\n",
      "819:\tlearn: 0.7651721\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 40s\tremaining: 1m 54s\n",
      "820:\tlearn: 0.7651721\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 40s\tremaining: 1m 53s\n",
      "821:\tlearn: 0.7651721\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 41s\tremaining: 1m 52s\n",
      "822:\tlearn: 0.7651721\ttest: 0.7398928\tbest: 0.7398928 (806)\ttotal: 8m 41s\tremaining: 1m 52s\n",
      "823:\tlearn: 0.7651721\ttest: 0.7395859\tbest: 0.7398928 (806)\ttotal: 8m 42s\tremaining: 1m 51s\n",
      "824:\tlearn: 0.7651721\ttest: 0.7395859\tbest: 0.7398928 (806)\ttotal: 8m 43s\tremaining: 1m 50s\n",
      "825:\tlearn: 0.7651721\ttest: 0.7395859\tbest: 0.7398928 (806)\ttotal: 8m 43s\tremaining: 1m 50s\n",
      "826:\tlearn: 0.7651721\ttest: 0.7397661\tbest: 0.7398928 (806)\ttotal: 8m 44s\tremaining: 1m 49s\n",
      "827:\tlearn: 0.7651721\ttest: 0.7397661\tbest: 0.7398928 (806)\ttotal: 8m 45s\tremaining: 1m 49s\n",
      "828:\tlearn: 0.7652120\ttest: 0.7395859\tbest: 0.7398928 (806)\ttotal: 8m 45s\tremaining: 1m 48s\n",
      "829:\tlearn: 0.7652120\ttest: 0.7395859\tbest: 0.7398928 (806)\ttotal: 8m 46s\tremaining: 1m 47s\n",
      "830:\tlearn: 0.7652120\ttest: 0.7395859\tbest: 0.7398928 (806)\ttotal: 8m 47s\tremaining: 1m 47s\n",
      "831:\tlearn: 0.7653407\ttest: 0.7395859\tbest: 0.7398928 (806)\ttotal: 8m 47s\tremaining: 1m 46s\n",
      "832:\tlearn: 0.7653407\ttest: 0.7395859\tbest: 0.7398928 (806)\ttotal: 8m 48s\tremaining: 1m 45s\n",
      "833:\tlearn: 0.7653407\ttest: 0.7395859\tbest: 0.7398928 (806)\ttotal: 8m 48s\tremaining: 1m 45s\n",
      "834:\tlearn: 0.7653407\ttest: 0.7395859\tbest: 0.7398928 (806)\ttotal: 8m 49s\tremaining: 1m 44s\n",
      "835:\tlearn: 0.7653407\ttest: 0.7395859\tbest: 0.7398928 (806)\ttotal: 8m 50s\tremaining: 1m 44s\n",
      "836:\tlearn: 0.7653407\ttest: 0.7395859\tbest: 0.7398928 (806)\ttotal: 8m 50s\tremaining: 1m 43s\n",
      "837:\tlearn: 0.7653407\ttest: 0.7395859\tbest: 0.7398928 (806)\ttotal: 8m 51s\tremaining: 1m 42s\n",
      "838:\tlearn: 0.7653407\ttest: 0.7395859\tbest: 0.7398928 (806)\ttotal: 8m 52s\tremaining: 1m 42s\n",
      "839:\tlearn: 0.7654450\ttest: 0.7394057\tbest: 0.7398928 (806)\ttotal: 8m 52s\tremaining: 1m 41s\n",
      "840:\tlearn: 0.7657024\ttest: 0.7389187\tbest: 0.7398928 (806)\ttotal: 8m 53s\tremaining: 1m 40s\n",
      "841:\tlearn: 0.7657024\ttest: 0.7389187\tbest: 0.7398928 (806)\ttotal: 8m 54s\tremaining: 1m 40s\n",
      "842:\tlearn: 0.7657024\ttest: 0.7389187\tbest: 0.7398928 (806)\ttotal: 8m 54s\tremaining: 1m 39s\n",
      "843:\tlearn: 0.7657024\ttest: 0.7389187\tbest: 0.7398928 (806)\ttotal: 8m 55s\tremaining: 1m 38s\n",
      "844:\tlearn: 0.7656380\ttest: 0.7389187\tbest: 0.7398928 (806)\ttotal: 8m 55s\tremaining: 1m 38s\n",
      "845:\tlearn: 0.7656380\ttest: 0.7389187\tbest: 0.7398928 (806)\ttotal: 8m 56s\tremaining: 1m 37s\n",
      "846:\tlearn: 0.7656380\ttest: 0.7389187\tbest: 0.7398928 (806)\ttotal: 8m 57s\tremaining: 1m 37s\n",
      "847:\tlearn: 0.7656380\ttest: 0.7389187\tbest: 0.7398928 (806)\ttotal: 8m 57s\tremaining: 1m 36s\n",
      "848:\tlearn: 0.7656380\ttest: 0.7392257\tbest: 0.7398928 (806)\ttotal: 8m 58s\tremaining: 1m 35s\n",
      "849:\tlearn: 0.7660084\ttest: 0.7389187\tbest: 0.7398928 (806)\ttotal: 8m 59s\tremaining: 1m 35s\n",
      "850:\tlearn: 0.7660084\ttest: 0.7389187\tbest: 0.7398928 (806)\ttotal: 8m 59s\tremaining: 1m 34s\n",
      "851:\tlearn: 0.7660084\ttest: 0.7389187\tbest: 0.7398928 (806)\ttotal: 9m\tremaining: 1m 33s\n",
      "852:\tlearn: 0.7660084\ttest: 0.7389187\tbest: 0.7398928 (806)\ttotal: 9m\tremaining: 1m 33s\n",
      "853:\tlearn: 0.7660084\ttest: 0.7389187\tbest: 0.7398928 (806)\ttotal: 9m 1s\tremaining: 1m 32s\n",
      "854:\tlearn: 0.7659841\ttest: 0.7389187\tbest: 0.7398928 (806)\ttotal: 9m 2s\tremaining: 1m 31s\n",
      "855:\tlearn: 0.7665226\ttest: 0.7392257\tbest: 0.7398928 (806)\ttotal: 9m 2s\tremaining: 1m 31s\n",
      "856:\tlearn: 0.7663542\ttest: 0.7397127\tbest: 0.7398928 (806)\ttotal: 9m 3s\tremaining: 1m 30s\n",
      "857:\tlearn: 0.7663542\ttest: 0.7397127\tbest: 0.7398928 (806)\ttotal: 9m 4s\tremaining: 1m 30s\n",
      "858:\tlearn: 0.7663542\ttest: 0.7397127\tbest: 0.7398928 (806)\ttotal: 9m 4s\tremaining: 1m 29s\n",
      "859:\tlearn: 0.7661790\ttest: 0.7397127\tbest: 0.7398928 (806)\ttotal: 9m 5s\tremaining: 1m 28s\n",
      "860:\tlearn: 0.7661790\ttest: 0.7397127\tbest: 0.7398928 (806)\ttotal: 9m 6s\tremaining: 1m 28s\n",
      "861:\tlearn: 0.7661790\ttest: 0.7397127\tbest: 0.7398928 (806)\ttotal: 9m 6s\tremaining: 1m 27s\n",
      "862:\tlearn: 0.7661790\ttest: 0.7397127\tbest: 0.7398928 (806)\ttotal: 9m 7s\tremaining: 1m 26s\n",
      "863:\tlearn: 0.7661790\ttest: 0.7397127\tbest: 0.7398928 (806)\ttotal: 9m 7s\tremaining: 1m 26s\n",
      "864:\tlearn: 0.7661790\ttest: 0.7397127\tbest: 0.7398928 (806)\ttotal: 9m 8s\tremaining: 1m 25s\n",
      "865:\tlearn: 0.7661790\ttest: 0.7395326\tbest: 0.7398928 (806)\ttotal: 9m 9s\tremaining: 1m 24s\n",
      "866:\tlearn: 0.7664758\ttest: 0.7393526\tbest: 0.7398928 (806)\ttotal: 9m 9s\tremaining: 1m 24s\n",
      "867:\tlearn: 0.7664758\ttest: 0.7393526\tbest: 0.7398928 (806)\ttotal: 9m 10s\tremaining: 1m 23s\n",
      "868:\tlearn: 0.7664758\ttest: 0.7393526\tbest: 0.7398928 (806)\ttotal: 9m 11s\tremaining: 1m 23s\n",
      "869:\tlearn: 0.7664758\ttest: 0.7393526\tbest: 0.7398928 (806)\ttotal: 9m 11s\tremaining: 1m 22s\n",
      "870:\tlearn: 0.7666042\ttest: 0.7396594\tbest: 0.7398928 (806)\ttotal: 9m 12s\tremaining: 1m 21s\n",
      "871:\tlearn: 0.7666042\ttest: 0.7396594\tbest: 0.7398928 (806)\ttotal: 9m 12s\tremaining: 1m 21s\n",
      "872:\tlearn: 0.7669408\ttest: 0.7394794\tbest: 0.7398928 (806)\ttotal: 9m 13s\tremaining: 1m 20s\n",
      "873:\tlearn: 0.7669650\ttest: 0.7391727\tbest: 0.7398928 (806)\ttotal: 9m 14s\tremaining: 1m 19s\n",
      "874:\tlearn: 0.7669650\ttest: 0.7391727\tbest: 0.7398928 (806)\ttotal: 9m 14s\tremaining: 1m 19s\n",
      "875:\tlearn: 0.7667239\ttest: 0.7392996\tbest: 0.7398928 (806)\ttotal: 9m 15s\tremaining: 1m 18s\n",
      "876:\tlearn: 0.7667239\ttest: 0.7392996\tbest: 0.7398928 (806)\ttotal: 9m 16s\tremaining: 1m 17s\n",
      "877:\tlearn: 0.7667239\ttest: 0.7392996\tbest: 0.7398928 (806)\ttotal: 9m 16s\tremaining: 1m 17s\n",
      "878:\tlearn: 0.7677819\ttest: 0.7392467\tbest: 0.7398928 (806)\ttotal: 9m 17s\tremaining: 1m 16s\n",
      "879:\tlearn: 0.7677819\ttest: 0.7392467\tbest: 0.7398928 (806)\ttotal: 9m 18s\tremaining: 1m 16s\n",
      "880:\tlearn: 0.7677819\ttest: 0.7392467\tbest: 0.7398928 (806)\ttotal: 9m 18s\tremaining: 1m 15s\n",
      "881:\tlearn: 0.7677819\ttest: 0.7392467\tbest: 0.7398928 (806)\ttotal: 9m 19s\tremaining: 1m 14s\n",
      "882:\tlearn: 0.7677819\ttest: 0.7392467\tbest: 0.7398928 (806)\ttotal: 9m 20s\tremaining: 1m 14s\n",
      "883:\tlearn: 0.7684627\ttest: 0.7390671\tbest: 0.7398928 (806)\ttotal: 9m 20s\tremaining: 1m 13s\n",
      "884:\tlearn: 0.7684627\ttest: 0.7390671\tbest: 0.7398928 (806)\ttotal: 9m 21s\tremaining: 1m 12s\n",
      "885:\tlearn: 0.7684627\ttest: 0.7390671\tbest: 0.7398928 (806)\ttotal: 9m 21s\tremaining: 1m 12s\n",
      "886:\tlearn: 0.7684627\ttest: 0.7390671\tbest: 0.7398928 (806)\ttotal: 9m 22s\tremaining: 1m 11s\n",
      "887:\tlearn: 0.7685026\ttest: 0.7390671\tbest: 0.7398928 (806)\ttotal: 9m 23s\tremaining: 1m 11s\n",
      "888:\tlearn: 0.7685026\ttest: 0.7390671\tbest: 0.7398928 (806)\ttotal: 9m 23s\tremaining: 1m 10s\n",
      "889:\tlearn: 0.7685026\ttest: 0.7390671\tbest: 0.7398928 (806)\ttotal: 9m 24s\tremaining: 1m 9s\n",
      "890:\tlearn: 0.7683745\ttest: 0.7390671\tbest: 0.7398928 (806)\ttotal: 9m 25s\tremaining: 1m 9s\n",
      "891:\tlearn: 0.7683745\ttest: 0.7390671\tbest: 0.7398928 (806)\ttotal: 9m 25s\tremaining: 1m 8s\n",
      "892:\tlearn: 0.7683745\ttest: 0.7390671\tbest: 0.7398928 (806)\ttotal: 9m 26s\tremaining: 1m 7s\n",
      "893:\tlearn: 0.7683745\ttest: 0.7390671\tbest: 0.7398928 (806)\ttotal: 9m 26s\tremaining: 1m 7s\n",
      "894:\tlearn: 0.7684386\ttest: 0.7387606\tbest: 0.7398928 (806)\ttotal: 9m 27s\tremaining: 1m 6s\n",
      "895:\tlearn: 0.7684386\ttest: 0.7387606\tbest: 0.7398928 (806)\ttotal: 9m 28s\tremaining: 1m 5s\n",
      "896:\tlearn: 0.7684386\ttest: 0.7387606\tbest: 0.7398928 (806)\ttotal: 9m 28s\tremaining: 1m 5s\n",
      "897:\tlearn: 0.7682305\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 29s\tremaining: 1m 4s\n",
      "898:\tlearn: 0.7682305\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 30s\tremaining: 1m 4s\n",
      "899:\tlearn: 0.7682305\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 30s\tremaining: 1m 3s\n",
      "900:\tlearn: 0.7682305\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 31s\tremaining: 1m 2s\n",
      "901:\tlearn: 0.7682305\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 31s\tremaining: 1m 2s\n",
      "902:\tlearn: 0.7682305\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 32s\tremaining: 1m 1s\n",
      "903:\tlearn: 0.7681423\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 33s\tremaining: 1m\n",
      "904:\tlearn: 0.7681423\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 33s\tremaining: 1m\n",
      "905:\tlearn: 0.7681423\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 34s\tremaining: 59.6s\n",
      "906:\tlearn: 0.7681423\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 35s\tremaining: 59s\n",
      "907:\tlearn: 0.7681423\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 35s\tremaining: 58.3s\n",
      "908:\tlearn: 0.7681423\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 36s\tremaining: 57.7s\n",
      "909:\tlearn: 0.7681423\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 36s\tremaining: 57.1s\n",
      "910:\tlearn: 0.7681423\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 37s\tremaining: 56.4s\n",
      "911:\tlearn: 0.7680782\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 38s\tremaining: 55.8s\n",
      "912:\tlearn: 0.7680782\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 38s\tremaining: 55.2s\n",
      "913:\tlearn: 0.7680782\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 39s\tremaining: 54.5s\n",
      "914:\tlearn: 0.7680782\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 40s\tremaining: 53.9s\n",
      "915:\tlearn: 0.7680782\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 40s\tremaining: 53.3s\n",
      "916:\tlearn: 0.7680782\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 41s\tremaining: 52.6s\n",
      "917:\tlearn: 0.7680782\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 42s\tremaining: 52s\n",
      "918:\tlearn: 0.7680782\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 42s\tremaining: 51.4s\n",
      "919:\tlearn: 0.7680782\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 43s\tremaining: 50.7s\n",
      "920:\tlearn: 0.7680782\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 43s\tremaining: 50.1s\n",
      "921:\tlearn: 0.7680782\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 44s\tremaining: 49.5s\n",
      "922:\tlearn: 0.7681182\ttest: 0.7387081\tbest: 0.7398928 (806)\ttotal: 9m 45s\tremaining: 48.8s\n",
      "923:\tlearn: 0.7681182\ttest: 0.7387081\tbest: 0.7398928 (806)\ttotal: 9m 45s\tremaining: 48.2s\n",
      "924:\tlearn: 0.7681182\ttest: 0.7387081\tbest: 0.7398928 (806)\ttotal: 9m 46s\tremaining: 47.5s\n",
      "925:\tlearn: 0.7681182\ttest: 0.7387081\tbest: 0.7398928 (806)\ttotal: 9m 47s\tremaining: 46.9s\n",
      "926:\tlearn: 0.7681182\ttest: 0.7387081\tbest: 0.7398928 (806)\ttotal: 9m 47s\tremaining: 46.3s\n",
      "927:\tlearn: 0.7681182\ttest: 0.7387081\tbest: 0.7398928 (806)\ttotal: 9m 48s\tremaining: 45.6s\n",
      "928:\tlearn: 0.7681182\ttest: 0.7387081\tbest: 0.7398928 (806)\ttotal: 9m 48s\tremaining: 45s\n",
      "929:\tlearn: 0.7683986\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 49s\tremaining: 44.4s\n",
      "930:\tlearn: 0.7683986\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 50s\tremaining: 43.7s\n",
      "931:\tlearn: 0.7683986\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 50s\tremaining: 43.1s\n",
      "932:\tlearn: 0.7683986\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 51s\tremaining: 42.5s\n",
      "933:\tlearn: 0.7683986\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 52s\tremaining: 41.8s\n",
      "934:\tlearn: 0.7683986\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 52s\tremaining: 41.2s\n",
      "935:\tlearn: 0.7683986\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 53s\tremaining: 40.6s\n",
      "936:\tlearn: 0.7683986\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 54s\tremaining: 39.9s\n",
      "937:\tlearn: 0.7683986\ttest: 0.7388875\tbest: 0.7398928 (806)\ttotal: 9m 54s\tremaining: 39.3s\n",
      "938:\tlearn: 0.7683986\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 55s\tremaining: 38.7s\n",
      "939:\tlearn: 0.7683986\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 55s\tremaining: 38s\n",
      "940:\tlearn: 0.7683986\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 56s\tremaining: 37.4s\n",
      "941:\tlearn: 0.7683986\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 57s\tremaining: 36.8s\n",
      "942:\tlearn: 0.7683986\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 57s\tremaining: 36.1s\n",
      "943:\tlearn: 0.7683986\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 58s\tremaining: 35.5s\n",
      "944:\tlearn: 0.7683986\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 59s\tremaining: 34.9s\n",
      "945:\tlearn: 0.7683986\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 9m 59s\tremaining: 34.2s\n",
      "946:\tlearn: 0.7683986\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 10m\tremaining: 33.6s\n",
      "947:\tlearn: 0.7683986\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 10m\tremaining: 33s\n",
      "948:\tlearn: 0.7683986\ttest: 0.7385811\tbest: 0.7398928 (806)\ttotal: 10m 1s\tremaining: 32.3s\n",
      "949:\tlearn: 0.7684627\ttest: 0.7382746\tbest: 0.7398928 (806)\ttotal: 10m 2s\tremaining: 31.7s\n",
      "950:\tlearn: 0.7684627\ttest: 0.7382746\tbest: 0.7398928 (806)\ttotal: 10m 2s\tremaining: 31.1s\n",
      "951:\tlearn: 0.7684627\ttest: 0.7382746\tbest: 0.7398928 (806)\ttotal: 10m 3s\tremaining: 30.4s\n",
      "952:\tlearn: 0.7684627\ttest: 0.7382746\tbest: 0.7398928 (806)\ttotal: 10m 4s\tremaining: 29.8s\n",
      "953:\tlearn: 0.7684627\ttest: 0.7382746\tbest: 0.7398928 (806)\ttotal: 10m 4s\tremaining: 29.2s\n",
      "954:\tlearn: 0.7684627\ttest: 0.7382746\tbest: 0.7398928 (806)\ttotal: 10m 5s\tremaining: 28.5s\n",
      "955:\tlearn: 0.7684627\ttest: 0.7382746\tbest: 0.7398928 (806)\ttotal: 10m 6s\tremaining: 27.9s\n",
      "956:\tlearn: 0.7684627\ttest: 0.7382746\tbest: 0.7398928 (806)\ttotal: 10m 6s\tremaining: 27.3s\n",
      "957:\tlearn: 0.7684550\ttest: 0.7387081\tbest: 0.7398928 (806)\ttotal: 10m 7s\tremaining: 26.6s\n",
      "958:\tlearn: 0.7684550\ttest: 0.7387081\tbest: 0.7398928 (806)\ttotal: 10m 7s\tremaining: 26s\n",
      "959:\tlearn: 0.7684550\ttest: 0.7387081\tbest: 0.7398928 (806)\ttotal: 10m 8s\tremaining: 25.4s\n",
      "960:\tlearn: 0.7684550\ttest: 0.7387081\tbest: 0.7398928 (806)\ttotal: 10m 9s\tremaining: 24.7s\n",
      "961:\tlearn: 0.7688390\ttest: 0.7387081\tbest: 0.7398928 (806)\ttotal: 10m 9s\tremaining: 24.1s\n",
      "962:\tlearn: 0.7688390\ttest: 0.7387081\tbest: 0.7398928 (806)\ttotal: 10m 10s\tremaining: 23.5s\n",
      "963:\tlearn: 0.7688390\ttest: 0.7387081\tbest: 0.7398928 (806)\ttotal: 10m 11s\tremaining: 22.8s\n",
      "964:\tlearn: 0.7690229\ttest: 0.7391938\tbest: 0.7398928 (806)\ttotal: 10m 11s\tremaining: 22.2s\n",
      "965:\tlearn: 0.7690229\ttest: 0.7391938\tbest: 0.7398928 (806)\ttotal: 10m 12s\tremaining: 21.6s\n",
      "966:\tlearn: 0.7690229\ttest: 0.7391938\tbest: 0.7398928 (806)\ttotal: 10m 13s\tremaining: 20.9s\n",
      "967:\tlearn: 0.7690229\ttest: 0.7391938\tbest: 0.7398928 (806)\ttotal: 10m 13s\tremaining: 20.3s\n",
      "968:\tlearn: 0.7690628\ttest: 0.7391938\tbest: 0.7398928 (806)\ttotal: 10m 14s\tremaining: 19.7s\n",
      "969:\tlearn: 0.7690628\ttest: 0.7391938\tbest: 0.7398928 (806)\ttotal: 10m 14s\tremaining: 19s\n",
      "970:\tlearn: 0.7690628\ttest: 0.7391938\tbest: 0.7398928 (806)\ttotal: 10m 15s\tremaining: 18.4s\n",
      "971:\tlearn: 0.7690628\ttest: 0.7391938\tbest: 0.7398928 (806)\ttotal: 10m 16s\tremaining: 17.8s\n",
      "972:\tlearn: 0.7689989\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 16s\tremaining: 17.1s\n",
      "973:\tlearn: 0.7689349\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 17s\tremaining: 16.5s\n",
      "974:\tlearn: 0.7689349\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 18s\tremaining: 15.8s\n",
      "975:\tlearn: 0.7689349\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 18s\tremaining: 15.2s\n",
      "976:\tlearn: 0.7689349\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 19s\tremaining: 14.6s\n",
      "977:\tlearn: 0.7688709\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 20s\tremaining: 13.9s\n",
      "978:\tlearn: 0.7688069\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 20s\tremaining: 13.3s\n",
      "979:\tlearn: 0.7688069\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 21s\tremaining: 12.7s\n",
      "980:\tlearn: 0.7688069\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 21s\tremaining: 12s\n",
      "981:\tlearn: 0.7688468\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 22s\tremaining: 11.4s\n",
      "982:\tlearn: 0.7688468\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 23s\tremaining: 10.8s\n",
      "983:\tlearn: 0.7689108\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 23s\tremaining: 10.1s\n",
      "984:\tlearn: 0.7689108\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 24s\tremaining: 9.51s\n",
      "985:\tlearn: 0.7689108\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 25s\tremaining: 8.87s\n",
      "986:\tlearn: 0.7689108\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 25s\tremaining: 8.24s\n",
      "987:\tlearn: 0.7689108\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 26s\tremaining: 7.61s\n",
      "988:\tlearn: 0.7690388\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 26s\tremaining: 6.97s\n",
      "989:\tlearn: 0.7689748\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 27s\tremaining: 6.34s\n",
      "990:\tlearn: 0.7689748\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 28s\tremaining: 5.71s\n",
      "991:\tlearn: 0.7689748\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 28s\tremaining: 5.07s\n",
      "992:\tlearn: 0.7689748\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 29s\tremaining: 4.44s\n",
      "993:\tlearn: 0.7689748\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 30s\tremaining: 3.8s\n",
      "994:\tlearn: 0.7689748\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 30s\tremaining: 3.17s\n",
      "995:\tlearn: 0.7689748\ttest: 0.7393733\tbest: 0.7398928 (806)\ttotal: 10m 31s\tremaining: 2.54s\n",
      "996:\tlearn: 0.7690788\ttest: 0.7396795\tbest: 0.7398928 (806)\ttotal: 10m 32s\tremaining: 1.9s\n",
      "997:\tlearn: 0.7690788\ttest: 0.7396795\tbest: 0.7398928 (806)\ttotal: 10m 32s\tremaining: 1.27s\n",
      "998:\tlearn: 0.7690788\ttest: 0.7396795\tbest: 0.7398928 (806)\ttotal: 10m 33s\tremaining: 634ms\n",
      "999:\tlearn: 0.7690788\ttest: 0.7396795\tbest: 0.7398928 (806)\ttotal: 10m 33s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7398928397\n",
      "bestIteration = 806\n",
      "\n",
      "Shrink model to first 807 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x25084b66730>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model_vect1 = CatBoostClassifier(random_state=42, eval_metric='F1')\n",
    "cat_model_vect1.fit(X_train_vect, y_train, eval_set=(X_valid_vect, y_valid), plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сбалансированные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.101529\n",
      "0:\tlearn: 0.5196021\ttest: 0.5227176\tbest: 0.5227176 (0)\ttotal: 680ms\tremaining: 11m 19s\n",
      "1:\tlearn: 0.5887671\ttest: 0.5915967\tbest: 0.5915967 (1)\ttotal: 1.36s\tremaining: 11m 18s\n",
      "2:\tlearn: 0.5824812\ttest: 0.5869660\tbest: 0.5915967 (1)\ttotal: 2.04s\tremaining: 11m 19s\n",
      "3:\tlearn: 0.5982209\ttest: 0.6010312\tbest: 0.6010312 (3)\ttotal: 2.75s\tremaining: 11m 23s\n",
      "4:\tlearn: 0.6219314\ttest: 0.6231107\tbest: 0.6231107 (4)\ttotal: 3.45s\tremaining: 11m 26s\n",
      "5:\tlearn: 0.6233221\ttest: 0.6224758\tbest: 0.6231107 (4)\ttotal: 4.12s\tremaining: 11m 22s\n",
      "6:\tlearn: 0.6501911\ttest: 0.6533333\tbest: 0.6533333 (6)\ttotal: 4.77s\tremaining: 11m 16s\n",
      "7:\tlearn: 0.6684702\ttest: 0.6744492\tbest: 0.6744492 (7)\ttotal: 5.43s\tremaining: 11m 12s\n",
      "8:\tlearn: 0.6703310\ttest: 0.6755212\tbest: 0.6755212 (8)\ttotal: 6.09s\tremaining: 11m 10s\n",
      "9:\tlearn: 0.6753923\ttest: 0.6785409\tbest: 0.6785409 (9)\ttotal: 6.77s\tremaining: 11m 10s\n",
      "10:\tlearn: 0.6878282\ttest: 0.6888604\tbest: 0.6888604 (10)\ttotal: 7.44s\tremaining: 11m 9s\n",
      "11:\tlearn: 0.7067417\ttest: 0.7069702\tbest: 0.7069702 (11)\ttotal: 8.09s\tremaining: 11m 6s\n",
      "12:\tlearn: 0.7171327\ttest: 0.7184588\tbest: 0.7184588 (12)\ttotal: 8.75s\tremaining: 11m 4s\n",
      "13:\tlearn: 0.7244669\ttest: 0.7260917\tbest: 0.7260917 (13)\ttotal: 9.4s\tremaining: 11m 2s\n",
      "14:\tlearn: 0.7437891\ttest: 0.7478586\tbest: 0.7478586 (14)\ttotal: 10.1s\tremaining: 11m 1s\n",
      "15:\tlearn: 0.7449179\ttest: 0.7473939\tbest: 0.7478586 (14)\ttotal: 10.7s\tremaining: 10m 58s\n",
      "16:\tlearn: 0.7505069\ttest: 0.7524520\tbest: 0.7524520 (16)\ttotal: 11.4s\tremaining: 10m 56s\n",
      "17:\tlearn: 0.7579916\ttest: 0.7613905\tbest: 0.7613905 (17)\ttotal: 12s\tremaining: 10m 54s\n",
      "18:\tlearn: 0.7626175\ttest: 0.7657600\tbest: 0.7657600 (18)\ttotal: 12.6s\tremaining: 10m 52s\n",
      "19:\tlearn: 0.7687242\ttest: 0.7717181\tbest: 0.7717181 (19)\ttotal: 13.3s\tremaining: 10m 50s\n",
      "20:\tlearn: 0.7694353\ttest: 0.7736617\tbest: 0.7736617 (20)\ttotal: 13.9s\tremaining: 10m 50s\n",
      "21:\tlearn: 0.7728806\ttest: 0.7766492\tbest: 0.7766492 (21)\ttotal: 14.6s\tremaining: 10m 48s\n",
      "22:\tlearn: 0.7769068\ttest: 0.7797652\tbest: 0.7797652 (22)\ttotal: 15.2s\tremaining: 10m 46s\n",
      "23:\tlearn: 0.7807582\ttest: 0.7827514\tbest: 0.7827514 (23)\ttotal: 15.9s\tremaining: 10m 45s\n",
      "24:\tlearn: 0.7809838\ttest: 0.7838991\tbest: 0.7838991 (24)\ttotal: 16.5s\tremaining: 10m 44s\n",
      "25:\tlearn: 0.7810725\ttest: 0.7836617\tbest: 0.7838991 (24)\ttotal: 17.2s\tremaining: 10m 43s\n",
      "26:\tlearn: 0.7836213\ttest: 0.7852264\tbest: 0.7852264 (26)\ttotal: 17.8s\tremaining: 10m 42s\n",
      "27:\tlearn: 0.7867755\ttest: 0.7874414\tbest: 0.7874414 (27)\ttotal: 18.5s\tremaining: 10m 41s\n",
      "28:\tlearn: 0.7867726\ttest: 0.7873766\tbest: 0.7874414 (27)\ttotal: 19.1s\tremaining: 10m 40s\n",
      "29:\tlearn: 0.7873734\ttest: 0.7905508\tbest: 0.7905508 (29)\ttotal: 19.8s\tremaining: 10m 40s\n",
      "30:\tlearn: 0.7881861\ttest: 0.7918081\tbest: 0.7918081 (30)\ttotal: 20.5s\tremaining: 10m 39s\n",
      "31:\tlearn: 0.7897214\ttest: 0.7940434\tbest: 0.7940434 (31)\ttotal: 21.1s\tremaining: 10m 37s\n",
      "32:\tlearn: 0.7913952\ttest: 0.7933864\tbest: 0.7940434 (31)\ttotal: 21.7s\tremaining: 10m 36s\n",
      "33:\tlearn: 0.7923556\ttest: 0.7942169\tbest: 0.7942169 (33)\ttotal: 22.4s\tremaining: 10m 35s\n",
      "34:\tlearn: 0.7929346\ttest: 0.7955620\tbest: 0.7955620 (34)\ttotal: 23s\tremaining: 10m 34s\n",
      "35:\tlearn: 0.7949105\ttest: 0.7969470\tbest: 0.7969470 (35)\ttotal: 23.6s\tremaining: 10m 32s\n",
      "36:\tlearn: 0.7961447\ttest: 0.7974826\tbest: 0.7974826 (36)\ttotal: 24.3s\tremaining: 10m 31s\n",
      "37:\tlearn: 0.7989831\ttest: 0.8018076\tbest: 0.8018076 (37)\ttotal: 24.9s\tremaining: 10m 29s\n",
      "38:\tlearn: 0.7992159\ttest: 0.8027165\tbest: 0.8027165 (38)\ttotal: 25.5s\tremaining: 10m 28s\n",
      "39:\tlearn: 0.8018473\ttest: 0.8072415\tbest: 0.8072415 (39)\ttotal: 26.2s\tremaining: 10m 28s\n",
      "40:\tlearn: 0.8031681\ttest: 0.8086197\tbest: 0.8086197 (40)\ttotal: 26.8s\tremaining: 10m 26s\n",
      "41:\tlearn: 0.8046780\ttest: 0.8098854\tbest: 0.8098854 (41)\ttotal: 27.4s\tremaining: 10m 25s\n",
      "42:\tlearn: 0.8068760\ttest: 0.8124500\tbest: 0.8124500 (42)\ttotal: 28.1s\tremaining: 10m 24s\n",
      "43:\tlearn: 0.8073359\ttest: 0.8142675\tbest: 0.8142675 (43)\ttotal: 28.7s\tremaining: 10m 23s\n",
      "44:\tlearn: 0.8083146\ttest: 0.8143549\tbest: 0.8143549 (44)\ttotal: 29.4s\tremaining: 10m 23s\n",
      "45:\tlearn: 0.8090396\ttest: 0.8139647\tbest: 0.8143549 (44)\ttotal: 30s\tremaining: 10m 22s\n",
      "46:\tlearn: 0.8110123\ttest: 0.8173942\tbest: 0.8173942 (46)\ttotal: 30.6s\tremaining: 10m 21s\n",
      "47:\tlearn: 0.8113805\ttest: 0.8171146\tbest: 0.8173942 (46)\ttotal: 31.3s\tremaining: 10m 20s\n",
      "48:\tlearn: 0.8127510\ttest: 0.8203737\tbest: 0.8203737 (48)\ttotal: 31.9s\tremaining: 10m 19s\n",
      "49:\tlearn: 0.8150023\ttest: 0.8226379\tbest: 0.8226379 (49)\ttotal: 32.6s\tremaining: 10m 19s\n",
      "50:\tlearn: 0.8156710\ttest: 0.8224190\tbest: 0.8226379 (49)\ttotal: 33.2s\tremaining: 10m 17s\n",
      "51:\tlearn: 0.8163199\ttest: 0.8226960\tbest: 0.8226960 (51)\ttotal: 33.8s\tremaining: 10m 16s\n",
      "52:\tlearn: 0.8183525\ttest: 0.8249857\tbest: 0.8249857 (52)\ttotal: 34.5s\tremaining: 10m 15s\n",
      "53:\tlearn: 0.8202568\ttest: 0.8256370\tbest: 0.8256370 (53)\ttotal: 35.1s\tremaining: 10m 14s\n",
      "54:\tlearn: 0.8206297\ttest: 0.8264404\tbest: 0.8264404 (54)\ttotal: 35.7s\tremaining: 10m 13s\n",
      "55:\tlearn: 0.8210242\ttest: 0.8273857\tbest: 0.8273857 (55)\ttotal: 36.4s\tremaining: 10m 13s\n",
      "56:\tlearn: 0.8208928\ttest: 0.8274295\tbest: 0.8274295 (56)\ttotal: 37s\tremaining: 10m 12s\n",
      "57:\tlearn: 0.8217616\ttest: 0.8283397\tbest: 0.8283397 (57)\ttotal: 37.6s\tremaining: 10m 11s\n",
      "58:\tlearn: 0.8231202\ttest: 0.8285479\tbest: 0.8285479 (58)\ttotal: 38.3s\tremaining: 10m 10s\n",
      "59:\tlearn: 0.8233868\ttest: 0.8288656\tbest: 0.8288656 (59)\ttotal: 38.9s\tremaining: 10m 9s\n",
      "60:\tlearn: 0.8241068\ttest: 0.8296090\tbest: 0.8296090 (60)\ttotal: 39.6s\tremaining: 10m 9s\n",
      "61:\tlearn: 0.8243026\ttest: 0.8299040\tbest: 0.8299040 (61)\ttotal: 40.2s\tremaining: 10m 8s\n",
      "62:\tlearn: 0.8251714\ttest: 0.8293138\tbest: 0.8299040 (61)\ttotal: 40.8s\tremaining: 10m 7s\n",
      "63:\tlearn: 0.8254985\ttest: 0.8302108\tbest: 0.8302108 (63)\ttotal: 41.5s\tremaining: 10m 6s\n",
      "64:\tlearn: 0.8259960\ttest: 0.8301670\tbest: 0.8302108 (63)\ttotal: 42.1s\tremaining: 10m 5s\n",
      "65:\tlearn: 0.8266274\ttest: 0.8306910\tbest: 0.8306910 (65)\ttotal: 42.7s\tremaining: 10m 4s\n",
      "66:\tlearn: 0.8266414\ttest: 0.8304400\tbest: 0.8306910 (65)\ttotal: 43.4s\tremaining: 10m 3s\n",
      "67:\tlearn: 0.8271497\ttest: 0.8311707\tbest: 0.8311707 (67)\ttotal: 44s\tremaining: 10m 3s\n",
      "68:\tlearn: 0.8274810\ttest: 0.8312364\tbest: 0.8312364 (68)\ttotal: 44.6s\tremaining: 10m 2s\n",
      "69:\tlearn: 0.8283521\ttest: 0.8325539\tbest: 0.8325539 (69)\ttotal: 45.3s\tremaining: 10m 1s\n",
      "70:\tlearn: 0.8285350\ttest: 0.8333034\tbest: 0.8333034 (70)\ttotal: 45.9s\tremaining: 10m 1s\n",
      "71:\tlearn: 0.8291958\ttest: 0.8343448\tbest: 0.8343448 (71)\ttotal: 46.6s\tremaining: 10m\n",
      "72:\tlearn: 0.8296337\ttest: 0.8349744\tbest: 0.8349744 (72)\ttotal: 47.2s\tremaining: 9m 59s\n",
      "73:\tlearn: 0.8298674\ttest: 0.8345719\tbest: 0.8349744 (72)\ttotal: 47.9s\tremaining: 9m 58s\n",
      "74:\tlearn: 0.8303559\ttest: 0.8347550\tbest: 0.8349744 (72)\ttotal: 48.5s\tremaining: 9m 58s\n",
      "75:\tlearn: 0.8305056\ttest: 0.8344841\tbest: 0.8349744 (72)\ttotal: 49.2s\tremaining: 9m 57s\n",
      "76:\tlearn: 0.8304378\ttest: 0.8343009\tbest: 0.8349744 (72)\ttotal: 49.8s\tremaining: 9m 56s\n",
      "77:\tlearn: 0.8320958\ttest: 0.8363841\tbest: 0.8363841 (77)\ttotal: 50.4s\tremaining: 9m 56s\n",
      "78:\tlearn: 0.8319578\ttest: 0.8357563\tbest: 0.8363841 (77)\ttotal: 51s\tremaining: 9m 55s\n",
      "79:\tlearn: 0.8320789\ttest: 0.8358221\tbest: 0.8363841 (77)\ttotal: 51.7s\tremaining: 9m 54s\n",
      "80:\tlearn: 0.8323277\ttest: 0.8363402\tbest: 0.8363841 (77)\ttotal: 52.3s\tremaining: 9m 53s\n",
      "81:\tlearn: 0.8333491\ttest: 0.8368797\tbest: 0.8368797 (81)\ttotal: 52.9s\tremaining: 9m 52s\n",
      "82:\tlearn: 0.8338347\ttest: 0.8375783\tbest: 0.8375783 (82)\ttotal: 53.6s\tremaining: 9m 52s\n",
      "83:\tlearn: 0.8343144\ttest: 0.8372651\tbest: 0.8375783 (82)\ttotal: 54.2s\tremaining: 9m 51s\n",
      "84:\tlearn: 0.8350629\ttest: 0.8376003\tbest: 0.8376003 (84)\ttotal: 54.8s\tremaining: 9m 50s\n",
      "85:\tlearn: 0.8355024\ttest: 0.8388791\tbest: 0.8388791 (85)\ttotal: 55.5s\tremaining: 9m 49s\n",
      "86:\tlearn: 0.8353538\ttest: 0.8388133\tbest: 0.8388791 (85)\ttotal: 56.1s\tremaining: 9m 48s\n",
      "87:\tlearn: 0.8360929\ttest: 0.8405808\tbest: 0.8405808 (87)\ttotal: 56.8s\tremaining: 9m 48s\n",
      "88:\tlearn: 0.8366188\ttest: 0.8416508\tbest: 0.8416508 (88)\ttotal: 57.4s\tremaining: 9m 47s\n",
      "89:\tlearn: 0.8365953\ttest: 0.8419180\tbest: 0.8419180 (89)\ttotal: 58s\tremaining: 9m 46s\n",
      "90:\tlearn: 0.8359568\ttest: 0.8422729\tbest: 0.8422729 (90)\ttotal: 58.7s\tremaining: 9m 45s\n",
      "91:\tlearn: 0.8366544\ttest: 0.8427847\tbest: 0.8427847 (91)\ttotal: 59.3s\tremaining: 9m 45s\n",
      "92:\tlearn: 0.8375019\ttest: 0.8439851\tbest: 0.8439851 (92)\ttotal: 59.9s\tremaining: 9m 44s\n",
      "93:\tlearn: 0.8375655\ttest: 0.8437629\tbest: 0.8439851 (92)\ttotal: 1m\tremaining: 9m 43s\n",
      "94:\tlearn: 0.8384970\ttest: 0.8436970\tbest: 0.8439851 (92)\ttotal: 1m 1s\tremaining: 9m 42s\n",
      "95:\tlearn: 0.8388759\ttest: 0.8445611\tbest: 0.8445611 (95)\ttotal: 1m 1s\tremaining: 9m 42s\n",
      "96:\tlearn: 0.8396365\ttest: 0.8451165\tbest: 0.8451165 (96)\ttotal: 1m 2s\tremaining: 9m 41s\n",
      "97:\tlearn: 0.8397278\ttest: 0.8445413\tbest: 0.8451165 (96)\ttotal: 1m 3s\tremaining: 9m 40s\n",
      "98:\tlearn: 0.8404113\ttest: 0.8456033\tbest: 0.8456033 (98)\ttotal: 1m 3s\tremaining: 9m 40s\n",
      "99:\tlearn: 0.8406781\ttest: 0.8458905\tbest: 0.8458905 (99)\ttotal: 1m 4s\tremaining: 9m 39s\n",
      "100:\tlearn: 0.8408358\ttest: 0.8458465\tbest: 0.8458905 (99)\ttotal: 1m 5s\tremaining: 9m 38s\n",
      "101:\tlearn: 0.8412319\ttest: 0.8458465\tbest: 0.8458905 (99)\ttotal: 1m 5s\tremaining: 9m 38s\n",
      "102:\tlearn: 0.8420185\ttest: 0.8462886\tbest: 0.8462886 (102)\ttotal: 1m 6s\tremaining: 9m 37s\n",
      "103:\tlearn: 0.8432692\ttest: 0.8472593\tbest: 0.8472593 (103)\ttotal: 1m 6s\tremaining: 9m 36s\n",
      "104:\tlearn: 0.8439538\ttest: 0.8473478\tbest: 0.8473478 (104)\ttotal: 1m 7s\tremaining: 9m 36s\n",
      "105:\tlearn: 0.8444469\ttest: 0.8478101\tbest: 0.8478101 (105)\ttotal: 1m 8s\tremaining: 9m 35s\n",
      "106:\tlearn: 0.8442902\ttest: 0.8479200\tbest: 0.8479200 (106)\ttotal: 1m 8s\tremaining: 9m 34s\n",
      "107:\tlearn: 0.8452596\ttest: 0.8478983\tbest: 0.8479200 (106)\ttotal: 1m 9s\tremaining: 9m 33s\n",
      "108:\tlearn: 0.8451534\ttest: 0.8482720\tbest: 0.8482720 (108)\ttotal: 1m 10s\tremaining: 9m 33s\n",
      "109:\tlearn: 0.8457260\ttest: 0.8480961\tbest: 0.8482720 (108)\ttotal: 1m 10s\tremaining: 9m 32s\n",
      "110:\tlearn: 0.8470545\ttest: 0.8486895\tbest: 0.8486895 (110)\ttotal: 1m 11s\tremaining: 9m 31s\n",
      "111:\tlearn: 0.8474605\ttest: 0.8483819\tbest: 0.8486895 (110)\ttotal: 1m 12s\tremaining: 9m 31s\n",
      "112:\tlearn: 0.8482573\ttest: 0.8494800\tbest: 0.8494800 (112)\ttotal: 1m 12s\tremaining: 9m 30s\n",
      "113:\tlearn: 0.8492365\ttest: 0.8503353\tbest: 0.8503353 (113)\ttotal: 1m 13s\tremaining: 9m 29s\n",
      "114:\tlearn: 0.8495985\ttest: 0.8503573\tbest: 0.8503573 (114)\ttotal: 1m 13s\tremaining: 9m 28s\n",
      "115:\tlearn: 0.8499838\ttest: 0.8507729\tbest: 0.8507729 (115)\ttotal: 1m 14s\tremaining: 9m 28s\n",
      "116:\tlearn: 0.8508516\ttest: 0.8514065\tbest: 0.8514065 (116)\ttotal: 1m 15s\tremaining: 9m 27s\n",
      "117:\tlearn: 0.8516715\ttest: 0.8510342\tbest: 0.8514065 (116)\ttotal: 1m 15s\tremaining: 9m 27s\n",
      "118:\tlearn: 0.8524845\ttest: 0.8509682\tbest: 0.8514065 (116)\ttotal: 1m 16s\tremaining: 9m 26s\n",
      "119:\tlearn: 0.8526009\ttest: 0.8507277\tbest: 0.8514065 (116)\ttotal: 1m 17s\tremaining: 9m 25s\n",
      "120:\tlearn: 0.8535811\ttest: 0.8515368\tbest: 0.8515368 (120)\ttotal: 1m 17s\tremaining: 9m 24s\n",
      "121:\tlearn: 0.8544147\ttest: 0.8517989\tbest: 0.8517989 (121)\ttotal: 1m 18s\tremaining: 9m 24s\n",
      "122:\tlearn: 0.8547390\ttest: 0.8526703\tbest: 0.8526703 (122)\ttotal: 1m 19s\tremaining: 9m 23s\n",
      "123:\tlearn: 0.8547760\ttest: 0.8535645\tbest: 0.8535645 (123)\ttotal: 1m 19s\tremaining: 9m 22s\n",
      "124:\tlearn: 0.8552705\ttest: 0.8544544\tbest: 0.8544544 (124)\ttotal: 1m 20s\tremaining: 9m 22s\n",
      "125:\tlearn: 0.8553309\ttest: 0.8546491\tbest: 0.8546491 (125)\ttotal: 1m 20s\tremaining: 9m 21s\n",
      "126:\tlearn: 0.8549586\ttest: 0.8546051\tbest: 0.8546491 (125)\ttotal: 1m 21s\tremaining: 9m 20s\n",
      "127:\tlearn: 0.8551307\ttest: 0.8547997\tbest: 0.8547997 (127)\ttotal: 1m 22s\tremaining: 9m 20s\n",
      "128:\tlearn: 0.8552367\ttest: 0.8544952\tbest: 0.8547997 (127)\ttotal: 1m 22s\tremaining: 9m 19s\n",
      "129:\tlearn: 0.8552312\ttest: 0.8538419\tbest: 0.8547997 (127)\ttotal: 1m 23s\tremaining: 9m 18s\n",
      "130:\tlearn: 0.8560574\ttest: 0.8552545\tbest: 0.8552545 (130)\ttotal: 1m 24s\tremaining: 9m 18s\n",
      "131:\tlearn: 0.8565430\ttest: 0.8545392\tbest: 0.8552545 (130)\ttotal: 1m 24s\tremaining: 9m 17s\n",
      "132:\tlearn: 0.8571632\ttest: 0.8549942\tbest: 0.8552545 (130)\ttotal: 1m 25s\tremaining: 9m 16s\n",
      "133:\tlearn: 0.8575794\ttest: 0.8547118\tbest: 0.8552545 (130)\ttotal: 1m 26s\tremaining: 9m 15s\n",
      "134:\tlearn: 0.8579281\ttest: 0.8557488\tbest: 0.8557488 (134)\ttotal: 1m 26s\tremaining: 9m 15s\n",
      "135:\tlearn: 0.8583953\ttest: 0.8559867\tbest: 0.8559867 (135)\ttotal: 1m 27s\tremaining: 9m 14s\n",
      "136:\tlearn: 0.8590059\ttest: 0.8564400\tbest: 0.8564400 (136)\ttotal: 1m 27s\tremaining: 9m 13s\n",
      "137:\tlearn: 0.8591956\ttest: 0.8564180\tbest: 0.8564400 (136)\ttotal: 1m 28s\tremaining: 9m 13s\n",
      "138:\tlearn: 0.8594791\ttest: 0.8572572\tbest: 0.8572572 (138)\ttotal: 1m 29s\tremaining: 9m 12s\n",
      "139:\tlearn: 0.8604899\ttest: 0.8578410\tbest: 0.8578410 (139)\ttotal: 1m 29s\tremaining: 9m 11s\n",
      "140:\tlearn: 0.8612038\ttest: 0.8576481\tbest: 0.8578410 (139)\ttotal: 1m 30s\tremaining: 9m 11s\n",
      "141:\tlearn: 0.8611269\ttest: 0.8577531\tbest: 0.8578410 (139)\ttotal: 1m 31s\tremaining: 9m 10s\n",
      "142:\tlearn: 0.8613332\ttest: 0.8589412\tbest: 0.8589412 (142)\ttotal: 1m 31s\tremaining: 9m 10s\n",
      "143:\tlearn: 0.8617518\ttest: 0.8584023\tbest: 0.8589412 (142)\ttotal: 1m 32s\tremaining: 9m 9s\n",
      "144:\tlearn: 0.8625034\ttest: 0.8585949\tbest: 0.8589412 (142)\ttotal: 1m 33s\tremaining: 9m 8s\n",
      "145:\tlearn: 0.8631360\ttest: 0.8597756\tbest: 0.8597756 (145)\ttotal: 1m 33s\tremaining: 9m 8s\n",
      "146:\tlearn: 0.8630636\ttest: 0.8595558\tbest: 0.8597756 (145)\ttotal: 1m 34s\tremaining: 9m 7s\n",
      "147:\tlearn: 0.8636189\ttest: 0.8605267\tbest: 0.8605267 (147)\ttotal: 1m 34s\tremaining: 9m 6s\n",
      "148:\tlearn: 0.8642798\ttest: 0.8603727\tbest: 0.8605267 (147)\ttotal: 1m 35s\tremaining: 9m 5s\n",
      "149:\tlearn: 0.8640105\ttest: 0.8607181\tbest: 0.8607181 (149)\ttotal: 1m 36s\tremaining: 9m 5s\n",
      "150:\tlearn: 0.8650435\ttest: 0.8612986\tbest: 0.8612986 (150)\ttotal: 1m 36s\tremaining: 9m 4s\n",
      "151:\tlearn: 0.8653077\ttest: 0.8616217\tbest: 0.8616217 (151)\ttotal: 1m 37s\tremaining: 9m 3s\n",
      "152:\tlearn: 0.8657026\ttest: 0.8626049\tbest: 0.8626049 (152)\ttotal: 1m 38s\tremaining: 9m 3s\n",
      "153:\tlearn: 0.8661020\ttest: 0.8621943\tbest: 0.8626049 (152)\ttotal: 1m 38s\tremaining: 9m 2s\n",
      "154:\tlearn: 0.8667507\ttest: 0.8627658\tbest: 0.8627658 (154)\ttotal: 1m 39s\tremaining: 9m 1s\n",
      "155:\tlearn: 0.8668687\ttest: 0.8628318\tbest: 0.8628318 (155)\ttotal: 1m 40s\tremaining: 9m 1s\n",
      "156:\tlearn: 0.8671727\ttest: 0.8643456\tbest: 0.8643456 (156)\ttotal: 1m 40s\tremaining: 9m\n",
      "157:\tlearn: 0.8674545\ttest: 0.8640239\tbest: 0.8643456 (156)\ttotal: 1m 41s\tremaining: 8m 59s\n",
      "158:\tlearn: 0.8677645\ttest: 0.8643456\tbest: 0.8643456 (156)\ttotal: 1m 41s\tremaining: 8m 59s\n",
      "159:\tlearn: 0.8679256\ttest: 0.8640679\tbest: 0.8643456 (156)\ttotal: 1m 42s\tremaining: 8m 58s\n",
      "160:\tlearn: 0.8678636\ttest: 0.8638781\tbest: 0.8643456 (156)\ttotal: 1m 43s\tremaining: 8m 57s\n",
      "161:\tlearn: 0.8680694\ttest: 0.8631980\tbest: 0.8643456 (156)\ttotal: 1m 43s\tremaining: 8m 57s\n",
      "162:\tlearn: 0.8680905\ttest: 0.8635422\tbest: 0.8643456 (156)\ttotal: 1m 44s\tremaining: 8m 56s\n",
      "163:\tlearn: 0.8683723\ttest: 0.8644997\tbest: 0.8644997 (163)\ttotal: 1m 45s\tremaining: 8m 56s\n",
      "164:\tlearn: 0.8690955\ttest: 0.8658204\tbest: 0.8658204 (164)\ttotal: 1m 45s\tremaining: 8m 55s\n",
      "165:\tlearn: 0.8691687\ttest: 0.8658645\tbest: 0.8658645 (165)\ttotal: 1m 46s\tremaining: 8m 54s\n",
      "166:\tlearn: 0.8694237\ttest: 0.8656094\tbest: 0.8658645 (165)\ttotal: 1m 47s\tremaining: 8m 53s\n",
      "167:\tlearn: 0.8696785\ttest: 0.8668398\tbest: 0.8668398 (167)\ttotal: 1m 47s\tremaining: 8m 53s\n",
      "168:\tlearn: 0.8701431\ttest: 0.8675811\tbest: 0.8675811 (168)\ttotal: 1m 48s\tremaining: 8m 52s\n",
      "169:\tlearn: 0.8702940\ttest: 0.8674489\tbest: 0.8675811 (168)\ttotal: 1m 48s\tremaining: 8m 51s\n",
      "170:\tlearn: 0.8706333\ttest: 0.8674929\tbest: 0.8675811 (168)\ttotal: 1m 49s\tremaining: 8m 50s\n",
      "171:\tlearn: 0.8709324\ttest: 0.8682332\tbest: 0.8682332 (171)\ttotal: 1m 50s\tremaining: 8m 50s\n",
      "172:\tlearn: 0.8711206\ttest: 0.8680232\tbest: 0.8682332 (171)\ttotal: 1m 50s\tremaining: 8m 49s\n",
      "173:\tlearn: 0.8713161\ttest: 0.8683433\tbest: 0.8683433 (173)\ttotal: 1m 51s\tremaining: 8m 48s\n",
      "174:\tlearn: 0.8716758\ttest: 0.8683433\tbest: 0.8683433 (173)\ttotal: 1m 52s\tremaining: 8m 48s\n",
      "175:\tlearn: 0.8721077\ttest: 0.8686192\tbest: 0.8686192 (175)\ttotal: 1m 52s\tremaining: 8m 47s\n",
      "176:\tlearn: 0.8723352\ttest: 0.8685311\tbest: 0.8686192 (175)\ttotal: 1m 53s\tremaining: 8m 46s\n",
      "177:\tlearn: 0.8725815\ttest: 0.8681671\tbest: 0.8686192 (175)\ttotal: 1m 53s\tremaining: 8m 46s\n",
      "178:\tlearn: 0.8726193\ttest: 0.8683548\tbest: 0.8686192 (175)\ttotal: 1m 54s\tremaining: 8m 45s\n",
      "179:\tlearn: 0.8726732\ttest: 0.8683548\tbest: 0.8686192 (175)\ttotal: 1m 55s\tremaining: 8m 45s\n",
      "180:\tlearn: 0.8731426\ttest: 0.8682888\tbest: 0.8686192 (175)\ttotal: 1m 55s\tremaining: 8m 44s\n",
      "181:\tlearn: 0.8735530\ttest: 0.8693250\tbest: 0.8693250 (181)\ttotal: 1m 56s\tremaining: 8m 43s\n",
      "182:\tlearn: 0.8743259\ttest: 0.8701065\tbest: 0.8701065 (182)\ttotal: 1m 57s\tremaining: 8m 43s\n",
      "183:\tlearn: 0.8745837\ttest: 0.8703595\tbest: 0.8703595 (183)\ttotal: 1m 57s\tremaining: 8m 42s\n",
      "184:\tlearn: 0.8744808\ttest: 0.8697433\tbest: 0.8703595 (183)\ttotal: 1m 58s\tremaining: 8m 41s\n",
      "185:\tlearn: 0.8743732\ttest: 0.8689615\tbest: 0.8703595 (183)\ttotal: 1m 59s\tremaining: 8m 41s\n",
      "186:\tlearn: 0.8743874\ttest: 0.8697874\tbest: 0.8703595 (183)\ttotal: 1m 59s\tremaining: 8m 40s\n",
      "187:\tlearn: 0.8746120\ttest: 0.8700184\tbest: 0.8703595 (183)\ttotal: 2m\tremaining: 8m 39s\n",
      "188:\tlearn: 0.8745665\ttest: 0.8699964\tbest: 0.8703595 (183)\ttotal: 2m\tremaining: 8m 39s\n",
      "189:\tlearn: 0.8748733\ttest: 0.8701832\tbest: 0.8703595 (183)\ttotal: 2m 1s\tremaining: 8m 38s\n",
      "190:\tlearn: 0.8749016\ttest: 0.8707768\tbest: 0.8707768 (190)\ttotal: 2m 2s\tremaining: 8m 37s\n",
      "191:\tlearn: 0.8749093\ttest: 0.8701506\tbest: 0.8707768 (190)\ttotal: 2m 2s\tremaining: 8m 37s\n",
      "192:\tlearn: 0.8753600\ttest: 0.8704256\tbest: 0.8707768 (190)\ttotal: 2m 3s\tremaining: 8m 36s\n",
      "193:\tlearn: 0.8761984\ttest: 0.8709532\tbest: 0.8709532 (193)\ttotal: 2m 4s\tremaining: 8m 35s\n",
      "194:\tlearn: 0.8763199\ttest: 0.8709973\tbest: 0.8709973 (194)\ttotal: 2m 4s\tremaining: 8m 35s\n",
      "195:\tlearn: 0.8765439\ttest: 0.8710193\tbest: 0.8710193 (195)\ttotal: 2m 5s\tremaining: 8m 34s\n",
      "196:\tlearn: 0.8768560\ttest: 0.8710193\tbest: 0.8710193 (195)\ttotal: 2m 5s\tremaining: 8m 33s\n",
      "197:\tlearn: 0.8768183\ttest: 0.8718650\tbest: 0.8718650 (197)\ttotal: 2m 6s\tremaining: 8m 32s\n",
      "198:\tlearn: 0.8769554\ttest: 0.8721393\tbest: 0.8721393 (198)\ttotal: 2m 7s\tremaining: 8m 32s\n",
      "199:\tlearn: 0.8769459\ttest: 0.8721173\tbest: 0.8721393 (198)\ttotal: 2m 7s\tremaining: 8m 31s\n",
      "200:\tlearn: 0.8772940\ttest: 0.8731914\tbest: 0.8731914 (200)\ttotal: 2m 8s\tremaining: 8m 30s\n",
      "201:\tlearn: 0.8774245\ttest: 0.8731564\tbest: 0.8731914 (200)\ttotal: 2m 9s\tremaining: 8m 30s\n",
      "202:\tlearn: 0.8776636\ttest: 0.8734300\tbest: 0.8734300 (202)\ttotal: 2m 9s\tremaining: 8m 29s\n",
      "203:\tlearn: 0.8779873\ttest: 0.8738887\tbest: 0.8738887 (203)\ttotal: 2m 10s\tremaining: 8m 28s\n",
      "204:\tlearn: 0.8783600\ttest: 0.8736153\tbest: 0.8738887 (203)\ttotal: 2m 11s\tremaining: 8m 28s\n",
      "205:\tlearn: 0.8784810\ttest: 0.8737918\tbest: 0.8738887 (203)\ttotal: 2m 11s\tremaining: 8m 27s\n",
      "206:\tlearn: 0.8787433\ttest: 0.8740211\tbest: 0.8740211 (206)\ttotal: 2m 12s\tremaining: 8m 26s\n",
      "207:\tlearn: 0.8790480\ttest: 0.8740211\tbest: 0.8740211 (206)\ttotal: 2m 12s\tremaining: 8m 26s\n",
      "208:\tlearn: 0.8790824\ttest: 0.8738580\tbest: 0.8740211 (206)\ttotal: 2m 13s\tremaining: 8m 25s\n",
      "209:\tlearn: 0.8795968\ttest: 0.8741841\tbest: 0.8741841 (209)\ttotal: 2m 14s\tremaining: 8m 24s\n",
      "210:\tlearn: 0.8797756\ttest: 0.8736815\tbest: 0.8741841 (209)\ttotal: 2m 14s\tremaining: 8m 24s\n",
      "211:\tlearn: 0.8798052\ttest: 0.8738667\tbest: 0.8741841 (209)\ttotal: 2m 15s\tremaining: 8m 23s\n",
      "212:\tlearn: 0.8799414\ttest: 0.8743470\tbest: 0.8743470 (212)\ttotal: 2m 16s\tremaining: 8m 22s\n",
      "213:\tlearn: 0.8803272\ttest: 0.8741179\tbest: 0.8743470 (212)\ttotal: 2m 16s\tremaining: 8m 22s\n",
      "214:\tlearn: 0.8804573\ttest: 0.8746201\tbest: 0.8746201 (214)\ttotal: 2m 17s\tremaining: 8m 21s\n",
      "215:\tlearn: 0.8806892\ttest: 0.8748930\tbest: 0.8748930 (215)\ttotal: 2m 17s\tremaining: 8m 20s\n",
      "216:\tlearn: 0.8811726\ttest: 0.8750997\tbest: 0.8750997 (216)\ttotal: 2m 18s\tremaining: 8m 20s\n",
      "217:\tlearn: 0.8812352\ttest: 0.8751218\tbest: 0.8751218 (217)\ttotal: 2m 19s\tremaining: 8m 19s\n",
      "218:\tlearn: 0.8814915\ttest: 0.8751659\tbest: 0.8751659 (218)\ttotal: 2m 19s\tremaining: 8m 18s\n",
      "219:\tlearn: 0.8813994\ttest: 0.8749592\tbest: 0.8751659 (218)\ttotal: 2m 20s\tremaining: 8m 18s\n",
      "220:\tlearn: 0.8816945\ttest: 0.8757113\tbest: 0.8757113 (220)\ttotal: 2m 21s\tremaining: 8m 17s\n",
      "221:\tlearn: 0.8822993\ttest: 0.8753283\tbest: 0.8757113 (220)\ttotal: 2m 21s\tremaining: 8m 16s\n",
      "222:\tlearn: 0.8823040\ttest: 0.8750115\tbest: 0.8757113 (220)\ttotal: 2m 22s\tremaining: 8m 16s\n",
      "223:\tlearn: 0.8828049\ttest: 0.8751960\tbest: 0.8757113 (220)\ttotal: 2m 23s\tremaining: 8m 15s\n",
      "224:\tlearn: 0.8828428\ttest: 0.8750115\tbest: 0.8757113 (220)\ttotal: 2m 23s\tremaining: 8m 14s\n",
      "225:\tlearn: 0.8826014\ttest: 0.8754686\tbest: 0.8757113 (220)\ttotal: 2m 24s\tremaining: 8m 14s\n",
      "226:\tlearn: 0.8830690\ttest: 0.8759473\tbest: 0.8759473 (226)\ttotal: 2m 24s\tremaining: 8m 13s\n",
      "227:\tlearn: 0.8835456\ttest: 0.8764697\tbest: 0.8764697 (227)\ttotal: 2m 25s\tremaining: 8m 12s\n",
      "228:\tlearn: 0.8838553\ttest: 0.8767197\tbest: 0.8767197 (228)\ttotal: 2m 26s\tremaining: 8m 12s\n",
      "229:\tlearn: 0.8836626\ttest: 0.8770800\tbest: 0.8770800 (229)\ttotal: 2m 26s\tremaining: 8m 11s\n",
      "230:\tlearn: 0.8838411\ttest: 0.8775353\tbest: 0.8775353 (230)\ttotal: 2m 27s\tremaining: 8m 10s\n",
      "231:\tlearn: 0.8837834\ttest: 0.8767639\tbest: 0.8775353 (230)\ttotal: 2m 28s\tremaining: 8m 9s\n",
      "232:\tlearn: 0.8838750\ttest: 0.8772194\tbest: 0.8775353 (230)\ttotal: 2m 28s\tremaining: 8m 9s\n",
      "233:\tlearn: 0.8841773\ttest: 0.8782174\tbest: 0.8782174 (233)\ttotal: 2m 29s\tremaining: 8m 8s\n",
      "234:\tlearn: 0.8841868\ttest: 0.8785108\tbest: 0.8785108 (234)\ttotal: 2m 29s\tremaining: 8m 8s\n",
      "235:\tlearn: 0.8844423\ttest: 0.8784446\tbest: 0.8785108 (234)\ttotal: 2m 30s\tremaining: 8m 7s\n",
      "236:\tlearn: 0.8843556\ttest: 0.8780343\tbest: 0.8785108 (234)\ttotal: 2m 31s\tremaining: 8m 6s\n",
      "237:\tlearn: 0.8848553\ttest: 0.8782616\tbest: 0.8785108 (234)\ttotal: 2m 31s\tremaining: 8m 6s\n",
      "238:\tlearn: 0.8849751\ttest: 0.8782616\tbest: 0.8785108 (234)\ttotal: 2m 32s\tremaining: 8m 5s\n",
      "239:\tlearn: 0.8847592\ttest: 0.8787378\tbest: 0.8787378 (239)\ttotal: 2m 33s\tremaining: 8m 4s\n",
      "240:\tlearn: 0.8851821\ttest: 0.8786937\tbest: 0.8787378 (239)\ttotal: 2m 33s\tremaining: 8m 4s\n",
      "241:\tlearn: 0.8851584\ttest: 0.8781291\tbest: 0.8787378 (239)\ttotal: 2m 34s\tremaining: 8m 3s\n",
      "242:\tlearn: 0.8854844\ttest: 0.8780409\tbest: 0.8787378 (239)\ttotal: 2m 34s\tremaining: 8m 2s\n",
      "243:\tlearn: 0.8857811\ttest: 0.8782901\tbest: 0.8787378 (239)\ttotal: 2m 35s\tremaining: 8m 2s\n",
      "244:\tlearn: 0.8863990\ttest: 0.8788103\tbest: 0.8788103 (244)\ttotal: 2m 36s\tremaining: 8m 1s\n",
      "245:\tlearn: 0.8863464\ttest: 0.8793521\tbest: 0.8793521 (245)\ttotal: 2m 36s\tremaining: 8m\n",
      "246:\tlearn: 0.8864659\ttest: 0.8796890\tbest: 0.8796890 (246)\ttotal: 2m 37s\tremaining: 8m\n",
      "247:\tlearn: 0.8864706\ttest: 0.8799376\tbest: 0.8799376 (247)\ttotal: 2m 38s\tremaining: 7m 59s\n",
      "248:\tlearn: 0.8867001\ttest: 0.8802965\tbest: 0.8802965 (248)\ttotal: 2m 38s\tremaining: 7m 58s\n",
      "249:\tlearn: 0.8868627\ttest: 0.8799818\tbest: 0.8802965 (248)\ttotal: 2m 39s\tremaining: 7m 58s\n",
      "250:\tlearn: 0.8868485\ttest: 0.8805228\tbest: 0.8805228 (250)\ttotal: 2m 40s\tremaining: 7m 57s\n",
      "251:\tlearn: 0.8869679\ttest: 0.8805228\tbest: 0.8805228 (250)\ttotal: 2m 40s\tremaining: 7m 56s\n",
      "252:\tlearn: 0.8870825\ttest: 0.8805228\tbest: 0.8805228 (250)\ttotal: 2m 41s\tremaining: 7m 56s\n",
      "253:\tlearn: 0.8870343\ttest: 0.8802744\tbest: 0.8805228 (250)\ttotal: 2m 41s\tremaining: 7m 55s\n",
      "254:\tlearn: 0.8873399\ttest: 0.8803407\tbest: 0.8805228 (250)\ttotal: 2m 42s\tremaining: 7m 54s\n",
      "255:\tlearn: 0.8874975\ttest: 0.8802744\tbest: 0.8805228 (250)\ttotal: 2m 43s\tremaining: 7m 54s\n",
      "256:\tlearn: 0.8878369\ttest: 0.8805448\tbest: 0.8805448 (256)\ttotal: 2m 43s\tremaining: 7m 53s\n",
      "257:\tlearn: 0.8882806\ttest: 0.8805448\tbest: 0.8805448 (256)\ttotal: 2m 44s\tremaining: 7m 52s\n",
      "258:\tlearn: 0.8884285\ttest: 0.8807710\tbest: 0.8807710 (258)\ttotal: 2m 45s\tremaining: 7m 52s\n",
      "259:\tlearn: 0.8886004\ttest: 0.8808373\tbest: 0.8808373 (259)\ttotal: 2m 45s\tremaining: 7m 51s\n",
      "260:\tlearn: 0.8888768\ttest: 0.8813997\tbest: 0.8813997 (260)\ttotal: 2m 46s\tremaining: 7m 50s\n",
      "261:\tlearn: 0.8891152\ttest: 0.8813113\tbest: 0.8813997 (260)\ttotal: 2m 46s\tremaining: 7m 50s\n",
      "262:\tlearn: 0.8895581\ttest: 0.8816034\tbest: 0.8816034 (262)\ttotal: 2m 47s\tremaining: 7m 49s\n",
      "263:\tlearn: 0.8897816\ttest: 0.8821210\tbest: 0.8821210 (263)\ttotal: 2m 48s\tremaining: 7m 48s\n",
      "264:\tlearn: 0.8897721\ttest: 0.8822581\tbest: 0.8822581 (264)\ttotal: 2m 48s\tremaining: 7m 48s\n",
      "265:\tlearn: 0.8898102\ttest: 0.8823244\tbest: 0.8823244 (265)\ttotal: 2m 49s\tremaining: 7m 47s\n",
      "266:\tlearn: 0.8894008\ttest: 0.8820768\tbest: 0.8823244 (265)\ttotal: 2m 50s\tremaining: 7m 46s\n",
      "267:\tlearn: 0.8893534\ttest: 0.8821476\tbest: 0.8823244 (265)\ttotal: 2m 50s\tremaining: 7m 46s\n",
      "268:\tlearn: 0.8894771\ttest: 0.8818780\tbest: 0.8823244 (265)\ttotal: 2m 51s\tremaining: 7m 45s\n",
      "269:\tlearn: 0.8899101\ttest: 0.8818780\tbest: 0.8823244 (265)\ttotal: 2m 51s\tremaining: 7m 44s\n",
      "270:\tlearn: 0.8901478\ttest: 0.8826204\tbest: 0.8826204 (270)\ttotal: 2m 52s\tremaining: 7m 44s\n",
      "271:\tlearn: 0.8901954\ttest: 0.8829339\tbest: 0.8829339 (271)\ttotal: 2m 53s\tremaining: 7m 43s\n",
      "272:\tlearn: 0.8902524\ttest: 0.8827308\tbest: 0.8829339 (271)\ttotal: 2m 53s\tremaining: 7m 43s\n",
      "273:\tlearn: 0.8905946\ttest: 0.8829560\tbest: 0.8829560 (273)\ttotal: 2m 54s\tremaining: 7m 42s\n",
      "274:\tlearn: 0.8907133\ttest: 0.8827529\tbest: 0.8829560 (273)\ttotal: 2m 55s\tremaining: 7m 41s\n",
      "275:\tlearn: 0.8904948\ttest: 0.8819443\tbest: 0.8829560 (273)\ttotal: 2m 55s\tremaining: 7m 40s\n",
      "276:\tlearn: 0.8909650\ttest: 0.8824835\tbest: 0.8829560 (273)\ttotal: 2m 56s\tremaining: 7m 40s\n",
      "277:\tlearn: 0.8911407\ttest: 0.8824835\tbest: 0.8829560 (273)\ttotal: 2m 56s\tremaining: 7m 39s\n",
      "278:\tlearn: 0.8914160\ttest: 0.8827308\tbest: 0.8829560 (273)\ttotal: 2m 57s\tremaining: 7m 38s\n",
      "279:\tlearn: 0.8916532\ttest: 0.8827308\tbest: 0.8829560 (273)\ttotal: 2m 58s\tremaining: 7m 38s\n",
      "280:\tlearn: 0.8917244\ttest: 0.8830002\tbest: 0.8830002 (280)\ttotal: 2m 58s\tremaining: 7m 37s\n",
      "281:\tlearn: 0.8919472\ttest: 0.8835386\tbest: 0.8835386 (281)\ttotal: 2m 59s\tremaining: 7m 37s\n",
      "282:\tlearn: 0.8921036\ttest: 0.8835607\tbest: 0.8835607 (282)\ttotal: 3m\tremaining: 7m 36s\n",
      "283:\tlearn: 0.8922695\ttest: 0.8835165\tbest: 0.8835607 (282)\ttotal: 3m\tremaining: 7m 35s\n",
      "284:\tlearn: 0.8926532\ttest: 0.8835386\tbest: 0.8835607 (282)\ttotal: 3m 1s\tremaining: 7m 35s\n",
      "285:\tlearn: 0.8930508\ttest: 0.8833136\tbest: 0.8835607 (282)\ttotal: 3m 2s\tremaining: 7m 34s\n",
      "286:\tlearn: 0.8933442\ttest: 0.8831107\tbest: 0.8835607 (282)\ttotal: 3m 2s\tremaining: 7m 33s\n",
      "287:\tlearn: 0.8934577\ttest: 0.8833800\tbest: 0.8835607 (282)\ttotal: 3m 3s\tremaining: 7m 33s\n",
      "288:\tlearn: 0.8936847\ttest: 0.8834021\tbest: 0.8835607 (282)\ttotal: 3m 3s\tremaining: 7m 32s\n",
      "289:\tlearn: 0.8936752\ttest: 0.8836270\tbest: 0.8836270 (289)\ttotal: 3m 4s\tremaining: 7m 31s\n",
      "290:\tlearn: 0.8937415\ttest: 0.8835607\tbest: 0.8836270 (289)\ttotal: 3m 5s\tremaining: 7m 31s\n",
      "291:\tlearn: 0.8938077\ttest: 0.8835607\tbest: 0.8836270 (289)\ttotal: 3m 5s\tremaining: 7m 30s\n",
      "292:\tlearn: 0.8940863\ttest: 0.8838076\tbest: 0.8838076 (292)\ttotal: 3m 6s\tremaining: 7m 29s\n",
      "293:\tlearn: 0.8940102\ttest: 0.8837413\tbest: 0.8838076 (292)\ttotal: 3m 7s\tremaining: 7m 29s\n",
      "294:\tlearn: 0.8938493\ttest: 0.8834281\tbest: 0.8838076 (292)\ttotal: 3m 7s\tremaining: 7m 28s\n",
      "295:\tlearn: 0.8937359\ttest: 0.8840580\tbest: 0.8840580 (295)\ttotal: 3m 8s\tremaining: 7m 28s\n",
      "296:\tlearn: 0.8939345\ttest: 0.8837671\tbest: 0.8840580 (295)\ttotal: 3m 8s\tremaining: 7m 27s\n",
      "297:\tlearn: 0.8937644\ttest: 0.8838113\tbest: 0.8840580 (295)\ttotal: 3m 9s\tremaining: 7m 26s\n",
      "298:\tlearn: 0.8940049\ttest: 0.8840359\tbest: 0.8840580 (295)\ttotal: 3m 10s\tremaining: 7m 26s\n",
      "299:\tlearn: 0.8942598\ttest: 0.8840359\tbest: 0.8840580 (295)\ttotal: 3m 10s\tremaining: 7m 25s\n",
      "300:\tlearn: 0.8942836\ttest: 0.8841022\tbest: 0.8841022 (300)\ttotal: 3m 11s\tremaining: 7m 24s\n",
      "301:\tlearn: 0.8942364\ttest: 0.8841243\tbest: 0.8841243 (301)\ttotal: 3m 12s\tremaining: 7m 24s\n",
      "302:\tlearn: 0.8944535\ttest: 0.8838776\tbest: 0.8841243 (301)\ttotal: 3m 12s\tremaining: 7m 23s\n",
      "303:\tlearn: 0.8944345\ttest: 0.8835645\tbest: 0.8841243 (301)\ttotal: 3m 13s\tremaining: 7m 22s\n",
      "304:\tlearn: 0.8946940\ttest: 0.8838113\tbest: 0.8841243 (301)\ttotal: 3m 14s\tremaining: 7m 22s\n",
      "305:\tlearn: 0.8951559\ttest: 0.8842825\tbest: 0.8842825 (305)\ttotal: 3m 14s\tremaining: 7m 21s\n",
      "306:\tlearn: 0.8954626\ttest: 0.8842604\tbest: 0.8842825 (305)\ttotal: 3m 15s\tremaining: 7m 20s\n",
      "307:\tlearn: 0.8955947\ttest: 0.8845731\tbest: 0.8845731 (307)\ttotal: 3m 15s\tremaining: 7m 20s\n",
      "308:\tlearn: 0.8957591\ttest: 0.8843046\tbest: 0.8845731 (307)\ttotal: 3m 16s\tremaining: 7m 19s\n",
      "309:\tlearn: 0.8960227\ttest: 0.8843267\tbest: 0.8845731 (307)\ttotal: 3m 17s\tremaining: 7m 18s\n",
      "310:\tlearn: 0.8962392\ttest: 0.8843488\tbest: 0.8845731 (307)\ttotal: 3m 17s\tremaining: 7m 18s\n",
      "311:\tlearn: 0.8962909\ttest: 0.8845510\tbest: 0.8845731 (307)\ttotal: 3m 18s\tremaining: 7m 17s\n",
      "312:\tlearn: 0.8963094\ttest: 0.8846173\tbest: 0.8846173 (312)\ttotal: 3m 19s\tremaining: 7m 16s\n",
      "313:\tlearn: 0.8965210\ttest: 0.8844151\tbest: 0.8846173 (312)\ttotal: 3m 19s\tremaining: 7m 16s\n",
      "314:\tlearn: 0.8968033\ttest: 0.8846616\tbest: 0.8846616 (314)\ttotal: 3m 20s\tremaining: 7m 15s\n",
      "315:\tlearn: 0.8970753\ttest: 0.8843930\tbest: 0.8846616 (314)\ttotal: 3m 20s\tremaining: 7m 15s\n",
      "316:\tlearn: 0.8973104\ttest: 0.8844151\tbest: 0.8846616 (314)\ttotal: 3m 21s\tremaining: 7m 14s\n",
      "317:\tlearn: 0.8972730\ttest: 0.8844151\tbest: 0.8846616 (314)\ttotal: 3m 22s\tremaining: 7m 13s\n",
      "318:\tlearn: 0.8974612\ttest: 0.8841685\tbest: 0.8846616 (314)\ttotal: 3m 22s\tremaining: 7m 13s\n",
      "319:\tlearn: 0.8975080\ttest: 0.8841685\tbest: 0.8846616 (314)\ttotal: 3m 23s\tremaining: 7m 12s\n",
      "320:\tlearn: 0.8975827\ttest: 0.8840801\tbest: 0.8846616 (314)\ttotal: 3m 24s\tremaining: 7m 11s\n",
      "321:\tlearn: 0.8976581\ttest: 0.8840580\tbest: 0.8846616 (314)\ttotal: 3m 24s\tremaining: 7m 11s\n",
      "322:\tlearn: 0.8976486\ttest: 0.8841906\tbest: 0.8846616 (314)\ttotal: 3m 25s\tremaining: 7m 10s\n",
      "323:\tlearn: 0.8977104\ttest: 0.8842127\tbest: 0.8846616 (314)\ttotal: 3m 25s\tremaining: 7m 9s\n",
      "324:\tlearn: 0.8978557\ttest: 0.8844151\tbest: 0.8846616 (314)\ttotal: 3m 26s\tremaining: 7m 9s\n",
      "325:\tlearn: 0.8980573\ttest: 0.8845952\tbest: 0.8846616 (314)\ttotal: 3m 27s\tremaining: 7m 8s\n",
      "326:\tlearn: 0.8982635\ttest: 0.8845731\tbest: 0.8846616 (314)\ttotal: 3m 27s\tremaining: 7m 7s\n",
      "327:\tlearn: 0.8982730\ttest: 0.8846395\tbest: 0.8846616 (314)\ttotal: 3m 28s\tremaining: 7m 7s\n",
      "328:\tlearn: 0.8982968\ttest: 0.8849300\tbest: 0.8849300 (328)\ttotal: 3m 29s\tremaining: 7m 6s\n",
      "329:\tlearn: 0.8985403\ttest: 0.8854225\tbest: 0.8854225 (329)\ttotal: 3m 29s\tremaining: 7m 5s\n",
      "330:\tlearn: 0.8985545\ttest: 0.8854225\tbest: 0.8854225 (329)\ttotal: 3m 30s\tremaining: 7m 5s\n",
      "331:\tlearn: 0.8988177\ttest: 0.8854667\tbest: 0.8854667 (331)\ttotal: 3m 31s\tremaining: 7m 4s\n",
      "332:\tlearn: 0.8989025\ttest: 0.8854446\tbest: 0.8854667 (331)\ttotal: 3m 31s\tremaining: 7m 3s\n",
      "333:\tlearn: 0.8990942\ttest: 0.8849300\tbest: 0.8854667 (331)\ttotal: 3m 32s\tremaining: 7m 3s\n",
      "334:\tlearn: 0.8991829\ttest: 0.8848858\tbest: 0.8854667 (331)\ttotal: 3m 32s\tremaining: 7m 2s\n",
      "335:\tlearn: 0.8992954\ttest: 0.8848858\tbest: 0.8854667 (331)\ttotal: 3m 33s\tremaining: 7m 2s\n",
      "336:\tlearn: 0.8994766\ttest: 0.8844184\tbest: 0.8854667 (331)\ttotal: 3m 34s\tremaining: 7m 1s\n",
      "337:\tlearn: 0.8995928\ttest: 0.8846869\tbest: 0.8854667 (331)\ttotal: 3m 34s\tremaining: 7m\n",
      "338:\tlearn: 0.8995034\ttest: 0.8844184\tbest: 0.8854667 (331)\ttotal: 3m 35s\tremaining: 7m\n",
      "339:\tlearn: 0.8997519\ttest: 0.8844847\tbest: 0.8854667 (331)\ttotal: 3m 36s\tremaining: 6m 59s\n",
      "340:\tlearn: 0.8999346\ttest: 0.8845731\tbest: 0.8854667 (331)\ttotal: 3m 36s\tremaining: 6m 58s\n",
      "341:\tlearn: 0.9000555\ttest: 0.8847753\tbest: 0.8854667 (331)\ttotal: 3m 37s\tremaining: 6m 58s\n",
      "342:\tlearn: 0.9002610\ttest: 0.8850437\tbest: 0.8854667 (331)\ttotal: 3m 37s\tremaining: 6m 57s\n",
      "343:\tlearn: 0.9005092\ttest: 0.8847753\tbest: 0.8854667 (331)\ttotal: 3m 38s\tremaining: 6m 56s\n",
      "344:\tlearn: 0.9005330\ttest: 0.8847090\tbest: 0.8854667 (331)\ttotal: 3m 39s\tremaining: 6m 56s\n",
      "345:\tlearn: 0.9005824\ttest: 0.8846206\tbest: 0.8854667 (331)\ttotal: 3m 39s\tremaining: 6m 55s\n",
      "346:\tlearn: 0.9008665\ttest: 0.8850658\tbest: 0.8854667 (331)\ttotal: 3m 40s\tremaining: 6m 55s\n",
      "347:\tlearn: 0.9008951\ttest: 0.8850658\tbest: 0.8854667 (331)\ttotal: 3m 41s\tremaining: 6m 54s\n",
      "348:\tlearn: 0.9008713\ttest: 0.8850658\tbest: 0.8854667 (331)\ttotal: 3m 41s\tremaining: 6m 53s\n",
      "349:\tlearn: 0.9011183\ttest: 0.8853119\tbest: 0.8854667 (331)\ttotal: 3m 42s\tremaining: 6m 53s\n",
      "350:\tlearn: 0.9014591\ttest: 0.8853561\tbest: 0.8854667 (331)\ttotal: 3m 43s\tremaining: 6m 52s\n",
      "351:\tlearn: 0.9015426\ttest: 0.8850658\tbest: 0.8854667 (331)\ttotal: 3m 43s\tremaining: 6m 51s\n",
      "352:\tlearn: 0.9015521\ttest: 0.8850879\tbest: 0.8854667 (331)\ttotal: 3m 44s\tremaining: 6m 51s\n",
      "353:\tlearn: 0.9015283\ttest: 0.8853782\tbest: 0.8854667 (331)\ttotal: 3m 44s\tremaining: 6m 50s\n",
      "354:\tlearn: 0.9017475\ttest: 0.8856022\tbest: 0.8856022 (354)\ttotal: 3m 45s\tremaining: 6m 49s\n",
      "355:\tlearn: 0.9016963\ttest: 0.8856022\tbest: 0.8856022 (354)\ttotal: 3m 46s\tremaining: 6m 49s\n",
      "356:\tlearn: 0.9018690\ttest: 0.8855580\tbest: 0.8856022 (354)\ttotal: 3m 46s\tremaining: 6m 48s\n",
      "357:\tlearn: 0.9019667\ttest: 0.8854916\tbest: 0.8856022 (354)\ttotal: 3m 47s\tremaining: 6m 47s\n",
      "358:\tlearn: 0.9021298\ttest: 0.8852456\tbest: 0.8856022 (354)\ttotal: 3m 48s\tremaining: 6m 47s\n",
      "359:\tlearn: 0.9022833\ttest: 0.8852677\tbest: 0.8856022 (354)\ttotal: 3m 48s\tremaining: 6m 46s\n",
      "360:\tlearn: 0.9024463\ttest: 0.8853119\tbest: 0.8856022 (354)\ttotal: 3m 49s\tremaining: 6m 45s\n",
      "361:\tlearn: 0.9024463\ttest: 0.8856022\tbest: 0.8856022 (354)\ttotal: 3m 49s\tremaining: 6m 45s\n",
      "362:\tlearn: 0.9025023\ttest: 0.8855801\tbest: 0.8856022 (354)\ttotal: 3m 50s\tremaining: 6m 44s\n",
      "363:\tlearn: 0.9025118\ttest: 0.8855801\tbest: 0.8856022 (354)\ttotal: 3m 51s\tremaining: 6m 44s\n",
      "364:\tlearn: 0.9025772\ttest: 0.8856022\tbest: 0.8856022 (354)\ttotal: 3m 51s\tremaining: 6m 43s\n",
      "365:\tlearn: 0.9029066\ttest: 0.8858039\tbest: 0.8858039 (365)\ttotal: 3m 52s\tremaining: 6m 42s\n",
      "366:\tlearn: 0.9026141\ttest: 0.8862954\tbest: 0.8862954 (366)\ttotal: 3m 53s\tremaining: 6m 42s\n",
      "367:\tlearn: 0.9029018\ttest: 0.8862733\tbest: 0.8862954 (366)\ttotal: 3m 53s\tremaining: 6m 41s\n",
      "368:\tlearn: 0.9029197\ttest: 0.8864747\tbest: 0.8864747 (368)\ttotal: 3m 54s\tremaining: 6m 40s\n",
      "369:\tlearn: 0.9031181\ttest: 0.8862070\tbest: 0.8864747 (368)\ttotal: 3m 55s\tremaining: 6m 40s\n",
      "370:\tlearn: 0.9031371\ttest: 0.8862070\tbest: 0.8864747 (368)\ttotal: 3m 55s\tremaining: 6m 39s\n",
      "371:\tlearn: 0.9033176\ttest: 0.8864084\tbest: 0.8864747 (368)\ttotal: 3m 56s\tremaining: 6m 38s\n",
      "372:\tlearn: 0.9036287\ttest: 0.8864084\tbest: 0.8864747 (368)\ttotal: 3m 56s\tremaining: 6m 38s\n",
      "373:\tlearn: 0.9036525\ttest: 0.8864084\tbest: 0.8864747 (368)\ttotal: 3m 57s\tremaining: 6m 37s\n",
      "374:\tlearn: 0.9036573\ttest: 0.8864084\tbest: 0.8864747 (368)\ttotal: 3m 58s\tremaining: 6m 36s\n",
      "375:\tlearn: 0.9035790\ttest: 0.8863863\tbest: 0.8864747 (368)\ttotal: 3m 58s\tremaining: 6m 36s\n",
      "376:\tlearn: 0.9032738\ttest: 0.8866097\tbest: 0.8866097 (376)\ttotal: 3m 59s\tremaining: 6m 35s\n",
      "377:\tlearn: 0.9032370\ttest: 0.8866318\tbest: 0.8866318 (377)\ttotal: 4m\tremaining: 6m 34s\n",
      "378:\tlearn: 0.9034045\ttest: 0.8866539\tbest: 0.8866539 (378)\ttotal: 4m\tremaining: 6m 34s\n",
      "379:\tlearn: 0.9035340\ttest: 0.8866981\tbest: 0.8866981 (379)\ttotal: 4m 1s\tremaining: 6m 33s\n",
      "380:\tlearn: 0.9038130\ttest: 0.8865189\tbest: 0.8866981 (379)\ttotal: 4m 1s\tremaining: 6m 33s\n",
      "381:\tlearn: 0.9038225\ttest: 0.8865189\tbest: 0.8866981 (379)\ttotal: 4m 2s\tremaining: 6m 32s\n",
      "382:\tlearn: 0.9039328\ttest: 0.8862954\tbest: 0.8866981 (379)\ttotal: 4m 3s\tremaining: 6m 31s\n",
      "383:\tlearn: 0.9038545\ttest: 0.8862954\tbest: 0.8866981 (379)\ttotal: 4m 3s\tremaining: 6m 31s\n",
      "384:\tlearn: 0.9042531\ttest: 0.8865189\tbest: 0.8866981 (379)\ttotal: 4m 4s\tremaining: 6m 30s\n",
      "385:\tlearn: 0.9044251\ttest: 0.8862512\tbest: 0.8866981 (379)\ttotal: 4m 5s\tremaining: 6m 29s\n",
      "386:\tlearn: 0.9045590\ttest: 0.8861849\tbest: 0.8866981 (379)\ttotal: 4m 5s\tremaining: 6m 29s\n",
      "387:\tlearn: 0.9045876\ttest: 0.8861628\tbest: 0.8866981 (379)\ttotal: 4m 6s\tremaining: 6m 28s\n",
      "388:\tlearn: 0.9047357\ttest: 0.8859613\tbest: 0.8866981 (379)\ttotal: 4m 6s\tremaining: 6m 27s\n",
      "389:\tlearn: 0.9046718\ttest: 0.8860497\tbest: 0.8866981 (379)\ttotal: 4m 7s\tremaining: 6m 27s\n",
      "390:\tlearn: 0.9047390\ttest: 0.8865410\tbest: 0.8866981 (379)\ttotal: 4m 8s\tremaining: 6m 26s\n",
      "391:\tlearn: 0.9049618\ttest: 0.8865632\tbest: 0.8866981 (379)\ttotal: 4m 8s\tremaining: 6m 25s\n",
      "392:\tlearn: 0.9049014\ttest: 0.8865853\tbest: 0.8866981 (379)\ttotal: 4m 9s\tremaining: 6m 25s\n",
      "393:\tlearn: 0.9050127\ttest: 0.8866074\tbest: 0.8866981 (379)\ttotal: 4m 10s\tremaining: 6m 24s\n",
      "394:\tlearn: 0.9050080\ttest: 0.8867865\tbest: 0.8867865 (394)\ttotal: 4m 10s\tremaining: 6m 23s\n",
      "395:\tlearn: 0.9052483\ttest: 0.8867202\tbest: 0.8867865 (394)\ttotal: 4m 11s\tremaining: 6m 23s\n",
      "396:\tlearn: 0.9055631\ttest: 0.8869214\tbest: 0.8869214 (396)\ttotal: 4m 11s\tremaining: 6m 22s\n",
      "397:\tlearn: 0.9054851\ttest: 0.8870098\tbest: 0.8870098 (397)\ttotal: 4m 12s\tremaining: 6m 21s\n",
      "398:\tlearn: 0.9055090\ttest: 0.8870098\tbest: 0.8870098 (397)\ttotal: 4m 13s\tremaining: 6m 21s\n",
      "399:\tlearn: 0.9054628\ttest: 0.8870541\tbest: 0.8870541 (399)\ttotal: 4m 13s\tremaining: 6m 20s\n",
      "400:\tlearn: 0.9054167\ttest: 0.8870762\tbest: 0.8870762 (400)\ttotal: 4m 14s\tremaining: 6m 19s\n",
      "401:\tlearn: 0.9055646\ttest: 0.8870541\tbest: 0.8870762 (400)\ttotal: 4m 14s\tremaining: 6m 19s\n",
      "402:\tlearn: 0.9055232\ttest: 0.8870762\tbest: 0.8870762 (400)\ttotal: 4m 15s\tremaining: 6m 18s\n",
      "403:\tlearn: 0.9057443\ttest: 0.8867644\tbest: 0.8870762 (400)\ttotal: 4m 16s\tremaining: 6m 18s\n",
      "404:\tlearn: 0.9057951\ttest: 0.8872772\tbest: 0.8872772 (404)\ttotal: 4m 16s\tremaining: 6m 17s\n",
      "405:\tlearn: 0.9059206\ttest: 0.8870098\tbest: 0.8872772 (404)\ttotal: 4m 17s\tremaining: 6m 16s\n",
      "406:\tlearn: 0.9059349\ttest: 0.8870098\tbest: 0.8872772 (404)\ttotal: 4m 18s\tremaining: 6m 16s\n",
      "407:\tlearn: 0.9060080\ttest: 0.8872330\tbest: 0.8872772 (404)\ttotal: 4m 18s\tremaining: 6m 15s\n",
      "408:\tlearn: 0.9060859\ttest: 0.8872551\tbest: 0.8872772 (404)\ttotal: 4m 19s\tremaining: 6m 14s\n",
      "409:\tlearn: 0.9061589\ttest: 0.8875445\tbest: 0.8875445 (409)\ttotal: 4m 20s\tremaining: 6m 14s\n",
      "410:\tlearn: 0.9061685\ttest: 0.8875445\tbest: 0.8875445 (409)\ttotal: 4m 20s\tremaining: 6m 13s\n",
      "411:\tlearn: 0.9064574\ttest: 0.8879682\tbest: 0.8879682 (411)\ttotal: 4m 21s\tremaining: 6m 12s\n",
      "412:\tlearn: 0.9064574\ttest: 0.8879682\tbest: 0.8879682 (411)\ttotal: 4m 21s\tremaining: 6m 12s\n",
      "413:\tlearn: 0.9065780\ttest: 0.8882130\tbest: 0.8882130 (413)\ttotal: 4m 22s\tremaining: 6m 11s\n",
      "414:\tlearn: 0.9064114\ttest: 0.8882352\tbest: 0.8882352 (414)\ttotal: 4m 23s\tremaining: 6m 10s\n",
      "415:\tlearn: 0.9065827\ttest: 0.8885020\tbest: 0.8885020 (415)\ttotal: 4m 23s\tremaining: 6m 10s\n",
      "416:\tlearn: 0.9065970\ttest: 0.8885020\tbest: 0.8885020 (415)\ttotal: 4m 24s\tremaining: 6m 9s\n",
      "417:\tlearn: 0.9068191\ttest: 0.8885241\tbest: 0.8885241 (417)\ttotal: 4m 24s\tremaining: 6m 8s\n",
      "418:\tlearn: 0.9067953\ttest: 0.8885241\tbest: 0.8885241 (417)\ttotal: 4m 25s\tremaining: 6m 8s\n",
      "419:\tlearn: 0.9069380\ttest: 0.8887024\tbest: 0.8887024 (419)\ttotal: 4m 26s\tremaining: 6m 7s\n",
      "420:\tlearn: 0.9070395\ttest: 0.8891914\tbest: 0.8891914 (420)\ttotal: 4m 26s\tremaining: 6m 7s\n",
      "421:\tlearn: 0.9071045\ttest: 0.8891914\tbest: 0.8891914 (420)\ttotal: 4m 27s\tremaining: 6m 6s\n",
      "422:\tlearn: 0.9071457\ttest: 0.8891692\tbest: 0.8891914 (420)\ttotal: 4m 28s\tremaining: 6m 5s\n",
      "423:\tlearn: 0.9073533\ttest: 0.8891471\tbest: 0.8891914 (420)\ttotal: 4m 28s\tremaining: 6m 5s\n",
      "424:\tlearn: 0.9073233\ttest: 0.8886582\tbest: 0.8891914 (420)\ttotal: 4m 29s\tremaining: 6m 4s\n",
      "425:\tlearn: 0.9074105\ttest: 0.8886803\tbest: 0.8891914 (420)\ttotal: 4m 30s\tremaining: 6m 3s\n",
      "426:\tlearn: 0.9074802\ttest: 0.8884357\tbest: 0.8891914 (420)\ttotal: 4m 30s\tremaining: 6m 3s\n",
      "427:\tlearn: 0.9076228\ttest: 0.8886582\tbest: 0.8891914 (420)\ttotal: 4m 31s\tremaining: 6m 2s\n",
      "428:\tlearn: 0.9078224\ttest: 0.8884578\tbest: 0.8891914 (420)\ttotal: 4m 31s\tremaining: 6m 1s\n",
      "429:\tlearn: 0.9079220\ttest: 0.8887467\tbest: 0.8891914 (420)\ttotal: 4m 32s\tremaining: 6m 1s\n",
      "430:\tlearn: 0.9079268\ttest: 0.8887467\tbest: 0.8891914 (420)\ttotal: 4m 33s\tremaining: 6m\n",
      "431:\tlearn: 0.9080328\ttest: 0.8887467\tbest: 0.8891914 (420)\ttotal: 4m 33s\tremaining: 6m\n",
      "432:\tlearn: 0.9080328\ttest: 0.8887467\tbest: 0.8891914 (420)\ttotal: 4m 34s\tremaining: 5m 59s\n",
      "433:\tlearn: 0.9079709\ttest: 0.8888584\tbest: 0.8891914 (420)\ttotal: 4m 35s\tremaining: 5m 58s\n",
      "434:\tlearn: 0.9078887\ttest: 0.8888584\tbest: 0.8891914 (420)\ttotal: 4m 35s\tremaining: 5m 58s\n",
      "435:\tlearn: 0.9080960\ttest: 0.8887245\tbest: 0.8891914 (420)\ttotal: 4m 36s\tremaining: 5m 57s\n",
      "436:\tlearn: 0.9077635\ttest: 0.8886803\tbest: 0.8891914 (420)\ttotal: 4m 36s\tremaining: 5m 56s\n",
      "437:\tlearn: 0.9079947\ttest: 0.8886803\tbest: 0.8891914 (420)\ttotal: 4m 37s\tremaining: 5m 56s\n",
      "438:\tlearn: 0.9082812\ttest: 0.8884578\tbest: 0.8891914 (420)\ttotal: 4m 38s\tremaining: 5m 55s\n",
      "439:\tlearn: 0.9083051\ttest: 0.8884578\tbest: 0.8891914 (420)\ttotal: 4m 38s\tremaining: 5m 54s\n",
      "440:\tlearn: 0.9083700\ttest: 0.8889469\tbest: 0.8891914 (420)\ttotal: 4m 39s\tremaining: 5m 54s\n",
      "441:\tlearn: 0.9084712\ttest: 0.8889469\tbest: 0.8891914 (420)\ttotal: 4m 40s\tremaining: 5m 53s\n",
      "442:\tlearn: 0.9085867\ttest: 0.8887024\tbest: 0.8891914 (420)\ttotal: 4m 40s\tremaining: 5m 53s\n",
      "443:\tlearn: 0.9086831\ttest: 0.8887245\tbest: 0.8891914 (420)\ttotal: 4m 41s\tremaining: 5m 52s\n",
      "444:\tlearn: 0.9088301\ttest: 0.8887688\tbest: 0.8891914 (420)\ttotal: 4m 42s\tremaining: 5m 51s\n",
      "445:\tlearn: 0.9088444\ttest: 0.8887688\tbest: 0.8891914 (420)\ttotal: 4m 42s\tremaining: 5m 51s\n",
      "446:\tlearn: 0.9091049\ttest: 0.8889691\tbest: 0.8891914 (420)\ttotal: 4m 43s\tremaining: 5m 50s\n",
      "447:\tlearn: 0.9092250\ttest: 0.8889469\tbest: 0.8891914 (420)\ttotal: 4m 43s\tremaining: 5m 49s\n",
      "448:\tlearn: 0.9093690\ttest: 0.8889469\tbest: 0.8891914 (420)\ttotal: 4m 44s\tremaining: 5m 49s\n",
      "449:\tlearn: 0.9098769\ttest: 0.8889469\tbest: 0.8891914 (420)\ttotal: 4m 45s\tremaining: 5m 48s\n",
      "450:\tlearn: 0.9098816\ttest: 0.8889469\tbest: 0.8891914 (420)\ttotal: 4m 45s\tremaining: 5m 47s\n",
      "451:\tlearn: 0.9099778\ttest: 0.8894357\tbest: 0.8894357 (451)\ttotal: 4m 46s\tremaining: 5m 47s\n",
      "452:\tlearn: 0.9100016\ttest: 0.8897241\tbest: 0.8897241 (452)\ttotal: 4m 47s\tremaining: 5m 46s\n",
      "453:\tlearn: 0.9101939\ttest: 0.8896799\tbest: 0.8897241 (452)\ttotal: 4m 47s\tremaining: 5m 45s\n",
      "454:\tlearn: 0.9101987\ttest: 0.8896799\tbest: 0.8897241 (452)\ttotal: 4m 48s\tremaining: 5m 45s\n",
      "455:\tlearn: 0.9102539\ttest: 0.8897020\tbest: 0.8897241 (452)\ttotal: 4m 48s\tremaining: 5m 44s\n",
      "456:\tlearn: 0.9104100\ttest: 0.8894578\tbest: 0.8897241 (452)\ttotal: 4m 49s\tremaining: 5m 44s\n",
      "457:\tlearn: 0.9106165\ttest: 0.8899461\tbest: 0.8899461 (457)\ttotal: 4m 50s\tremaining: 5m 43s\n",
      "458:\tlearn: 0.9106355\ttest: 0.8899461\tbest: 0.8899461 (457)\ttotal: 4m 50s\tremaining: 5m 42s\n",
      "459:\tlearn: 0.9107002\ttest: 0.8902343\tbest: 0.8902343 (459)\ttotal: 4m 51s\tremaining: 5m 42s\n",
      "460:\tlearn: 0.9106594\ttest: 0.8905446\tbest: 0.8905446 (460)\ttotal: 4m 52s\tremaining: 5m 41s\n",
      "461:\tlearn: 0.9106089\ttest: 0.8905668\tbest: 0.8905668 (461)\ttotal: 4m 52s\tremaining: 5m 40s\n",
      "462:\tlearn: 0.9108106\ttest: 0.8905668\tbest: 0.8905668 (461)\ttotal: 4m 53s\tremaining: 5m 40s\n",
      "463:\tlearn: 0.9109638\ttest: 0.8902786\tbest: 0.8905668 (461)\ttotal: 4m 53s\tremaining: 5m 39s\n",
      "464:\tlearn: 0.9109638\ttest: 0.8902565\tbest: 0.8905668 (461)\ttotal: 4m 54s\tremaining: 5m 38s\n",
      "465:\tlearn: 0.9110333\ttest: 0.8902565\tbest: 0.8905668 (461)\ttotal: 4m 55s\tremaining: 5m 38s\n",
      "466:\tlearn: 0.9113593\ttest: 0.8905446\tbest: 0.8905668 (461)\ttotal: 4m 55s\tremaining: 5m 37s\n",
      "467:\tlearn: 0.9114144\ttest: 0.8905668\tbest: 0.8905668 (461)\ttotal: 4m 56s\tremaining: 5m 36s\n",
      "468:\tlearn: 0.9113593\ttest: 0.8906556\tbest: 0.8906556 (468)\ttotal: 4m 57s\tremaining: 5m 36s\n",
      "469:\tlearn: 0.9114648\ttest: 0.8906777\tbest: 0.8906777 (469)\ttotal: 4m 57s\tremaining: 5m 35s\n",
      "470:\tlearn: 0.9115056\ttest: 0.8904118\tbest: 0.8906777 (469)\ttotal: 4m 58s\tremaining: 5m 35s\n",
      "471:\tlearn: 0.9114049\ttest: 0.8901901\tbest: 0.8906777 (469)\ttotal: 4m 58s\tremaining: 5m 34s\n",
      "472:\tlearn: 0.9115703\ttest: 0.8901901\tbest: 0.8906777 (469)\ttotal: 4m 59s\tremaining: 5m 33s\n",
      "473:\tlearn: 0.9115750\ttest: 0.8901901\tbest: 0.8906777 (469)\ttotal: 5m\tremaining: 5m 33s\n",
      "474:\tlearn: 0.9117165\ttest: 0.8901680\tbest: 0.8906777 (469)\ttotal: 5m\tremaining: 5m 32s\n",
      "475:\tlearn: 0.9117546\ttest: 0.8899461\tbest: 0.8906777 (469)\ttotal: 5m 1s\tremaining: 5m 31s\n",
      "476:\tlearn: 0.9118913\ttest: 0.8900125\tbest: 0.8906777 (469)\ttotal: 5m 2s\tremaining: 5m 31s\n",
      "477:\tlearn: 0.9118982\ttest: 0.8899682\tbest: 0.8906777 (469)\ttotal: 5m 2s\tremaining: 5m 30s\n",
      "478:\tlearn: 0.9119077\ttest: 0.8899461\tbest: 0.8906777 (469)\ttotal: 5m 3s\tremaining: 5m 29s\n",
      "479:\tlearn: 0.9119173\ttest: 0.8899682\tbest: 0.8906777 (469)\ttotal: 5m 3s\tremaining: 5m 29s\n",
      "480:\tlearn: 0.9120036\ttest: 0.8899904\tbest: 0.8906777 (469)\ttotal: 5m 4s\tremaining: 5m 28s\n",
      "481:\tlearn: 0.9120608\ttest: 0.8899904\tbest: 0.8906777 (469)\ttotal: 5m 5s\tremaining: 5m 27s\n",
      "482:\tlearn: 0.9120608\ttest: 0.8902565\tbest: 0.8906777 (469)\ttotal: 5m 5s\tremaining: 5m 27s\n",
      "483:\tlearn: 0.9120799\ttest: 0.8902343\tbest: 0.8906777 (469)\ttotal: 5m 6s\tremaining: 5m 26s\n",
      "484:\tlearn: 0.9122165\ttest: 0.8902122\tbest: 0.8906777 (469)\ttotal: 5m 7s\tremaining: 5m 26s\n",
      "485:\tlearn: 0.9124514\ttest: 0.8903454\tbest: 0.8906777 (469)\ttotal: 5m 7s\tremaining: 5m 25s\n",
      "486:\tlearn: 0.9126858\ttest: 0.8908993\tbest: 0.8908993 (486)\ttotal: 5m 8s\tremaining: 5m 24s\n",
      "487:\tlearn: 0.9126883\ttest: 0.8905228\tbest: 0.8908993 (486)\ttotal: 5m 8s\tremaining: 5m 24s\n",
      "488:\tlearn: 0.9127602\ttest: 0.8904565\tbest: 0.8908993 (486)\ttotal: 5m 9s\tremaining: 5m 23s\n",
      "489:\tlearn: 0.9127338\ttest: 0.8904565\tbest: 0.8908993 (486)\ttotal: 5m 10s\tremaining: 5m 22s\n",
      "490:\tlearn: 0.9128391\ttest: 0.8905228\tbest: 0.8908993 (486)\ttotal: 5m 10s\tremaining: 5m 22s\n",
      "491:\tlearn: 0.9128486\ttest: 0.8905450\tbest: 0.8908993 (486)\ttotal: 5m 11s\tremaining: 5m 21s\n",
      "492:\tlearn: 0.9128629\ttest: 0.8905450\tbest: 0.8908993 (486)\ttotal: 5m 12s\tremaining: 5m 20s\n",
      "493:\tlearn: 0.9128724\ttest: 0.8905671\tbest: 0.8908993 (486)\ttotal: 5m 12s\tremaining: 5m 20s\n",
      "494:\tlearn: 0.9129322\ttest: 0.8906335\tbest: 0.8908993 (486)\ttotal: 5m 13s\tremaining: 5m 19s\n",
      "495:\tlearn: 0.9133697\ttest: 0.8906113\tbest: 0.8908993 (486)\ttotal: 5m 13s\tremaining: 5m 19s\n",
      "496:\tlearn: 0.9133936\ttest: 0.8908329\tbest: 0.8908993 (486)\ttotal: 5m 14s\tremaining: 5m 18s\n",
      "497:\tlearn: 0.9134485\ttest: 0.8908550\tbest: 0.8908993 (486)\ttotal: 5m 15s\tremaining: 5m 17s\n",
      "498:\tlearn: 0.9135035\ttest: 0.8906113\tbest: 0.8908993 (486)\ttotal: 5m 15s\tremaining: 5m 17s\n",
      "499:\tlearn: 0.9137543\ttest: 0.8906335\tbest: 0.8908993 (486)\ttotal: 5m 16s\tremaining: 5m 16s\n",
      "500:\tlearn: 0.9137686\ttest: 0.8906335\tbest: 0.8908993 (486)\ttotal: 5m 17s\tremaining: 5m 15s\n",
      "501:\tlearn: 0.9137280\ttest: 0.8906335\tbest: 0.8908993 (486)\ttotal: 5m 17s\tremaining: 5m 15s\n",
      "502:\tlearn: 0.9138020\ttest: 0.8906113\tbest: 0.8908993 (486)\ttotal: 5m 18s\tremaining: 5m 14s\n",
      "503:\tlearn: 0.9138020\ttest: 0.8906335\tbest: 0.8908993 (486)\ttotal: 5m 19s\tremaining: 5m 13s\n",
      "504:\tlearn: 0.9139524\ttest: 0.8906335\tbest: 0.8908993 (486)\ttotal: 5m 19s\tremaining: 5m 13s\n",
      "505:\tlearn: 0.9138737\ttest: 0.8906556\tbest: 0.8908993 (486)\ttotal: 5m 20s\tremaining: 5m 12s\n",
      "506:\tlearn: 0.9137638\ttest: 0.8906777\tbest: 0.8908993 (486)\ttotal: 5m 20s\tremaining: 5m 12s\n",
      "507:\tlearn: 0.9137829\ttest: 0.8906777\tbest: 0.8908993 (486)\ttotal: 5m 21s\tremaining: 5m 11s\n",
      "508:\tlearn: 0.9138283\ttest: 0.8909657\tbest: 0.8909657 (508)\ttotal: 5m 22s\tremaining: 5m 10s\n",
      "509:\tlearn: 0.9138378\ttest: 0.8909878\tbest: 0.8909878 (509)\ttotal: 5m 22s\tremaining: 5m 10s\n",
      "510:\tlearn: 0.9138569\ttest: 0.8909878\tbest: 0.8909878 (509)\ttotal: 5m 23s\tremaining: 5m 9s\n",
      "511:\tlearn: 0.9138115\ttest: 0.8909878\tbest: 0.8909878 (509)\ttotal: 5m 23s\tremaining: 5m 8s\n",
      "512:\tlearn: 0.9141386\ttest: 0.8909657\tbest: 0.8909878 (509)\ttotal: 5m 24s\tremaining: 5m 8s\n",
      "513:\tlearn: 0.9139930\ttest: 0.8911207\tbest: 0.8911207 (513)\ttotal: 5m 25s\tremaining: 5m 7s\n",
      "514:\tlearn: 0.9141124\ttest: 0.8911207\tbest: 0.8911207 (513)\ttotal: 5m 25s\tremaining: 5m 6s\n",
      "515:\tlearn: 0.9142579\ttest: 0.8914306\tbest: 0.8914306 (515)\ttotal: 5m 26s\tremaining: 5m 6s\n",
      "516:\tlearn: 0.9143438\ttest: 0.8914306\tbest: 0.8914306 (515)\ttotal: 5m 27s\tremaining: 5m 5s\n",
      "517:\tlearn: 0.9142174\ttest: 0.8913863\tbest: 0.8914306 (515)\ttotal: 5m 27s\tremaining: 5m 4s\n",
      "518:\tlearn: 0.9142030\ttest: 0.8913199\tbest: 0.8914306 (515)\ttotal: 5m 28s\tremaining: 5m 4s\n",
      "519:\tlearn: 0.9142770\ttest: 0.8910986\tbest: 0.8914306 (515)\ttotal: 5m 28s\tremaining: 5m 3s\n",
      "520:\tlearn: 0.9143558\ttest: 0.8914084\tbest: 0.8914306 (515)\ttotal: 5m 29s\tremaining: 5m 3s\n",
      "521:\tlearn: 0.9144703\ttest: 0.8912757\tbest: 0.8914306 (515)\ttotal: 5m 30s\tremaining: 5m 2s\n",
      "522:\tlearn: 0.9147446\ttest: 0.8912757\tbest: 0.8914306 (515)\ttotal: 5m 30s\tremaining: 5m 1s\n",
      "523:\tlearn: 0.9146993\ttest: 0.8912757\tbest: 0.8914306 (515)\ttotal: 5m 31s\tremaining: 5m 1s\n",
      "524:\tlearn: 0.9148518\ttest: 0.8909878\tbest: 0.8914306 (515)\ttotal: 5m 32s\tremaining: 5m\n",
      "525:\tlearn: 0.9148113\ttest: 0.8909878\tbest: 0.8914306 (515)\ttotal: 5m 32s\tremaining: 4m 59s\n",
      "526:\tlearn: 0.9150615\ttest: 0.8912757\tbest: 0.8914306 (515)\ttotal: 5m 33s\tremaining: 4m 59s\n",
      "527:\tlearn: 0.9151712\ttest: 0.8912535\tbest: 0.8914306 (515)\ttotal: 5m 33s\tremaining: 4m 58s\n",
      "528:\tlearn: 0.9150806\ttest: 0.8910100\tbest: 0.8914306 (515)\ttotal: 5m 34s\tremaining: 4m 57s\n",
      "529:\tlearn: 0.9150401\ttest: 0.8910321\tbest: 0.8914306 (515)\ttotal: 5m 35s\tremaining: 4m 57s\n",
      "530:\tlearn: 0.9148281\ttest: 0.8910321\tbest: 0.8914306 (515)\ttotal: 5m 35s\tremaining: 4m 56s\n",
      "531:\tlearn: 0.9150783\ttest: 0.8908327\tbest: 0.8914306 (515)\ttotal: 5m 36s\tremaining: 4m 56s\n",
      "532:\tlearn: 0.9151236\ttest: 0.8908106\tbest: 0.8914306 (515)\ttotal: 5m 37s\tremaining: 4m 55s\n",
      "533:\tlearn: 0.9153690\ttest: 0.8908106\tbest: 0.8914306 (515)\ttotal: 5m 37s\tremaining: 4m 54s\n",
      "534:\tlearn: 0.9153142\ttest: 0.8908548\tbest: 0.8914306 (515)\ttotal: 5m 38s\tremaining: 4m 54s\n",
      "535:\tlearn: 0.9156238\ttest: 0.8910764\tbest: 0.8914306 (515)\ttotal: 5m 39s\tremaining: 4m 53s\n",
      "536:\tlearn: 0.9156238\ttest: 0.8910764\tbest: 0.8914306 (515)\ttotal: 5m 39s\tremaining: 4m 52s\n",
      "537:\tlearn: 0.9156451\ttest: 0.8913642\tbest: 0.8914306 (515)\ttotal: 5m 40s\tremaining: 4m 52s\n",
      "538:\tlearn: 0.9157998\ttest: 0.8908991\tbest: 0.8914306 (515)\ttotal: 5m 40s\tremaining: 4m 51s\n",
      "539:\tlearn: 0.9158046\ttest: 0.8908991\tbest: 0.8914306 (515)\ttotal: 5m 41s\tremaining: 4m 50s\n",
      "540:\tlearn: 0.9157642\ttest: 0.8910985\tbest: 0.8914306 (515)\ttotal: 5m 42s\tremaining: 4m 50s\n",
      "541:\tlearn: 0.9157737\ttest: 0.8910985\tbest: 0.8914306 (515)\ttotal: 5m 42s\tremaining: 4m 49s\n",
      "542:\tlearn: 0.9158119\ttest: 0.8908770\tbest: 0.8914306 (515)\ttotal: 5m 43s\tremaining: 4m 49s\n",
      "543:\tlearn: 0.9158167\ttest: 0.8908991\tbest: 0.8914306 (515)\ttotal: 5m 44s\tremaining: 4m 48s\n",
      "544:\tlearn: 0.9158715\ttest: 0.8908991\tbest: 0.8914306 (515)\ttotal: 5m 44s\tremaining: 4m 47s\n",
      "545:\tlearn: 0.9159501\ttest: 0.8911207\tbest: 0.8914306 (515)\ttotal: 5m 45s\tremaining: 4m 47s\n",
      "546:\tlearn: 0.9159097\ttest: 0.8911428\tbest: 0.8914306 (515)\ttotal: 5m 45s\tremaining: 4m 46s\n",
      "547:\tlearn: 0.9158692\ttest: 0.8911428\tbest: 0.8914306 (515)\ttotal: 5m 46s\tremaining: 4m 45s\n",
      "548:\tlearn: 0.9159692\ttest: 0.8909213\tbest: 0.8914306 (515)\ttotal: 5m 47s\tremaining: 4m 45s\n",
      "549:\tlearn: 0.9159740\ttest: 0.8909434\tbest: 0.8914306 (515)\ttotal: 5m 47s\tremaining: 4m 44s\n",
      "550:\tlearn: 0.9159740\ttest: 0.8909434\tbest: 0.8914306 (515)\ttotal: 5m 48s\tremaining: 4m 43s\n",
      "551:\tlearn: 0.9160383\ttest: 0.8911871\tbest: 0.8914306 (515)\ttotal: 5m 48s\tremaining: 4m 43s\n",
      "552:\tlearn: 0.9161690\ttest: 0.8914307\tbest: 0.8914307 (552)\ttotal: 5m 49s\tremaining: 4m 42s\n",
      "553:\tlearn: 0.9162190\ttest: 0.8916963\tbest: 0.8916963 (553)\ttotal: 5m 50s\tremaining: 4m 41s\n",
      "554:\tlearn: 0.9162928\ttest: 0.8919396\tbest: 0.8919396 (554)\ttotal: 5m 50s\tremaining: 4m 41s\n",
      "555:\tlearn: 0.9163167\ttest: 0.8919396\tbest: 0.8919396 (554)\ttotal: 5m 51s\tremaining: 4m 40s\n",
      "556:\tlearn: 0.9164357\ttest: 0.8922051\tbest: 0.8922051 (556)\ttotal: 5m 52s\tremaining: 4m 40s\n",
      "557:\tlearn: 0.9165902\ttest: 0.8921165\tbest: 0.8922051 (556)\ttotal: 5m 52s\tremaining: 4m 39s\n",
      "558:\tlearn: 0.9165499\ttest: 0.8921165\tbest: 0.8922051 (556)\ttotal: 5m 53s\tremaining: 4m 38s\n",
      "559:\tlearn: 0.9165738\ttest: 0.8921608\tbest: 0.8922051 (556)\ttotal: 5m 54s\tremaining: 4m 38s\n",
      "560:\tlearn: 0.9169184\ttest: 0.8921829\tbest: 0.8922051 (556)\ttotal: 5m 54s\tremaining: 4m 37s\n",
      "561:\tlearn: 0.9169231\ttest: 0.8921829\tbest: 0.8922051 (556)\ttotal: 5m 55s\tremaining: 4m 36s\n",
      "562:\tlearn: 0.9169396\ttest: 0.8924704\tbest: 0.8924704 (562)\ttotal: 5m 55s\tremaining: 4m 36s\n",
      "563:\tlearn: 0.9169396\ttest: 0.8924704\tbest: 0.8924704 (562)\ttotal: 5m 56s\tremaining: 4m 35s\n",
      "564:\tlearn: 0.9170585\ttest: 0.8924039\tbest: 0.8924704 (562)\ttotal: 5m 57s\tremaining: 4m 34s\n",
      "565:\tlearn: 0.9170892\ttest: 0.8924482\tbest: 0.8924704 (562)\ttotal: 5m 57s\tremaining: 4m 34s\n",
      "566:\tlearn: 0.9172675\ttest: 0.8924704\tbest: 0.8924704 (562)\ttotal: 5m 58s\tremaining: 4m 33s\n",
      "567:\tlearn: 0.9172818\ttest: 0.8924482\tbest: 0.8924704 (562)\ttotal: 5m 59s\tremaining: 4m 33s\n",
      "568:\tlearn: 0.9172962\ttest: 0.8924704\tbest: 0.8924704 (562)\ttotal: 5m 59s\tremaining: 4m 32s\n",
      "569:\tlearn: 0.9173508\ttest: 0.8924704\tbest: 0.8924704 (562)\ttotal: 6m\tremaining: 4m 31s\n",
      "570:\tlearn: 0.9175789\ttest: 0.8920283\tbest: 0.8924704 (562)\ttotal: 6m\tremaining: 4m 31s\n",
      "571:\tlearn: 0.9175884\ttest: 0.8920283\tbest: 0.8924704 (562)\ttotal: 6m 1s\tremaining: 4m 30s\n",
      "572:\tlearn: 0.9175932\ttest: 0.8920504\tbest: 0.8924704 (562)\ttotal: 6m 2s\tremaining: 4m 29s\n",
      "573:\tlearn: 0.9176642\ttest: 0.8919840\tbest: 0.8924704 (562)\ttotal: 6m 2s\tremaining: 4m 29s\n",
      "574:\tlearn: 0.9176949\ttest: 0.8919618\tbest: 0.8924704 (562)\ttotal: 6m 3s\tremaining: 4m 28s\n",
      "575:\tlearn: 0.9178683\ttest: 0.8919840\tbest: 0.8924704 (562)\ttotal: 6m 4s\tremaining: 4m 27s\n",
      "576:\tlearn: 0.9178587\ttest: 0.8919840\tbest: 0.8924704 (562)\ttotal: 6m 4s\tremaining: 4m 27s\n",
      "577:\tlearn: 0.9179488\ttest: 0.8919618\tbest: 0.8924704 (562)\ttotal: 6m 5s\tremaining: 4m 26s\n",
      "578:\tlearn: 0.9179488\ttest: 0.8919396\tbest: 0.8924704 (562)\ttotal: 6m 5s\tremaining: 4m 26s\n",
      "579:\tlearn: 0.9178348\ttest: 0.8916741\tbest: 0.8924704 (562)\ttotal: 6m 6s\tremaining: 4m 25s\n",
      "580:\tlearn: 0.9178396\ttest: 0.8916741\tbest: 0.8924704 (562)\ttotal: 6m 7s\tremaining: 4m 24s\n",
      "581:\tlearn: 0.9179488\ttest: 0.8916741\tbest: 0.8924704 (562)\ttotal: 6m 7s\tremaining: 4m 24s\n",
      "582:\tlearn: 0.9179038\ttest: 0.8916741\tbest: 0.8924704 (562)\ttotal: 6m 8s\tremaining: 4m 23s\n",
      "583:\tlearn: 0.9180273\ttest: 0.8916520\tbest: 0.8924704 (562)\ttotal: 6m 9s\tremaining: 4m 22s\n",
      "584:\tlearn: 0.9181814\ttest: 0.8919175\tbest: 0.8924704 (562)\ttotal: 6m 9s\tremaining: 4m 22s\n",
      "585:\tlearn: 0.9183709\ttest: 0.8918953\tbest: 0.8924704 (562)\ttotal: 6m 10s\tremaining: 4m 21s\n",
      "586:\tlearn: 0.9184255\ttest: 0.8919175\tbest: 0.8924704 (562)\ttotal: 6m 10s\tremaining: 4m 20s\n",
      "587:\tlearn: 0.9183260\ttest: 0.8919175\tbest: 0.8924704 (562)\ttotal: 6m 11s\tremaining: 4m 20s\n",
      "588:\tlearn: 0.9186293\ttest: 0.8919175\tbest: 0.8924704 (562)\ttotal: 6m 12s\tremaining: 4m 19s\n",
      "589:\tlearn: 0.9186742\ttest: 0.8921386\tbest: 0.8924704 (562)\ttotal: 6m 12s\tremaining: 4m 19s\n",
      "590:\tlearn: 0.9186886\ttest: 0.8919396\tbest: 0.8924704 (562)\ttotal: 6m 13s\tremaining: 4m 18s\n",
      "591:\tlearn: 0.9186245\ttest: 0.8918953\tbest: 0.8924704 (562)\ttotal: 6m 14s\tremaining: 4m 17s\n",
      "592:\tlearn: 0.9186388\ttest: 0.8919175\tbest: 0.8924704 (562)\ttotal: 6m 14s\tremaining: 4m 17s\n",
      "593:\tlearn: 0.9185346\ttest: 0.8919396\tbest: 0.8924704 (562)\ttotal: 6m 15s\tremaining: 4m 16s\n",
      "594:\tlearn: 0.9185891\ttest: 0.8922051\tbest: 0.8924704 (562)\ttotal: 6m 15s\tremaining: 4m 15s\n",
      "595:\tlearn: 0.9188120\ttest: 0.8921608\tbest: 0.8924704 (562)\ttotal: 6m 16s\tremaining: 4m 15s\n",
      "596:\tlearn: 0.9187173\ttest: 0.8921608\tbest: 0.8924704 (562)\ttotal: 6m 17s\tremaining: 4m 14s\n",
      "597:\tlearn: 0.9188167\ttest: 0.8922051\tbest: 0.8924704 (562)\ttotal: 6m 17s\tremaining: 4m 14s\n",
      "598:\tlearn: 0.9191743\ttest: 0.8920283\tbest: 0.8924704 (562)\ttotal: 6m 18s\tremaining: 4m 13s\n",
      "599:\tlearn: 0.9190797\ttest: 0.8920283\tbest: 0.8924704 (562)\ttotal: 6m 19s\tremaining: 4m 12s\n",
      "600:\tlearn: 0.9191389\ttest: 0.8917849\tbest: 0.8924704 (562)\ttotal: 6m 19s\tremaining: 4m 12s\n",
      "601:\tlearn: 0.9191485\ttest: 0.8918071\tbest: 0.8924704 (562)\ttotal: 6m 20s\tremaining: 4m 11s\n",
      "602:\tlearn: 0.9191628\ttest: 0.8920283\tbest: 0.8924704 (562)\ttotal: 6m 20s\tremaining: 4m 10s\n",
      "603:\tlearn: 0.9191437\ttest: 0.8919396\tbest: 0.8924704 (562)\ttotal: 6m 21s\tremaining: 4m 10s\n",
      "604:\tlearn: 0.9192317\ttest: 0.8919175\tbest: 0.8924704 (562)\ttotal: 6m 22s\tremaining: 4m 9s\n",
      "605:\tlearn: 0.9193310\ttest: 0.8921829\tbest: 0.8924704 (562)\ttotal: 6m 22s\tremaining: 4m 8s\n",
      "606:\tlearn: 0.9192317\ttest: 0.8922051\tbest: 0.8924704 (562)\ttotal: 6m 23s\tremaining: 4m 8s\n",
      "607:\tlearn: 0.9193024\ttest: 0.8921386\tbest: 0.8924704 (562)\ttotal: 6m 24s\tremaining: 4m 7s\n",
      "608:\tlearn: 0.9193969\ttest: 0.8921608\tbest: 0.8924704 (562)\ttotal: 6m 24s\tremaining: 4m 7s\n",
      "609:\tlearn: 0.9194658\ttest: 0.8919175\tbest: 0.8924704 (562)\ttotal: 6m 25s\tremaining: 4m 6s\n",
      "610:\tlearn: 0.9195268\ttest: 0.8920283\tbest: 0.8924704 (562)\ttotal: 6m 26s\tremaining: 4m 5s\n",
      "611:\tlearn: 0.9194084\ttest: 0.8920504\tbest: 0.8924704 (562)\ttotal: 6m 26s\tremaining: 4m 5s\n",
      "612:\tlearn: 0.9193520\ttest: 0.8917849\tbest: 0.8924704 (562)\ttotal: 6m 27s\tremaining: 4m 4s\n",
      "613:\tlearn: 0.9193568\ttest: 0.8917849\tbest: 0.8924704 (562)\ttotal: 6m 27s\tremaining: 4m 3s\n",
      "614:\tlearn: 0.9192766\ttest: 0.8920504\tbest: 0.8924704 (562)\ttotal: 6m 28s\tremaining: 4m 3s\n",
      "615:\tlearn: 0.9195938\ttest: 0.8917849\tbest: 0.8924704 (562)\ttotal: 6m 29s\tremaining: 4m 2s\n",
      "616:\tlearn: 0.9196291\ttest: 0.8918292\tbest: 0.8924704 (562)\ttotal: 6m 29s\tremaining: 4m 1s\n",
      "617:\tlearn: 0.9198181\ttest: 0.8918071\tbest: 0.8924704 (562)\ttotal: 6m 30s\tremaining: 4m 1s\n",
      "618:\tlearn: 0.9196788\ttest: 0.8918071\tbest: 0.8924704 (562)\ttotal: 6m 31s\tremaining: 4m\n",
      "619:\tlearn: 0.9200310\ttest: 0.8918071\tbest: 0.8924704 (562)\ttotal: 6m 31s\tremaining: 4m\n",
      "620:\tlearn: 0.9200358\ttest: 0.8918292\tbest: 0.8924704 (562)\ttotal: 6m 32s\tremaining: 3m 59s\n",
      "621:\tlearn: 0.9200454\ttest: 0.8917849\tbest: 0.8924704 (562)\ttotal: 6m 32s\tremaining: 3m 58s\n",
      "622:\tlearn: 0.9201542\ttest: 0.8917627\tbest: 0.8924704 (562)\ttotal: 6m 33s\tremaining: 3m 58s\n",
      "623:\tlearn: 0.9201542\ttest: 0.8917627\tbest: 0.8924704 (562)\ttotal: 6m 34s\tremaining: 3m 57s\n",
      "624:\tlearn: 0.9203526\ttest: 0.8917406\tbest: 0.8924704 (562)\ttotal: 6m 34s\tremaining: 3m 56s\n",
      "625:\tlearn: 0.9203526\ttest: 0.8917627\tbest: 0.8924704 (562)\ttotal: 6m 35s\tremaining: 3m 56s\n",
      "626:\tlearn: 0.9203717\ttest: 0.8918071\tbest: 0.8924704 (562)\ttotal: 6m 36s\tremaining: 3m 55s\n",
      "627:\tlearn: 0.9203861\ttest: 0.8918292\tbest: 0.8924704 (562)\ttotal: 6m 36s\tremaining: 3m 55s\n",
      "628:\tlearn: 0.9204422\ttest: 0.8915414\tbest: 0.8924704 (562)\ttotal: 6m 37s\tremaining: 3m 54s\n",
      "629:\tlearn: 0.9205462\ttest: 0.8915636\tbest: 0.8924704 (562)\ttotal: 6m 37s\tremaining: 3m 53s\n",
      "630:\tlearn: 0.9205014\ttest: 0.8915636\tbest: 0.8924704 (562)\ttotal: 6m 38s\tremaining: 3m 53s\n",
      "631:\tlearn: 0.9203478\ttest: 0.8915857\tbest: 0.8924704 (562)\ttotal: 6m 39s\tremaining: 3m 52s\n",
      "632:\tlearn: 0.9204070\ttest: 0.8916079\tbest: 0.8924704 (562)\ttotal: 6m 39s\tremaining: 3m 51s\n",
      "633:\tlearn: 0.9205062\ttest: 0.8913643\tbest: 0.8924704 (562)\ttotal: 6m 40s\tremaining: 3m 51s\n",
      "634:\tlearn: 0.9205157\ttest: 0.8913643\tbest: 0.8924704 (562)\ttotal: 6m 41s\tremaining: 3m 50s\n",
      "635:\tlearn: 0.9206597\ttest: 0.8915857\tbest: 0.8924704 (562)\ttotal: 6m 41s\tremaining: 3m 49s\n",
      "636:\tlearn: 0.9206245\ttest: 0.8915414\tbest: 0.8924704 (562)\ttotal: 6m 42s\tremaining: 3m 49s\n",
      "637:\tlearn: 0.9206280\ttest: 0.8914750\tbest: 0.8924704 (562)\ttotal: 6m 43s\tremaining: 3m 48s\n",
      "638:\tlearn: 0.9207623\ttest: 0.8914750\tbest: 0.8924704 (562)\ttotal: 6m 43s\tremaining: 3m 48s\n",
      "639:\tlearn: 0.9207719\ttest: 0.8915413\tbest: 0.8924704 (562)\ttotal: 6m 44s\tremaining: 3m 47s\n",
      "640:\tlearn: 0.9208501\ttest: 0.8915634\tbest: 0.8924704 (562)\ttotal: 6m 44s\tremaining: 3m 46s\n",
      "641:\tlearn: 0.9208245\ttest: 0.8913421\tbest: 0.8924704 (562)\ttotal: 6m 45s\tremaining: 3m 46s\n",
      "642:\tlearn: 0.9206758\ttest: 0.8913642\tbest: 0.8924704 (562)\ttotal: 6m 46s\tremaining: 3m 45s\n",
      "643:\tlearn: 0.9206406\ttest: 0.8913642\tbest: 0.8924704 (562)\ttotal: 6m 46s\tremaining: 3m 44s\n",
      "644:\tlearn: 0.9206453\ttest: 0.8913864\tbest: 0.8924704 (562)\ttotal: 6m 47s\tremaining: 3m 44s\n",
      "645:\tlearn: 0.9208340\ttest: 0.8916298\tbest: 0.8924704 (562)\ttotal: 6m 48s\tremaining: 3m 43s\n",
      "646:\tlearn: 0.9207062\ttest: 0.8916741\tbest: 0.8924704 (562)\ttotal: 6m 48s\tremaining: 3m 42s\n",
      "647:\tlearn: 0.9208597\ttest: 0.8918732\tbest: 0.8924704 (562)\ttotal: 6m 49s\tremaining: 3m 42s\n",
      "648:\tlearn: 0.9208197\ttest: 0.8918732\tbest: 0.8924704 (562)\ttotal: 6m 49s\tremaining: 3m 41s\n",
      "649:\tlearn: 0.9211073\ttest: 0.8918732\tbest: 0.8924704 (562)\ttotal: 6m 50s\tremaining: 3m 41s\n",
      "650:\tlearn: 0.9211073\ttest: 0.8918953\tbest: 0.8924704 (562)\ttotal: 6m 51s\tremaining: 3m 40s\n",
      "651:\tlearn: 0.9209892\ttest: 0.8922051\tbest: 0.8924704 (562)\ttotal: 6m 51s\tremaining: 3m 39s\n",
      "652:\tlearn: 0.9209444\ttest: 0.8919618\tbest: 0.8924704 (562)\ttotal: 6m 52s\tremaining: 3m 39s\n",
      "653:\tlearn: 0.9209635\ttest: 0.8925147\tbest: 0.8925147 (653)\ttotal: 6m 52s\tremaining: 3m 38s\n",
      "654:\tlearn: 0.9209635\ttest: 0.8920726\tbest: 0.8925147 (653)\ttotal: 6m 53s\tremaining: 3m 37s\n",
      "655:\tlearn: 0.9209635\ttest: 0.8920726\tbest: 0.8925147 (653)\ttotal: 6m 54s\tremaining: 3m 37s\n",
      "656:\tlearn: 0.9209635\ttest: 0.8920726\tbest: 0.8925147 (653)\ttotal: 6m 54s\tremaining: 3m 36s\n",
      "657:\tlearn: 0.9209188\ttest: 0.8920726\tbest: 0.8925147 (653)\ttotal: 6m 55s\tremaining: 3m 35s\n",
      "658:\tlearn: 0.9210370\ttest: 0.8921391\tbest: 0.8925147 (653)\ttotal: 6m 56s\tremaining: 3m 35s\n",
      "659:\tlearn: 0.9210370\ttest: 0.8921391\tbest: 0.8925147 (653)\ttotal: 6m 56s\tremaining: 3m 34s\n",
      "660:\tlearn: 0.9209970\ttest: 0.8921834\tbest: 0.8925147 (653)\ttotal: 6m 57s\tremaining: 3m 34s\n",
      "661:\tlearn: 0.9209618\ttest: 0.8921834\tbest: 0.8925147 (653)\ttotal: 6m 57s\tremaining: 3m 33s\n",
      "662:\tlearn: 0.9209218\ttest: 0.8921391\tbest: 0.8925147 (653)\ttotal: 6m 58s\tremaining: 3m 32s\n",
      "663:\tlearn: 0.9210705\ttest: 0.8920947\tbest: 0.8925147 (653)\ttotal: 6m 59s\tremaining: 3m 32s\n",
      "664:\tlearn: 0.9210848\ttest: 0.8923158\tbest: 0.8925147 (653)\ttotal: 6m 59s\tremaining: 3m 31s\n",
      "665:\tlearn: 0.9211583\ttest: 0.8923602\tbest: 0.8925147 (653)\ttotal: 7m\tremaining: 3m 30s\n",
      "666:\tlearn: 0.9211183\ttest: 0.8923602\tbest: 0.8925147 (653)\ttotal: 7m 1s\tremaining: 3m 30s\n",
      "667:\tlearn: 0.9214298\ttest: 0.8921169\tbest: 0.8925147 (653)\ttotal: 7m 1s\tremaining: 3m 29s\n",
      "668:\tlearn: 0.9213850\ttest: 0.8923602\tbest: 0.8925147 (653)\ttotal: 7m 2s\tremaining: 3m 28s\n",
      "669:\tlearn: 0.9216980\ttest: 0.8923602\tbest: 0.8925147 (653)\ttotal: 7m 3s\tremaining: 3m 28s\n",
      "670:\tlearn: 0.9217523\ttest: 0.8923602\tbest: 0.8925147 (653)\ttotal: 7m 3s\tremaining: 3m 27s\n",
      "671:\tlearn: 0.9217619\ttest: 0.8923380\tbest: 0.8925147 (653)\ttotal: 7m 4s\tremaining: 3m 27s\n",
      "672:\tlearn: 0.9219502\ttest: 0.8926255\tbest: 0.8926255 (672)\ttotal: 7m 4s\tremaining: 3m 26s\n",
      "673:\tlearn: 0.9219103\ttest: 0.8926255\tbest: 0.8926255 (672)\ttotal: 7m 5s\tremaining: 3m 25s\n",
      "674:\tlearn: 0.9219502\ttest: 0.8931115\tbest: 0.8931115 (674)\ttotal: 7m 6s\tremaining: 3m 25s\n",
      "675:\tlearn: 0.9219055\ttest: 0.8931115\tbest: 0.8931115 (674)\ttotal: 7m 6s\tremaining: 3m 24s\n",
      "676:\tlearn: 0.9219645\ttest: 0.8931115\tbest: 0.8931115 (674)\ttotal: 7m 7s\tremaining: 3m 23s\n",
      "677:\tlearn: 0.9220188\ttest: 0.8928020\tbest: 0.8931115 (674)\ttotal: 7m 7s\tremaining: 3m 23s\n",
      "678:\tlearn: 0.9220235\ttest: 0.8928020\tbest: 0.8931115 (674)\ttotal: 7m 8s\tremaining: 3m 22s\n",
      "679:\tlearn: 0.9221033\ttest: 0.8930007\tbest: 0.8931115 (674)\ttotal: 7m 9s\tremaining: 3m 21s\n",
      "680:\tlearn: 0.9221129\ttest: 0.8930007\tbest: 0.8931115 (674)\ttotal: 7m 9s\tremaining: 3m 21s\n",
      "681:\tlearn: 0.9221416\ttest: 0.8930450\tbest: 0.8931115 (674)\ttotal: 7m 10s\tremaining: 3m 20s\n",
      "682:\tlearn: 0.9222596\ttest: 0.8930228\tbest: 0.8931115 (674)\ttotal: 7m 11s\tremaining: 3m 20s\n",
      "683:\tlearn: 0.9222102\ttest: 0.8930672\tbest: 0.8931115 (674)\ttotal: 7m 11s\tremaining: 3m 19s\n",
      "684:\tlearn: 0.9222500\ttest: 0.8930450\tbest: 0.8931115 (674)\ttotal: 7m 12s\tremaining: 3m 18s\n",
      "685:\tlearn: 0.9221910\ttest: 0.8934641\tbest: 0.8934641 (685)\ttotal: 7m 12s\tremaining: 3m 18s\n",
      "686:\tlearn: 0.9222660\ttest: 0.8932435\tbest: 0.8934641 (685)\ttotal: 7m 13s\tremaining: 3m 17s\n",
      "687:\tlearn: 0.9223202\ttest: 0.8932435\tbest: 0.8934641 (685)\ttotal: 7m 14s\tremaining: 3m 16s\n",
      "688:\tlearn: 0.9222373\ttest: 0.8932657\tbest: 0.8934641 (685)\ttotal: 7m 14s\tremaining: 3m 16s\n",
      "689:\tlearn: 0.9223409\ttest: 0.8932435\tbest: 0.8934641 (685)\ttotal: 7m 15s\tremaining: 3m 15s\n",
      "690:\tlearn: 0.9225083\ttest: 0.8930007\tbest: 0.8934641 (685)\ttotal: 7m 16s\tremaining: 3m 15s\n",
      "691:\tlearn: 0.9224142\ttest: 0.8930228\tbest: 0.8934641 (685)\ttotal: 7m 16s\tremaining: 3m 14s\n",
      "692:\tlearn: 0.9225960\ttest: 0.8930450\tbest: 0.8934641 (685)\ttotal: 7m 17s\tremaining: 3m 13s\n",
      "693:\tlearn: 0.9225019\ttest: 0.8930672\tbest: 0.8934641 (685)\ttotal: 7m 17s\tremaining: 3m 13s\n",
      "694:\tlearn: 0.9225019\ttest: 0.8930672\tbest: 0.8934641 (685)\ttotal: 7m 18s\tremaining: 3m 12s\n",
      "695:\tlearn: 0.9224525\ttest: 0.8930672\tbest: 0.8934641 (685)\ttotal: 7m 19s\tremaining: 3m 11s\n",
      "696:\tlearn: 0.9224573\ttest: 0.8930672\tbest: 0.8934641 (685)\ttotal: 7m 19s\tremaining: 3m 11s\n",
      "697:\tlearn: 0.9225912\ttest: 0.8930228\tbest: 0.8934641 (685)\ttotal: 7m 20s\tremaining: 3m 10s\n",
      "698:\tlearn: 0.9226502\ttest: 0.8930228\tbest: 0.8934641 (685)\ttotal: 7m 21s\tremaining: 3m 9s\n",
      "699:\tlearn: 0.9228079\ttest: 0.8930007\tbest: 0.8934641 (685)\ttotal: 7m 21s\tremaining: 3m 9s\n",
      "700:\tlearn: 0.9228716\ttest: 0.8932657\tbest: 0.8934641 (685)\ttotal: 7m 22s\tremaining: 3m 8s\n",
      "701:\tlearn: 0.9228812\ttest: 0.8932657\tbest: 0.8934641 (685)\ttotal: 7m 22s\tremaining: 3m 8s\n",
      "702:\tlearn: 0.9229354\ttest: 0.8932213\tbest: 0.8934641 (685)\ttotal: 7m 23s\tremaining: 3m 7s\n",
      "703:\tlearn: 0.9229258\ttest: 0.8932435\tbest: 0.8934641 (685)\ttotal: 7m 24s\tremaining: 3m 6s\n",
      "704:\tlearn: 0.9228908\ttest: 0.8932213\tbest: 0.8934641 (685)\ttotal: 7m 24s\tremaining: 3m 6s\n",
      "705:\tlearn: 0.9230485\ttest: 0.8932435\tbest: 0.8934641 (685)\ttotal: 7m 25s\tremaining: 3m 5s\n",
      "706:\tlearn: 0.9233192\ttest: 0.8931992\tbest: 0.8934641 (685)\ttotal: 7m 26s\tremaining: 3m 4s\n",
      "707:\tlearn: 0.9233877\ttest: 0.8932213\tbest: 0.8934641 (685)\ttotal: 7m 26s\tremaining: 3m 4s\n",
      "708:\tlearn: 0.9235261\ttest: 0.8934641\tbest: 0.8934641 (685)\ttotal: 7m 27s\tremaining: 3m 3s\n",
      "709:\tlearn: 0.9236089\ttest: 0.8934419\tbest: 0.8934641 (685)\ttotal: 7m 27s\tremaining: 3m 2s\n",
      "710:\tlearn: 0.9234864\ttest: 0.8933976\tbest: 0.8934641 (685)\ttotal: 7m 28s\tremaining: 3m 2s\n",
      "711:\tlearn: 0.9234864\ttest: 0.8933976\tbest: 0.8934641 (685)\ttotal: 7m 29s\tremaining: 3m 1s\n",
      "712:\tlearn: 0.9235453\ttest: 0.8934419\tbest: 0.8934641 (685)\ttotal: 7m 29s\tremaining: 3m 1s\n",
      "713:\tlearn: 0.9237425\ttest: 0.8934419\tbest: 0.8934641 (685)\ttotal: 7m 30s\tremaining: 3m\n",
      "714:\tlearn: 0.9237473\ttest: 0.8934641\tbest: 0.8934641 (685)\ttotal: 7m 31s\tremaining: 2m 59s\n",
      "715:\tlearn: 0.9239747\ttest: 0.8934641\tbest: 0.8934641 (685)\ttotal: 7m 31s\tremaining: 2m 59s\n",
      "716:\tlearn: 0.9241464\ttest: 0.8934862\tbest: 0.8934862 (716)\ttotal: 7m 32s\tremaining: 2m 58s\n",
      "717:\tlearn: 0.9242149\ttest: 0.8937067\tbest: 0.8937067 (717)\ttotal: 7m 32s\tremaining: 2m 57s\n",
      "718:\tlearn: 0.9242340\ttest: 0.8937067\tbest: 0.8937067 (717)\ttotal: 7m 33s\tremaining: 2m 57s\n",
      "719:\tlearn: 0.9242737\ttest: 0.8937067\tbest: 0.8937067 (717)\ttotal: 7m 34s\tremaining: 2m 56s\n",
      "720:\tlearn: 0.9244612\ttest: 0.8937510\tbest: 0.8937510 (720)\ttotal: 7m 34s\tremaining: 2m 56s\n",
      "721:\tlearn: 0.9244612\ttest: 0.8937510\tbest: 0.8937510 (720)\ttotal: 7m 35s\tremaining: 2m 55s\n",
      "722:\tlearn: 0.9247217\ttest: 0.8937288\tbest: 0.8937510 (720)\ttotal: 7m 36s\tremaining: 2m 54s\n",
      "723:\tlearn: 0.9246725\ttest: 0.8937510\tbest: 0.8937510 (720)\ttotal: 7m 36s\tremaining: 2m 54s\n",
      "724:\tlearn: 0.9246820\ttest: 0.8937953\tbest: 0.8937953 (724)\ttotal: 7m 37s\tremaining: 2m 53s\n",
      "725:\tlearn: 0.9248297\ttest: 0.8935306\tbest: 0.8937953 (724)\ttotal: 7m 37s\tremaining: 2m 52s\n",
      "726:\tlearn: 0.9247121\ttest: 0.8935527\tbest: 0.8937953 (724)\ttotal: 7m 38s\tremaining: 2m 52s\n",
      "727:\tlearn: 0.9249978\ttest: 0.8935306\tbest: 0.8937953 (724)\ttotal: 7m 39s\tremaining: 2m 51s\n",
      "728:\tlearn: 0.9252485\ttest: 0.8935084\tbest: 0.8937953 (724)\ttotal: 7m 39s\tremaining: 2m 50s\n",
      "729:\tlearn: 0.9252041\ttest: 0.8935306\tbest: 0.8937953 (724)\ttotal: 7m 40s\tremaining: 2m 50s\n",
      "730:\tlearn: 0.9251550\ttest: 0.8935306\tbest: 0.8937953 (724)\ttotal: 7m 41s\tremaining: 2m 49s\n",
      "731:\tlearn: 0.9253121\ttest: 0.8935084\tbest: 0.8937953 (724)\ttotal: 7m 41s\tremaining: 2m 49s\n",
      "732:\tlearn: 0.9254056\ttest: 0.8934641\tbest: 0.8937953 (724)\ttotal: 7m 42s\tremaining: 2m 48s\n",
      "733:\tlearn: 0.9254943\ttest: 0.8934419\tbest: 0.8937953 (724)\ttotal: 7m 42s\tremaining: 2m 47s\n",
      "734:\tlearn: 0.9254500\ttest: 0.8934419\tbest: 0.8937953 (724)\ttotal: 7m 43s\tremaining: 2m 47s\n",
      "735:\tlearn: 0.9257844\ttest: 0.8934641\tbest: 0.8937953 (724)\ttotal: 7m 44s\tremaining: 2m 46s\n",
      "736:\tlearn: 0.9257844\ttest: 0.8934641\tbest: 0.8937953 (724)\ttotal: 7m 44s\tremaining: 2m 45s\n",
      "737:\tlearn: 0.9256909\ttest: 0.8935084\tbest: 0.8937953 (724)\ttotal: 7m 45s\tremaining: 2m 45s\n",
      "738:\tlearn: 0.9257844\ttest: 0.8934862\tbest: 0.8937953 (724)\ttotal: 7m 46s\tremaining: 2m 44s\n",
      "739:\tlearn: 0.9260300\ttest: 0.8935084\tbest: 0.8937953 (724)\ttotal: 7m 46s\tremaining: 2m 43s\n",
      "740:\tlearn: 0.9260300\ttest: 0.8934862\tbest: 0.8937953 (724)\ttotal: 7m 47s\tremaining: 2m 43s\n",
      "741:\tlearn: 0.9261317\ttest: 0.8939935\tbest: 0.8939935 (741)\ttotal: 7m 47s\tremaining: 2m 42s\n",
      "742:\tlearn: 0.9261317\ttest: 0.8939935\tbest: 0.8939935 (741)\ttotal: 7m 48s\tremaining: 2m 42s\n",
      "743:\tlearn: 0.9262204\ttest: 0.8942803\tbest: 0.8942803 (743)\ttotal: 7m 49s\tremaining: 2m 41s\n",
      "744:\tlearn: 0.9262156\ttest: 0.8943024\tbest: 0.8943024 (744)\ttotal: 7m 49s\tremaining: 2m 40s\n",
      "745:\tlearn: 0.9263772\ttest: 0.8940600\tbest: 0.8943024 (744)\ttotal: 7m 50s\tremaining: 2m 40s\n",
      "746:\tlearn: 0.9263772\ttest: 0.8940600\tbest: 0.8943024 (744)\ttotal: 7m 51s\tremaining: 2m 39s\n",
      "747:\tlearn: 0.9263915\ttest: 0.8940600\tbest: 0.8943024 (744)\ttotal: 7m 51s\tremaining: 2m 38s\n",
      "748:\tlearn: 0.9263915\ttest: 0.8940600\tbest: 0.8943024 (744)\ttotal: 7m 52s\tremaining: 2m 38s\n",
      "749:\tlearn: 0.9265292\ttest: 0.8942803\tbest: 0.8943024 (744)\ttotal: 7m 52s\tremaining: 2m 37s\n",
      "750:\tlearn: 0.9265399\ttest: 0.8942803\tbest: 0.8943024 (744)\ttotal: 7m 53s\tremaining: 2m 36s\n",
      "751:\tlearn: 0.9266823\ttest: 0.8940600\tbest: 0.8943024 (744)\ttotal: 7m 54s\tremaining: 2m 36s\n",
      "752:\tlearn: 0.9266332\ttest: 0.8940600\tbest: 0.8943024 (744)\ttotal: 7m 54s\tremaining: 2m 35s\n",
      "753:\tlearn: 0.9265938\ttest: 0.8940600\tbest: 0.8943024 (744)\ttotal: 7m 55s\tremaining: 2m 35s\n",
      "754:\tlearn: 0.9265734\ttest: 0.8940600\tbest: 0.8943024 (744)\ttotal: 7m 56s\tremaining: 2m 34s\n",
      "755:\tlearn: 0.9265734\ttest: 0.8940379\tbest: 0.8943024 (744)\ttotal: 7m 56s\tremaining: 2m 33s\n",
      "756:\tlearn: 0.9267350\ttest: 0.8940379\tbest: 0.8943024 (744)\ttotal: 7m 57s\tremaining: 2m 33s\n",
      "757:\tlearn: 0.9269407\ttest: 0.8942803\tbest: 0.8943024 (744)\ttotal: 7m 57s\tremaining: 2m 32s\n",
      "758:\tlearn: 0.9271272\ttest: 0.8944561\tbest: 0.8944561 (758)\ttotal: 7m 58s\tremaining: 2m 31s\n",
      "759:\tlearn: 0.9271320\ttest: 0.8944782\tbest: 0.8944782 (759)\ttotal: 7m 59s\tremaining: 2m 31s\n",
      "760:\tlearn: 0.9271416\ttest: 0.8944782\tbest: 0.8944782 (759)\ttotal: 7m 59s\tremaining: 2m 30s\n",
      "761:\tlearn: 0.9271080\ttest: 0.8941916\tbest: 0.8944782 (759)\ttotal: 8m\tremaining: 2m 30s\n",
      "762:\tlearn: 0.9271128\ttest: 0.8941916\tbest: 0.8944782 (759)\ttotal: 8m\tremaining: 2m 29s\n",
      "763:\tlearn: 0.9270244\ttest: 0.8942138\tbest: 0.8944782 (759)\ttotal: 8m 1s\tremaining: 2m 28s\n",
      "764:\tlearn: 0.9270340\ttest: 0.8942138\tbest: 0.8944782 (759)\ttotal: 8m 2s\tremaining: 2m 28s\n",
      "765:\tlearn: 0.9269801\ttest: 0.8944117\tbest: 0.8944782 (759)\ttotal: 8m 2s\tremaining: 2m 27s\n",
      "766:\tlearn: 0.9268869\ttest: 0.8944339\tbest: 0.8944782 (759)\ttotal: 8m 3s\tremaining: 2m 26s\n",
      "767:\tlearn: 0.9268965\ttest: 0.8944117\tbest: 0.8944782 (759)\ttotal: 8m 4s\tremaining: 2m 26s\n",
      "768:\tlearn: 0.9269993\ttest: 0.8944117\tbest: 0.8944782 (759)\ttotal: 8m 4s\tremaining: 2m 25s\n",
      "769:\tlearn: 0.9269646\ttest: 0.8944339\tbest: 0.8944782 (759)\ttotal: 8m 5s\tremaining: 2m 24s\n",
      "770:\tlearn: 0.9269694\ttest: 0.8944339\tbest: 0.8944782 (759)\ttotal: 8m 5s\tremaining: 2m 24s\n",
      "771:\tlearn: 0.9269790\ttest: 0.8943896\tbest: 0.8944782 (759)\ttotal: 8m 6s\tremaining: 2m 23s\n",
      "772:\tlearn: 0.9270627\ttest: 0.8941473\tbest: 0.8944782 (759)\ttotal: 8m 7s\tremaining: 2m 23s\n",
      "773:\tlearn: 0.9271261\ttest: 0.8941473\tbest: 0.8944782 (759)\ttotal: 8m 7s\tremaining: 2m 22s\n",
      "774:\tlearn: 0.9271405\ttest: 0.8941694\tbest: 0.8944782 (759)\ttotal: 8m 8s\tremaining: 2m 21s\n",
      "775:\tlearn: 0.9271895\ttest: 0.8944339\tbest: 0.8944782 (759)\ttotal: 8m 9s\tremaining: 2m 21s\n",
      "776:\tlearn: 0.9272385\ttest: 0.8943896\tbest: 0.8944782 (759)\ttotal: 8m 9s\tremaining: 2m 20s\n",
      "777:\tlearn: 0.9273114\ttest: 0.8943896\tbest: 0.8944782 (759)\ttotal: 8m 10s\tremaining: 2m 19s\n",
      "778:\tlearn: 0.9271943\ttest: 0.8944339\tbest: 0.8944782 (759)\ttotal: 8m 10s\tremaining: 2m 19s\n",
      "779:\tlearn: 0.9271452\ttest: 0.8944339\tbest: 0.8944782 (759)\ttotal: 8m 11s\tremaining: 2m 18s\n",
      "780:\tlearn: 0.9271500\ttest: 0.8944339\tbest: 0.8944782 (759)\ttotal: 8m 12s\tremaining: 2m 18s\n",
      "781:\tlearn: 0.9272182\ttest: 0.8944561\tbest: 0.8944782 (759)\ttotal: 8m 12s\tremaining: 2m 17s\n",
      "782:\tlearn: 0.9273998\ttest: 0.8944561\tbest: 0.8944782 (759)\ttotal: 8m 13s\tremaining: 2m 16s\n",
      "783:\tlearn: 0.9273114\ttest: 0.8944561\tbest: 0.8944782 (759)\ttotal: 8m 14s\tremaining: 2m 16s\n",
      "784:\tlearn: 0.9273604\ttest: 0.8944561\tbest: 0.8944782 (759)\ttotal: 8m 14s\tremaining: 2m 15s\n",
      "785:\tlearn: 0.9273844\ttest: 0.8945004\tbest: 0.8945004 (785)\ttotal: 8m 15s\tremaining: 2m 14s\n",
      "786:\tlearn: 0.9273892\ttest: 0.8945004\tbest: 0.8945004 (785)\ttotal: 8m 16s\tremaining: 2m 14s\n",
      "787:\tlearn: 0.9273940\ttest: 0.8945004\tbest: 0.8945004 (785)\ttotal: 8m 16s\tremaining: 2m 13s\n",
      "788:\tlearn: 0.9273988\ttest: 0.8945004\tbest: 0.8945004 (785)\ttotal: 8m 17s\tremaining: 2m 12s\n",
      "789:\tlearn: 0.9273988\ttest: 0.8945004\tbest: 0.8945004 (785)\ttotal: 8m 17s\tremaining: 2m 12s\n",
      "790:\tlearn: 0.9274872\ttest: 0.8943896\tbest: 0.8945004 (785)\ttotal: 8m 18s\tremaining: 2m 11s\n",
      "791:\tlearn: 0.9274536\ttest: 0.8943674\tbest: 0.8945004 (785)\ttotal: 8m 19s\tremaining: 2m 11s\n",
      "792:\tlearn: 0.9275612\ttest: 0.8941251\tbest: 0.8945004 (785)\ttotal: 8m 19s\tremaining: 2m 10s\n",
      "793:\tlearn: 0.9276352\ttest: 0.8939270\tbest: 0.8945004 (785)\ttotal: 8m 20s\tremaining: 2m 9s\n",
      "794:\tlearn: 0.9276937\ttest: 0.8941694\tbest: 0.8945004 (785)\ttotal: 8m 21s\tremaining: 2m 9s\n",
      "795:\tlearn: 0.9277129\ttest: 0.8941694\tbest: 0.8945004 (785)\ttotal: 8m 21s\tremaining: 2m 8s\n",
      "796:\tlearn: 0.9277177\ttest: 0.8941694\tbest: 0.8945004 (785)\ttotal: 8m 22s\tremaining: 2m 7s\n",
      "797:\tlearn: 0.9277416\ttest: 0.8941251\tbest: 0.8945004 (785)\ttotal: 8m 22s\tremaining: 2m 7s\n",
      "798:\tlearn: 0.9278981\ttest: 0.8939049\tbest: 0.8945004 (785)\ttotal: 8m 23s\tremaining: 2m 6s\n",
      "799:\tlearn: 0.9278539\ttest: 0.8939270\tbest: 0.8945004 (785)\ttotal: 8m 24s\tremaining: 2m 6s\n",
      "800:\tlearn: 0.9278683\ttest: 0.8939270\tbest: 0.8945004 (785)\ttotal: 8m 24s\tremaining: 2m 5s\n",
      "801:\tlearn: 0.9278827\ttest: 0.8939270\tbest: 0.8945004 (785)\ttotal: 8m 25s\tremaining: 2m 4s\n",
      "802:\tlearn: 0.9279364\ttest: 0.8939049\tbest: 0.8945004 (785)\ttotal: 8m 25s\tremaining: 2m 4s\n",
      "803:\tlearn: 0.9280141\ttest: 0.8938827\tbest: 0.8945004 (785)\ttotal: 8m 26s\tremaining: 2m 3s\n",
      "804:\tlearn: 0.9280189\ttest: 0.8938827\tbest: 0.8945004 (785)\ttotal: 8m 27s\tremaining: 2m 2s\n",
      "805:\tlearn: 0.9281216\ttest: 0.8936624\tbest: 0.8945004 (785)\ttotal: 8m 27s\tremaining: 2m 2s\n",
      "806:\tlearn: 0.9281264\ttest: 0.8936624\tbest: 0.8945004 (785)\ttotal: 8m 28s\tremaining: 2m 1s\n",
      "807:\tlearn: 0.9281264\ttest: 0.8936402\tbest: 0.8945004 (785)\ttotal: 8m 29s\tremaining: 2m\n",
      "808:\tlearn: 0.9281408\ttest: 0.8935959\tbest: 0.8945004 (785)\ttotal: 8m 29s\tremaining: 2m\n",
      "809:\tlearn: 0.9281945\ttest: 0.8938605\tbest: 0.8945004 (785)\ttotal: 8m 30s\tremaining: 1m 59s\n",
      "810:\tlearn: 0.9281993\ttest: 0.8939049\tbest: 0.8945004 (785)\ttotal: 8m 30s\tremaining: 1m 59s\n",
      "811:\tlearn: 0.9281014\ttest: 0.8939049\tbest: 0.8945004 (785)\ttotal: 8m 31s\tremaining: 1m 58s\n",
      "812:\tlearn: 0.9281551\ttest: 0.8939270\tbest: 0.8945004 (785)\ttotal: 8m 32s\tremaining: 1m 57s\n",
      "813:\tlearn: 0.9282089\ttest: 0.8938605\tbest: 0.8945004 (785)\ttotal: 8m 32s\tremaining: 1m 57s\n",
      "814:\tlearn: 0.9281695\ttest: 0.8938827\tbest: 0.8945004 (785)\ttotal: 8m 33s\tremaining: 1m 56s\n",
      "815:\tlearn: 0.9283557\ttest: 0.8944339\tbest: 0.8945004 (785)\ttotal: 8m 34s\tremaining: 1m 55s\n",
      "816:\tlearn: 0.9284046\ttest: 0.8943674\tbest: 0.8945004 (785)\ttotal: 8m 34s\tremaining: 1m 55s\n",
      "817:\tlearn: 0.9284583\ttest: 0.8943674\tbest: 0.8945004 (785)\ttotal: 8m 35s\tremaining: 1m 54s\n",
      "818:\tlearn: 0.9285312\ttest: 0.8944117\tbest: 0.8945004 (785)\ttotal: 8m 36s\tremaining: 1m 54s\n",
      "819:\tlearn: 0.9285312\ttest: 0.8944117\tbest: 0.8945004 (785)\ttotal: 8m 36s\tremaining: 1m 53s\n",
      "820:\tlearn: 0.9283940\ttest: 0.8944339\tbest: 0.8945004 (785)\ttotal: 8m 37s\tremaining: 1m 52s\n",
      "821:\tlearn: 0.9284036\ttest: 0.8944339\tbest: 0.8945004 (785)\ttotal: 8m 37s\tremaining: 1m 52s\n",
      "822:\tlearn: 0.9285158\ttest: 0.8944561\tbest: 0.8945004 (785)\ttotal: 8m 38s\tremaining: 1m 51s\n",
      "823:\tlearn: 0.9285206\ttest: 0.8944782\tbest: 0.8945004 (785)\ttotal: 8m 39s\tremaining: 1m 50s\n",
      "824:\tlearn: 0.9284717\ttest: 0.8945004\tbest: 0.8945004 (785)\ttotal: 8m 39s\tremaining: 1m 50s\n",
      "825:\tlearn: 0.9284717\ttest: 0.8944782\tbest: 0.8945004 (785)\ttotal: 8m 40s\tremaining: 1m 49s\n",
      "826:\tlearn: 0.9285014\ttest: 0.8942803\tbest: 0.8945004 (785)\ttotal: 8m 41s\tremaining: 1m 48s\n",
      "827:\tlearn: 0.9285312\ttest: 0.8942803\tbest: 0.8945004 (785)\ttotal: 8m 41s\tremaining: 1m 48s\n",
      "828:\tlearn: 0.9287316\ttest: 0.8943024\tbest: 0.8945004 (785)\ttotal: 8m 42s\tremaining: 1m 47s\n",
      "829:\tlearn: 0.9287364\ttest: 0.8943024\tbest: 0.8945004 (785)\ttotal: 8m 42s\tremaining: 1m 47s\n",
      "830:\tlearn: 0.9287364\ttest: 0.8943024\tbest: 0.8945004 (785)\ttotal: 8m 43s\tremaining: 1m 46s\n",
      "831:\tlearn: 0.9287411\ttest: 0.8943024\tbest: 0.8945004 (785)\ttotal: 8m 44s\tremaining: 1m 45s\n",
      "832:\tlearn: 0.9287459\ttest: 0.8942803\tbest: 0.8945004 (785)\ttotal: 8m 44s\tremaining: 1m 45s\n",
      "833:\tlearn: 0.9286970\ttest: 0.8942803\tbest: 0.8945004 (785)\ttotal: 8m 45s\tremaining: 1m 44s\n",
      "834:\tlearn: 0.9288044\ttest: 0.8942803\tbest: 0.8945004 (785)\ttotal: 8m 46s\tremaining: 1m 43s\n",
      "835:\tlearn: 0.9290335\ttest: 0.8943024\tbest: 0.8945004 (785)\ttotal: 8m 46s\tremaining: 1m 43s\n",
      "836:\tlearn: 0.9289750\ttest: 0.8943024\tbest: 0.8945004 (785)\ttotal: 8m 47s\tremaining: 1m 42s\n",
      "837:\tlearn: 0.9289750\ttest: 0.8943246\tbest: 0.8945004 (785)\ttotal: 8m 47s\tremaining: 1m 42s\n",
      "838:\tlearn: 0.9291216\ttest: 0.8940379\tbest: 0.8945004 (785)\ttotal: 8m 48s\tremaining: 1m 41s\n",
      "839:\tlearn: 0.9291801\ttest: 0.8940600\tbest: 0.8945004 (785)\ttotal: 8m 49s\tremaining: 1m 40s\n",
      "840:\tlearn: 0.9291072\ttest: 0.8938397\tbest: 0.8945004 (785)\ttotal: 8m 49s\tremaining: 1m 40s\n",
      "841:\tlearn: 0.9293410\ttest: 0.8935971\tbest: 0.8945004 (785)\ttotal: 8m 50s\tremaining: 1m 39s\n",
      "842:\tlearn: 0.9294827\ttest: 0.8936192\tbest: 0.8945004 (785)\ttotal: 8m 51s\tremaining: 1m 38s\n",
      "843:\tlearn: 0.9294923\ttest: 0.8936192\tbest: 0.8945004 (785)\ttotal: 8m 51s\tremaining: 1m 38s\n",
      "844:\tlearn: 0.9297748\ttest: 0.8938840\tbest: 0.8945004 (785)\ttotal: 8m 52s\tremaining: 1m 37s\n",
      "845:\tlearn: 0.9298284\ttest: 0.8939284\tbest: 0.8945004 (785)\ttotal: 8m 52s\tremaining: 1m 37s\n",
      "846:\tlearn: 0.9300235\ttest: 0.8939284\tbest: 0.8945004 (785)\ttotal: 8m 53s\tremaining: 1m 36s\n",
      "847:\tlearn: 0.9300187\ttest: 0.8939062\tbest: 0.8945004 (785)\ttotal: 8m 54s\tremaining: 1m 35s\n",
      "848:\tlearn: 0.9302626\ttest: 0.8939062\tbest: 0.8945004 (785)\ttotal: 8m 54s\tremaining: 1m 35s\n",
      "849:\tlearn: 0.9302770\ttest: 0.8936414\tbest: 0.8945004 (785)\ttotal: 8m 55s\tremaining: 1m 34s\n",
      "850:\tlearn: 0.9300379\ttest: 0.8933543\tbest: 0.8945004 (785)\ttotal: 8m 56s\tremaining: 1m 33s\n",
      "851:\tlearn: 0.9300723\ttest: 0.8933322\tbest: 0.8945004 (785)\ttotal: 8m 56s\tremaining: 1m 33s\n",
      "852:\tlearn: 0.9302194\ttest: 0.8931992\tbest: 0.8945004 (785)\ttotal: 8m 57s\tremaining: 1m 32s\n",
      "853:\tlearn: 0.9304584\ttest: 0.8932435\tbest: 0.8945004 (785)\ttotal: 8m 57s\tremaining: 1m 31s\n",
      "854:\tlearn: 0.9306533\ttest: 0.8932435\tbest: 0.8945004 (785)\ttotal: 8m 58s\tremaining: 1m 31s\n",
      "855:\tlearn: 0.9306238\ttest: 0.8932435\tbest: 0.8945004 (785)\ttotal: 8m 59s\tremaining: 1m 30s\n",
      "856:\tlearn: 0.9308282\ttest: 0.8930007\tbest: 0.8945004 (785)\ttotal: 8m 59s\tremaining: 1m 30s\n",
      "857:\tlearn: 0.9308769\ttest: 0.8930228\tbest: 0.8945004 (785)\ttotal: 9m\tremaining: 1m 29s\n",
      "858:\tlearn: 0.9311300\ttest: 0.8930450\tbest: 0.8945004 (785)\ttotal: 9m 1s\tremaining: 1m 28s\n",
      "859:\tlearn: 0.9312274\ttest: 0.8930450\tbest: 0.8945004 (785)\ttotal: 9m 1s\tremaining: 1m 28s\n",
      "860:\tlearn: 0.9312760\ttest: 0.8930228\tbest: 0.8945004 (785)\ttotal: 9m 2s\tremaining: 1m 27s\n",
      "861:\tlearn: 0.9315241\ttest: 0.8930450\tbest: 0.8945004 (785)\ttotal: 9m 2s\tremaining: 1m 26s\n",
      "862:\tlearn: 0.9316166\ttest: 0.8927577\tbest: 0.8945004 (785)\ttotal: 9m 3s\tremaining: 1m 26s\n",
      "863:\tlearn: 0.9318207\ttest: 0.8928242\tbest: 0.8945004 (785)\ttotal: 9m 4s\tremaining: 1m 25s\n",
      "864:\tlearn: 0.9320686\ttest: 0.8928242\tbest: 0.8945004 (785)\ttotal: 9m 4s\tremaining: 1m 25s\n",
      "865:\tlearn: 0.9320686\ttest: 0.8928464\tbest: 0.8945004 (785)\ttotal: 9m 5s\tremaining: 1m 24s\n",
      "866:\tlearn: 0.9322239\ttest: 0.8927799\tbest: 0.8945004 (785)\ttotal: 9m 6s\tremaining: 1m 23s\n",
      "867:\tlearn: 0.9324230\ttest: 0.8927799\tbest: 0.8945004 (785)\ttotal: 9m 6s\tremaining: 1m 23s\n",
      "868:\tlearn: 0.9324764\ttest: 0.8927799\tbest: 0.8945004 (785)\ttotal: 9m 7s\tremaining: 1m 22s\n",
      "869:\tlearn: 0.9326221\ttest: 0.8928020\tbest: 0.8945004 (785)\ttotal: 9m 7s\tremaining: 1m 21s\n",
      "870:\tlearn: 0.9326850\ttest: 0.8927134\tbest: 0.8945004 (785)\ttotal: 9m 8s\tremaining: 1m 21s\n",
      "871:\tlearn: 0.9329277\ttest: 0.8927577\tbest: 0.8945004 (785)\ttotal: 9m 9s\tremaining: 1m 20s\n",
      "872:\tlearn: 0.9332283\ttest: 0.8928020\tbest: 0.8945004 (785)\ttotal: 9m 9s\tremaining: 1m 19s\n",
      "873:\tlearn: 0.9333109\ttest: 0.8928020\tbest: 0.8945004 (785)\ttotal: 9m 10s\tremaining: 1m 19s\n",
      "874:\tlearn: 0.9332768\ttest: 0.8928242\tbest: 0.8945004 (785)\ttotal: 9m 11s\tremaining: 1m 18s\n",
      "875:\tlearn: 0.9332768\ttest: 0.8928242\tbest: 0.8945004 (785)\ttotal: 9m 11s\tremaining: 1m 18s\n",
      "876:\tlearn: 0.9333642\ttest: 0.8928685\tbest: 0.8945004 (785)\ttotal: 9m 12s\tremaining: 1m 17s\n",
      "877:\tlearn: 0.9333157\ttest: 0.8928685\tbest: 0.8945004 (785)\ttotal: 9m 12s\tremaining: 1m 16s\n",
      "878:\tlearn: 0.9330823\ttest: 0.8931115\tbest: 0.8945004 (785)\ttotal: 9m 13s\tremaining: 1m 16s\n",
      "879:\tlearn: 0.9330482\ttest: 0.8930893\tbest: 0.8945004 (785)\ttotal: 9m 14s\tremaining: 1m 15s\n",
      "880:\tlearn: 0.9332614\ttest: 0.8930893\tbest: 0.8945004 (785)\ttotal: 9m 14s\tremaining: 1m 14s\n",
      "881:\tlearn: 0.9333147\ttest: 0.8933322\tbest: 0.8945004 (785)\ttotal: 9m 15s\tremaining: 1m 14s\n",
      "882:\tlearn: 0.9333680\ttest: 0.8934208\tbest: 0.8945004 (785)\ttotal: 9m 16s\tremaining: 1m 13s\n",
      "883:\tlearn: 0.9332321\ttest: 0.8939062\tbest: 0.8945004 (785)\ttotal: 9m 16s\tremaining: 1m 13s\n",
      "884:\tlearn: 0.9332369\ttest: 0.8939062\tbest: 0.8945004 (785)\ttotal: 9m 17s\tremaining: 1m 12s\n",
      "885:\tlearn: 0.9333579\ttest: 0.8936857\tbest: 0.8945004 (785)\ttotal: 9m 18s\tremaining: 1m 11s\n",
      "886:\tlearn: 0.9335034\ttest: 0.8937079\tbest: 0.8945004 (785)\ttotal: 9m 18s\tremaining: 1m 11s\n",
      "887:\tlearn: 0.9336632\ttest: 0.8937079\tbest: 0.8945004 (785)\ttotal: 9m 19s\tremaining: 1m 10s\n",
      "888:\tlearn: 0.9336728\ttest: 0.8939505\tbest: 0.8945004 (785)\ttotal: 9m 19s\tremaining: 1m 9s\n",
      "889:\tlearn: 0.9334789\ttest: 0.8939727\tbest: 0.8945004 (785)\ttotal: 9m 20s\tremaining: 1m 9s\n",
      "890:\tlearn: 0.9336728\ttest: 0.8939727\tbest: 0.8945004 (785)\ttotal: 9m 21s\tremaining: 1m 8s\n",
      "891:\tlearn: 0.9339199\ttest: 0.8939727\tbest: 0.8945004 (785)\ttotal: 9m 21s\tremaining: 1m 8s\n",
      "892:\tlearn: 0.9337649\ttest: 0.8939949\tbest: 0.8945004 (785)\ttotal: 9m 22s\tremaining: 1m 7s\n",
      "893:\tlearn: 0.9340072\ttest: 0.8939949\tbest: 0.8945004 (785)\ttotal: 9m 23s\tremaining: 1m 6s\n",
      "894:\tlearn: 0.9340796\ttest: 0.8940171\tbest: 0.8945004 (785)\ttotal: 9m 23s\tremaining: 1m 6s\n",
      "895:\tlearn: 0.9339876\ttest: 0.8942374\tbest: 0.8945004 (785)\ttotal: 9m 24s\tremaining: 1m 5s\n",
      "896:\tlearn: 0.9341377\ttest: 0.8943040\tbest: 0.8945004 (785)\ttotal: 9m 24s\tremaining: 1m 4s\n",
      "897:\tlearn: 0.9341909\ttest: 0.8945686\tbest: 0.8945686 (897)\ttotal: 9m 25s\tremaining: 1m 4s\n",
      "898:\tlearn: 0.9344862\ttest: 0.8945908\tbest: 0.8945908 (898)\ttotal: 9m 26s\tremaining: 1m 3s\n",
      "899:\tlearn: 0.9345830\ttest: 0.8947887\tbest: 0.8947887 (899)\ttotal: 9m 26s\tremaining: 1m 2s\n",
      "900:\tlearn: 0.9348297\ttest: 0.8948109\tbest: 0.8948109 (900)\ttotal: 9m 27s\tremaining: 1m 2s\n",
      "901:\tlearn: 0.9350763\ttest: 0.8948109\tbest: 0.8948109 (900)\ttotal: 9m 28s\tremaining: 1m 1s\n",
      "902:\tlearn: 0.9351682\ttest: 0.8948109\tbest: 0.8948109 (900)\ttotal: 9m 28s\tremaining: 1m 1s\n",
      "903:\tlearn: 0.9351730\ttest: 0.8948109\tbest: 0.8948109 (900)\ttotal: 9m 29s\tremaining: 1m\n",
      "904:\tlearn: 0.9354194\ttest: 0.8948109\tbest: 0.8948109 (900)\ttotal: 9m 29s\tremaining: 59.8s\n",
      "905:\tlearn: 0.9356706\ttest: 0.8948109\tbest: 0.8948109 (900)\ttotal: 9m 30s\tremaining: 59.2s\n",
      "906:\tlearn: 0.9359603\ttest: 0.8948109\tbest: 0.8948109 (900)\ttotal: 9m 31s\tremaining: 58.6s\n",
      "907:\tlearn: 0.9359747\ttest: 0.8948109\tbest: 0.8948109 (900)\ttotal: 9m 31s\tremaining: 57.9s\n",
      "908:\tlearn: 0.9361773\ttest: 0.8947887\tbest: 0.8948109 (900)\ttotal: 9m 32s\tremaining: 57.3s\n",
      "909:\tlearn: 0.9364716\ttest: 0.8947887\tbest: 0.8948109 (900)\ttotal: 9m 32s\tremaining: 56.7s\n",
      "910:\tlearn: 0.9365198\ttest: 0.8948331\tbest: 0.8948331 (910)\ttotal: 9m 33s\tremaining: 56s\n",
      "911:\tlearn: 0.9365728\ttest: 0.8948331\tbest: 0.8948331 (910)\ttotal: 9m 34s\tremaining: 55.4s\n",
      "912:\tlearn: 0.9368668\ttest: 0.8948553\tbest: 0.8948553 (912)\ttotal: 9m 34s\tremaining: 54.8s\n",
      "913:\tlearn: 0.9371077\ttest: 0.8948553\tbest: 0.8948553 (912)\ttotal: 9m 35s\tremaining: 54.1s\n",
      "914:\tlearn: 0.9372570\ttest: 0.8950975\tbest: 0.8950975 (914)\ttotal: 9m 36s\tremaining: 53.5s\n",
      "915:\tlearn: 0.9372474\ttest: 0.8950975\tbest: 0.8950975 (914)\ttotal: 9m 36s\tremaining: 52.9s\n",
      "916:\tlearn: 0.9375026\ttest: 0.8951197\tbest: 0.8951197 (916)\ttotal: 9m 37s\tremaining: 52.3s\n",
      "917:\tlearn: 0.9376276\ttest: 0.8953618\tbest: 0.8953618 (917)\ttotal: 9m 38s\tremaining: 51.7s\n",
      "918:\tlearn: 0.9376710\ttest: 0.8953618\tbest: 0.8953618 (917)\ttotal: 9m 38s\tremaining: 51s\n",
      "919:\tlearn: 0.9376710\ttest: 0.8952508\tbest: 0.8953618 (917)\ttotal: 9m 39s\tremaining: 50.4s\n",
      "920:\tlearn: 0.9375699\ttest: 0.8955372\tbest: 0.8955372 (920)\ttotal: 9m 40s\tremaining: 49.8s\n",
      "921:\tlearn: 0.9375603\ttest: 0.8955150\tbest: 0.8955372 (920)\ttotal: 9m 40s\tremaining: 49.1s\n",
      "922:\tlearn: 0.9376277\ttest: 0.8954928\tbest: 0.8955372 (920)\ttotal: 9m 41s\tremaining: 48.5s\n",
      "923:\tlearn: 0.9379164\ttest: 0.8952508\tbest: 0.8955372 (920)\ttotal: 9m 41s\tremaining: 47.9s\n",
      "924:\tlearn: 0.9381616\ttest: 0.8952952\tbest: 0.8955372 (920)\ttotal: 9m 42s\tremaining: 47.2s\n",
      "925:\tlearn: 0.9382577\ttest: 0.8952952\tbest: 0.8955372 (920)\ttotal: 9m 43s\tremaining: 46.6s\n",
      "926:\tlearn: 0.9383106\ttest: 0.8952952\tbest: 0.8955372 (920)\ttotal: 9m 43s\tremaining: 46s\n",
      "927:\tlearn: 0.9381808\ttest: 0.8953174\tbest: 0.8955372 (920)\ttotal: 9m 44s\tremaining: 45.3s\n",
      "928:\tlearn: 0.9382770\ttest: 0.8953174\tbest: 0.8955372 (920)\ttotal: 9m 45s\tremaining: 44.7s\n",
      "929:\tlearn: 0.9382770\ttest: 0.8950975\tbest: 0.8955372 (920)\ttotal: 9m 45s\tremaining: 44.1s\n",
      "930:\tlearn: 0.9385653\ttest: 0.8948775\tbest: 0.8955372 (920)\ttotal: 9m 46s\tremaining: 43.5s\n",
      "931:\tlearn: 0.9386517\ttest: 0.8948775\tbest: 0.8955372 (920)\ttotal: 9m 46s\tremaining: 42.8s\n",
      "932:\tlearn: 0.9388486\ttest: 0.8950531\tbest: 0.8955372 (920)\ttotal: 9m 47s\tremaining: 42.2s\n",
      "933:\tlearn: 0.9386806\ttest: 0.8950087\tbest: 0.8955372 (920)\ttotal: 9m 48s\tremaining: 41.6s\n",
      "934:\tlearn: 0.9387478\ttest: 0.8949866\tbest: 0.8955372 (920)\ttotal: 9m 48s\tremaining: 40.9s\n",
      "935:\tlearn: 0.9389399\ttest: 0.8949866\tbest: 0.8955372 (920)\ttotal: 9m 49s\tremaining: 40.3s\n",
      "936:\tlearn: 0.9390935\ttest: 0.8950087\tbest: 0.8955372 (920)\ttotal: 9m 50s\tremaining: 39.7s\n",
      "937:\tlearn: 0.9392902\ttest: 0.8950087\tbest: 0.8955372 (920)\ttotal: 9m 50s\tremaining: 39s\n",
      "938:\tlearn: 0.9393238\ttest: 0.8949422\tbest: 0.8955372 (920)\ttotal: 9m 51s\tremaining: 38.4s\n",
      "939:\tlearn: 0.9394293\ttest: 0.8949422\tbest: 0.8955372 (920)\ttotal: 9m 51s\tremaining: 37.8s\n",
      "940:\tlearn: 0.9396691\ttest: 0.8949422\tbest: 0.8955372 (920)\ttotal: 9m 52s\tremaining: 37.1s\n",
      "941:\tlearn: 0.9398609\ttest: 0.8947222\tbest: 0.8955372 (920)\ttotal: 9m 53s\tremaining: 36.5s\n",
      "942:\tlearn: 0.9398705\ttest: 0.8947222\tbest: 0.8955372 (920)\ttotal: 9m 53s\tremaining: 35.9s\n",
      "943:\tlearn: 0.9401579\ttest: 0.8947222\tbest: 0.8955372 (920)\ttotal: 9m 54s\tremaining: 35.3s\n",
      "944:\tlearn: 0.9402682\ttest: 0.8949644\tbest: 0.8955372 (920)\ttotal: 9m 54s\tremaining: 34.6s\n",
      "945:\tlearn: 0.9401389\ttest: 0.8951399\tbest: 0.8955372 (920)\ttotal: 9m 55s\tremaining: 34s\n",
      "946:\tlearn: 0.9403832\ttest: 0.8951399\tbest: 0.8955372 (920)\ttotal: 9m 56s\tremaining: 33.4s\n",
      "947:\tlearn: 0.9405460\ttest: 0.8951621\tbest: 0.8955372 (920)\ttotal: 9m 56s\tremaining: 32.7s\n",
      "948:\tlearn: 0.9406896\ttest: 0.8951621\tbest: 0.8955372 (920)\ttotal: 9m 57s\tremaining: 32.1s\n",
      "949:\tlearn: 0.9407949\ttest: 0.8954041\tbest: 0.8955372 (920)\ttotal: 9m 58s\tremaining: 31.5s\n",
      "950:\tlearn: 0.9408524\ttest: 0.8953819\tbest: 0.8955372 (920)\ttotal: 9m 58s\tremaining: 30.9s\n",
      "951:\tlearn: 0.9408428\ttest: 0.8953376\tbest: 0.8955372 (920)\ttotal: 9m 59s\tremaining: 30.2s\n",
      "952:\tlearn: 0.9408762\ttest: 0.8953597\tbest: 0.8955372 (920)\ttotal: 9m 59s\tremaining: 29.6s\n",
      "953:\tlearn: 0.9411249\ttest: 0.8956016\tbest: 0.8956016 (953)\ttotal: 10m\tremaining: 29s\n",
      "954:\tlearn: 0.9414262\ttest: 0.8956016\tbest: 0.8956016 (953)\ttotal: 10m 1s\tremaining: 28.3s\n",
      "955:\tlearn: 0.9417129\ttest: 0.8956016\tbest: 0.8956016 (953)\ttotal: 10m 1s\tremaining: 27.7s\n",
      "956:\tlearn: 0.9419135\ttest: 0.8956238\tbest: 0.8956238 (956)\ttotal: 10m 2s\tremaining: 27.1s\n",
      "957:\tlearn: 0.9421570\ttest: 0.8956682\tbest: 0.8956682 (957)\ttotal: 10m 3s\tremaining: 26.4s\n",
      "958:\tlearn: 0.9422477\ttest: 0.8956460\tbest: 0.8956682 (957)\ttotal: 10m 3s\tremaining: 25.8s\n",
      "959:\tlearn: 0.9423479\ttest: 0.8956460\tbest: 0.8956682 (957)\ttotal: 10m 4s\tremaining: 25.2s\n",
      "960:\tlearn: 0.9423335\ttest: 0.8956016\tbest: 0.8956682 (957)\ttotal: 10m 4s\tremaining: 24.5s\n",
      "961:\tlearn: 0.9424097\ttest: 0.8956238\tbest: 0.8956682 (957)\ttotal: 10m 5s\tremaining: 23.9s\n",
      "962:\tlearn: 0.9425099\ttest: 0.8956460\tbest: 0.8956682 (957)\ttotal: 10m 6s\tremaining: 23.3s\n",
      "963:\tlearn: 0.9423904\ttest: 0.8954041\tbest: 0.8956682 (957)\ttotal: 10m 6s\tremaining: 22.7s\n",
      "964:\tlearn: 0.9424906\ttest: 0.8954041\tbest: 0.8956682 (957)\ttotal: 10m 7s\tremaining: 22s\n",
      "965:\tlearn: 0.9427339\ttest: 0.8956682\tbest: 0.8956682 (957)\ttotal: 10m 8s\tremaining: 21.4s\n",
      "966:\tlearn: 0.9428196\ttest: 0.8956682\tbest: 0.8956682 (957)\ttotal: 10m 8s\tremaining: 20.8s\n",
      "967:\tlearn: 0.9430054\ttest: 0.8956460\tbest: 0.8956682 (957)\ttotal: 10m 9s\tremaining: 20.1s\n",
      "968:\tlearn: 0.9430626\ttest: 0.8958656\tbest: 0.8958656 (968)\ttotal: 10m 9s\tremaining: 19.5s\n",
      "969:\tlearn: 0.9433580\ttest: 0.8959100\tbest: 0.8959100 (969)\ttotal: 10m 10s\tremaining: 18.9s\n",
      "970:\tlearn: 0.9435533\ttest: 0.8959100\tbest: 0.8959100 (969)\ttotal: 10m 11s\tremaining: 18.3s\n",
      "971:\tlearn: 0.9435153\ttest: 0.8959100\tbest: 0.8959100 (969)\ttotal: 10m 11s\tremaining: 17.6s\n",
      "972:\tlearn: 0.9435677\ttest: 0.8958878\tbest: 0.8959100 (969)\ttotal: 10m 12s\tremaining: 17s\n",
      "973:\tlearn: 0.9436009\ttest: 0.8958878\tbest: 0.8959100 (969)\ttotal: 10m 13s\tremaining: 16.4s\n",
      "974:\tlearn: 0.9435105\ttest: 0.8959100\tbest: 0.8959100 (969)\ttotal: 10m 13s\tremaining: 15.7s\n",
      "975:\tlearn: 0.9435725\ttest: 0.8957569\tbest: 0.8959100 (969)\ttotal: 10m 14s\tremaining: 15.1s\n",
      "976:\tlearn: 0.9438580\ttest: 0.8957791\tbest: 0.8959100 (969)\ttotal: 10m 14s\tremaining: 14.5s\n",
      "977:\tlearn: 0.9439296\ttest: 0.8957569\tbest: 0.8959100 (969)\ttotal: 10m 15s\tremaining: 13.8s\n",
      "978:\tlearn: 0.9439820\ttest: 0.8959765\tbest: 0.8959765 (978)\ttotal: 10m 16s\tremaining: 13.2s\n",
      "979:\tlearn: 0.9442342\ttest: 0.8959987\tbest: 0.8959987 (979)\ttotal: 10m 16s\tremaining: 12.6s\n",
      "980:\tlearn: 0.9443197\ttest: 0.8954485\tbest: 0.8959987 (979)\ttotal: 10m 17s\tremaining: 12s\n",
      "981:\tlearn: 0.9443197\ttest: 0.8954707\tbest: 0.8959987 (979)\ttotal: 10m 17s\tremaining: 11.3s\n",
      "982:\tlearn: 0.9445146\ttest: 0.8952287\tbest: 0.8959987 (979)\ttotal: 10m 18s\tremaining: 10.7s\n",
      "983:\tlearn: 0.9446427\ttest: 0.8954485\tbest: 0.8959987 (979)\ttotal: 10m 19s\tremaining: 10.1s\n",
      "984:\tlearn: 0.9449276\ttest: 0.8952065\tbest: 0.8959987 (979)\ttotal: 10m 19s\tremaining: 9.44s\n",
      "985:\tlearn: 0.9449751\ttest: 0.8951621\tbest: 0.8959987 (979)\ttotal: 10m 20s\tremaining: 8.81s\n",
      "986:\tlearn: 0.9451746\ttest: 0.8954485\tbest: 0.8959987 (979)\ttotal: 10m 21s\tremaining: 8.18s\n",
      "987:\tlearn: 0.9447894\ttest: 0.8954263\tbest: 0.8959987 (979)\ttotal: 10m 21s\tremaining: 7.55s\n",
      "988:\tlearn: 0.9448417\ttest: 0.8954263\tbest: 0.8959987 (979)\ttotal: 10m 22s\tremaining: 6.92s\n",
      "989:\tlearn: 0.9449174\ttest: 0.8954041\tbest: 0.8959987 (979)\ttotal: 10m 22s\tremaining: 6.29s\n",
      "990:\tlearn: 0.9450316\ttest: 0.8954485\tbest: 0.8959987 (979)\ttotal: 10m 23s\tremaining: 5.66s\n",
      "991:\tlearn: 0.9451884\ttest: 0.8953819\tbest: 0.8959987 (979)\ttotal: 10m 24s\tremaining: 5.03s\n",
      "992:\tlearn: 0.9452881\ttest: 0.8956460\tbest: 0.8959987 (979)\ttotal: 10m 24s\tremaining: 4.4s\n",
      "993:\tlearn: 0.9452455\ttest: 0.8956460\tbest: 0.8959987 (979)\ttotal: 10m 25s\tremaining: 3.77s\n",
      "994:\tlearn: 0.9454827\ttest: 0.8956460\tbest: 0.8959987 (979)\ttotal: 10m 26s\tremaining: 3.15s\n",
      "995:\tlearn: 0.9456723\ttest: 0.8956460\tbest: 0.8959987 (979)\ttotal: 10m 26s\tremaining: 2.52s\n",
      "996:\tlearn: 0.9459093\ttest: 0.8956460\tbest: 0.8959987 (979)\ttotal: 10m 27s\tremaining: 1.89s\n",
      "997:\tlearn: 0.9462032\ttest: 0.8956460\tbest: 0.8959987 (979)\ttotal: 10m 27s\tremaining: 1.26s\n",
      "998:\tlearn: 0.9464921\ttest: 0.8956460\tbest: 0.8959987 (979)\ttotal: 10m 28s\tremaining: 629ms\n",
      "999:\tlearn: 0.9467761\ttest: 0.8956460\tbest: 0.8959987 (979)\ttotal: 10m 29s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8959987166\n",
      "bestIteration = 979\n",
      "\n",
      "Shrink model to first 980 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x25085274790>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model_vect2 = CatBoostClassifier(random_state=42, eval_metric='F1', auto_class_weights='Balanced')\n",
    "cat_model_vect2.fit(X_train_vect, y_train, eval_set=(X_valid_vect, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшенная выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.067492\n",
      "0:\tlearn: 0.7373190\ttest: 0.2453372\tbest: 0.2453372 (0)\ttotal: 202ms\tremaining: 3m 21s\n",
      "20:\tlearn: 0.7997448\ttest: 0.3822163\tbest: 0.3822163 (20)\ttotal: 3.77s\tremaining: 2m 55s\n",
      "40:\tlearn: 0.8217453\ttest: 0.4176633\tbest: 0.4176633 (40)\ttotal: 7.34s\tremaining: 2m 51s\n",
      "60:\tlearn: 0.8247392\ttest: 0.6600624\tbest: 0.6621223 (58)\ttotal: 10.9s\tremaining: 2m 47s\n",
      "80:\tlearn: 0.8379322\ttest: 0.6874768\tbest: 0.6874768 (80)\ttotal: 14.4s\tremaining: 2m 43s\n",
      "100:\tlearn: 0.8488066\ttest: 0.6937799\tbest: 0.6964452 (98)\ttotal: 18s\tremaining: 2m 40s\n",
      "120:\tlearn: 0.8557609\ttest: 0.7020617\tbest: 0.7026428 (109)\ttotal: 21.5s\tremaining: 2m 36s\n",
      "140:\tlearn: 0.8629451\ttest: 0.7100917\tbest: 0.7102597 (137)\ttotal: 25.1s\tremaining: 2m 32s\n",
      "160:\tlearn: 0.8678812\ttest: 0.7115070\tbest: 0.7130562 (146)\ttotal: 28.6s\tremaining: 2m 29s\n",
      "180:\tlearn: 0.8733533\ttest: 0.7103983\tbest: 0.7169259 (175)\ttotal: 32.2s\tremaining: 2m 25s\n",
      "200:\tlearn: 0.8784523\ttest: 0.7214912\tbest: 0.7224557 (199)\ttotal: 35.7s\tremaining: 2m 21s\n",
      "220:\tlearn: 0.8832151\ttest: 0.7179579\tbest: 0.7224557 (199)\ttotal: 39.2s\tremaining: 2m 18s\n",
      "240:\tlearn: 0.8860246\ttest: 0.7197990\tbest: 0.7224557 (199)\ttotal: 42.7s\tremaining: 2m 14s\n",
      "260:\tlearn: 0.8894449\ttest: 0.7284241\tbest: 0.7284241 (260)\ttotal: 46.3s\tremaining: 2m 11s\n",
      "280:\tlearn: 0.8920877\ttest: 0.7232896\tbest: 0.7284241 (260)\ttotal: 49.8s\tremaining: 2m 7s\n",
      "300:\tlearn: 0.8970209\ttest: 0.7250626\tbest: 0.7284241 (260)\ttotal: 53.3s\tremaining: 2m 3s\n",
      "320:\tlearn: 0.9007069\ttest: 0.7280859\tbest: 0.7284241 (260)\ttotal: 56.8s\tremaining: 2m\n",
      "340:\tlearn: 0.9024630\ttest: 0.7276953\tbest: 0.7284241 (260)\ttotal: 1m\tremaining: 1m 56s\n",
      "360:\tlearn: 0.9048397\ttest: 0.7289586\tbest: 0.7294453 (354)\ttotal: 1m 3s\tremaining: 1m 53s\n",
      "380:\tlearn: 0.9071492\ttest: 0.7292483\tbest: 0.7294453 (354)\ttotal: 1m 7s\tremaining: 1m 49s\n",
      "400:\tlearn: 0.9087268\ttest: 0.7297971\tbest: 0.7297971 (400)\ttotal: 1m 10s\tremaining: 1m 45s\n",
      "420:\tlearn: 0.9106470\ttest: 0.7274343\tbest: 0.7302831 (402)\ttotal: 1m 14s\tremaining: 1m 42s\n",
      "440:\tlearn: 0.9129506\ttest: 0.7273050\tbest: 0.7302831 (402)\ttotal: 1m 17s\tremaining: 1m 38s\n",
      "460:\tlearn: 0.9142300\ttest: 0.7270793\tbest: 0.7302831 (402)\ttotal: 1m 21s\tremaining: 1m 35s\n",
      "480:\tlearn: 0.9164425\ttest: 0.7319844\tbest: 0.7321143 (479)\ttotal: 1m 25s\tremaining: 1m 31s\n",
      "500:\tlearn: 0.9177974\ttest: 0.7321397\tbest: 0.7324694 (496)\ttotal: 1m 28s\tremaining: 1m 28s\n",
      "520:\tlearn: 0.9191765\ttest: 0.7329214\tbest: 0.7337110 (506)\ttotal: 1m 32s\tremaining: 1m 24s\n",
      "540:\tlearn: 0.9201609\ttest: 0.7327327\tbest: 0.7337110 (506)\ttotal: 1m 35s\tremaining: 1m 21s\n",
      "560:\tlearn: 0.9215632\ttest: 0.7332862\tbest: 0.7345493 (549)\ttotal: 1m 39s\tremaining: 1m 17s\n",
      "580:\tlearn: 0.9224094\ttest: 0.7336985\tbest: 0.7345493 (549)\ttotal: 1m 42s\tremaining: 1m 13s\n",
      "600:\tlearn: 0.9227503\ttest: 0.7323446\tbest: 0.7345493 (549)\ttotal: 1m 46s\tremaining: 1m 10s\n",
      "620:\tlearn: 0.9238925\ttest: 0.7307895\tbest: 0.7345493 (549)\ttotal: 1m 49s\tremaining: 1m 6s\n",
      "640:\tlearn: 0.9250415\ttest: 0.7316300\tbest: 0.7345493 (549)\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "660:\tlearn: 0.9259259\ttest: 0.7337800\tbest: 0.7345493 (549)\ttotal: 1m 56s\tremaining: 59.8s\n",
      "680:\tlearn: 0.9268046\ttest: 0.7340388\tbest: 0.7345493 (549)\ttotal: 2m\tremaining: 56.2s\n",
      "700:\tlearn: 0.9279176\ttest: 0.7340257\tbest: 0.7345493 (549)\ttotal: 2m 3s\tremaining: 52.7s\n",
      "720:\tlearn: 0.9289391\ttest: 0.7346580\tbest: 0.7346580 (718)\ttotal: 2m 7s\tremaining: 49.2s\n",
      "740:\tlearn: 0.9299035\ttest: 0.7336260\tbest: 0.7346580 (718)\ttotal: 2m 10s\tremaining: 45.7s\n",
      "760:\tlearn: 0.9305230\ttest: 0.7326559\tbest: 0.7346580 (718)\ttotal: 2m 14s\tremaining: 42.1s\n",
      "780:\tlearn: 0.9316439\ttest: 0.7321429\tbest: 0.7346580 (718)\ttotal: 2m 17s\tremaining: 38.6s\n",
      "800:\tlearn: 0.9324765\ttest: 0.7338129\tbest: 0.7346580 (718)\ttotal: 2m 21s\tremaining: 35s\n",
      "820:\tlearn: 0.9332661\ttest: 0.7328779\tbest: 0.7346580 (718)\ttotal: 2m 24s\tremaining: 31.5s\n",
      "840:\tlearn: 0.9337490\ttest: 0.7333217\tbest: 0.7346580 (718)\ttotal: 2m 28s\tremaining: 28s\n",
      "860:\tlearn: 0.9341586\ttest: 0.7336719\tbest: 0.7346580 (718)\ttotal: 2m 31s\tremaining: 24.5s\n",
      "880:\tlearn: 0.9342075\ttest: 0.7326456\tbest: 0.7346580 (718)\ttotal: 2m 35s\tremaining: 20.9s\n",
      "900:\tlearn: 0.9352874\ttest: 0.7313927\tbest: 0.7346580 (718)\ttotal: 2m 38s\tremaining: 17.4s\n",
      "920:\tlearn: 0.9360260\ttest: 0.7303078\tbest: 0.7346580 (718)\ttotal: 2m 42s\tremaining: 13.9s\n",
      "940:\tlearn: 0.9365326\ttest: 0.7317668\tbest: 0.7346580 (718)\ttotal: 2m 45s\tremaining: 10.4s\n",
      "960:\tlearn: 0.9368990\ttest: 0.7318942\tbest: 0.7346580 (718)\ttotal: 2m 49s\tremaining: 6.86s\n",
      "980:\tlearn: 0.9376545\ttest: 0.7306286\tbest: 0.7346580 (718)\ttotal: 2m 52s\tremaining: 3.34s\n",
      "999:\tlearn: 0.9384411\ttest: 0.7319624\tbest: 0.7346580 (718)\ttotal: 2m 55s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7346579919\n",
      "bestIteration = 718\n",
      "\n",
      "Shrink model to first 719 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x25085274c70>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model_vect3 = CatBoostClassifier(random_state=42, eval_metric='F1', verbose=20)\n",
    "cat_model_vect3.fit(X_train_down_vect, y_train_down, eval_set=(X_valid_down_vect, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uwvf-vZ1ck5Q"
   },
   "source": [
    "#### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.101529\n",
      "0:\tlearn: 0.4543516\ttest: 0.4568591\tbest: 0.4568591 (0)\ttotal: 1.29s\tremaining: 21m 33s\n",
      "20:\tlearn: 0.5381818\ttest: 0.5413937\tbest: 0.5413937 (20)\ttotal: 25.3s\tremaining: 19m 37s\n",
      "40:\tlearn: 0.5902141\ttest: 0.5919589\tbest: 0.5919589 (39)\ttotal: 48.4s\tremaining: 18m 51s\n",
      "60:\tlearn: 0.6173991\ttest: 0.6155562\tbest: 0.6155562 (59)\ttotal: 1m 11s\tremaining: 18m 19s\n",
      "80:\tlearn: 0.6404869\ttest: 0.6431886\tbest: 0.6431886 (80)\ttotal: 1m 34s\tremaining: 17m 52s\n",
      "100:\tlearn: 0.6619937\ttest: 0.6605898\tbest: 0.6605898 (100)\ttotal: 1m 57s\tremaining: 17m 26s\n",
      "120:\tlearn: 0.6752214\ttest: 0.6721617\tbest: 0.6740859 (118)\ttotal: 2m 20s\tremaining: 17m\n",
      "140:\tlearn: 0.6911855\ttest: 0.6831189\tbest: 0.6831189 (139)\ttotal: 2m 43s\tremaining: 16m 35s\n",
      "160:\tlearn: 0.7010309\ttest: 0.6930281\tbest: 0.6933680 (159)\ttotal: 3m 6s\tremaining: 16m 11s\n",
      "180:\tlearn: 0.7084091\ttest: 0.6980352\tbest: 0.6980352 (180)\ttotal: 3m 29s\tremaining: 15m 47s\n",
      "200:\tlearn: 0.7182483\ttest: 0.7047668\tbest: 0.7050986 (199)\ttotal: 3m 52s\tremaining: 15m 23s\n",
      "220:\tlearn: 0.7235962\ttest: 0.7122869\tbest: 0.7127957 (219)\ttotal: 4m 15s\tremaining: 14m 59s\n",
      "240:\tlearn: 0.7302994\ttest: 0.7138150\tbest: 0.7146477 (238)\ttotal: 4m 38s\tremaining: 14m 36s\n",
      "260:\tlearn: 0.7381463\ttest: 0.7192540\tbest: 0.7192540 (260)\ttotal: 5m 1s\tremaining: 14m 12s\n",
      "280:\tlearn: 0.7425092\ttest: 0.7253133\tbest: 0.7253133 (280)\ttotal: 5m 24s\tremaining: 13m 49s\n",
      "300:\tlearn: 0.7466326\ttest: 0.7295409\tbest: 0.7295409 (300)\ttotal: 5m 46s\tremaining: 13m 25s\n",
      "320:\tlearn: 0.7518407\ttest: 0.7324224\tbest: 0.7325553 (319)\ttotal: 6m 9s\tremaining: 13m 2s\n",
      "340:\tlearn: 0.7563859\ttest: 0.7345220\tbest: 0.7347040 (336)\ttotal: 6m 32s\tremaining: 12m 38s\n",
      "360:\tlearn: 0.7610340\ttest: 0.7353086\tbest: 0.7353086 (357)\ttotal: 6m 55s\tremaining: 12m 15s\n",
      "380:\tlearn: 0.7637622\ttest: 0.7361419\tbest: 0.7361419 (379)\ttotal: 7m 18s\tremaining: 11m 52s\n",
      "400:\tlearn: 0.7651218\ttest: 0.7386280\tbest: 0.7389381 (399)\ttotal: 7m 41s\tremaining: 11m 28s\n",
      "420:\tlearn: 0.7687728\ttest: 0.7435144\tbest: 0.7435144 (418)\ttotal: 8m 3s\tremaining: 11m 5s\n",
      "440:\tlearn: 0.7707551\ttest: 0.7451747\tbest: 0.7451747 (437)\ttotal: 8m 26s\tremaining: 10m 42s\n",
      "460:\tlearn: 0.7729569\ttest: 0.7467057\tbest: 0.7470115 (459)\ttotal: 8m 49s\tremaining: 10m 19s\n",
      "480:\tlearn: 0.7750052\ttest: 0.7482330\tbest: 0.7482330 (477)\ttotal: 9m 12s\tremaining: 9m 56s\n",
      "500:\tlearn: 0.7783649\ttest: 0.7484812\tbest: 0.7491492 (493)\ttotal: 9m 35s\tremaining: 9m 33s\n",
      "520:\tlearn: 0.7794224\ttest: 0.7507274\tbest: 0.7507274 (519)\ttotal: 9m 58s\tremaining: 9m 9s\n",
      "540:\tlearn: 0.7814679\ttest: 0.7512740\tbest: 0.7512740 (540)\ttotal: 10m 20s\tremaining: 8m 46s\n",
      "560:\tlearn: 0.7837392\ttest: 0.7521823\tbest: 0.7521823 (558)\ttotal: 10m 43s\tremaining: 8m 23s\n",
      "580:\tlearn: 0.7851882\ttest: 0.7536302\tbest: 0.7536302 (577)\ttotal: 11m 7s\tremaining: 8m 1s\n",
      "600:\tlearn: 0.7882837\ttest: 0.7552549\tbest: 0.7555556 (596)\ttotal: 11m 30s\tremaining: 7m 38s\n",
      "620:\tlearn: 0.7908098\ttest: 0.7567568\tbest: 0.7567568 (618)\ttotal: 11m 52s\tremaining: 7m 15s\n",
      "640:\tlearn: 0.7916346\ttest: 0.7571739\tbest: 0.7585542 (635)\ttotal: 12m 15s\tremaining: 6m 52s\n",
      "660:\tlearn: 0.7925417\ttest: 0.7565217\tbest: 0.7585542 (635)\ttotal: 12m 38s\tremaining: 6m 29s\n",
      "680:\tlearn: 0.7944967\ttest: 0.7589200\tbest: 0.7592191 (677)\ttotal: 13m 1s\tremaining: 6m 6s\n",
      "700:\tlearn: 0.7966924\ttest: 0.7590188\tbest: 0.7592191 (677)\ttotal: 13m 24s\tremaining: 5m 43s\n",
      "720:\tlearn: 0.7985314\ttest: 0.7605769\tbest: 0.7605769 (717)\ttotal: 13m 48s\tremaining: 5m 20s\n",
      "740:\tlearn: 0.7997962\ttest: 0.7603266\tbest: 0.7607598 (722)\ttotal: 14m 11s\tremaining: 4m 57s\n",
      "760:\tlearn: 0.8017702\ttest: 0.7605566\tbest: 0.7609217 (749)\ttotal: 14m 34s\tremaining: 4m 34s\n",
      "780:\tlearn: 0.8039196\ttest: 0.7610365\tbest: 0.7610365 (778)\ttotal: 14m 57s\tremaining: 4m 11s\n",
      "800:\tlearn: 0.8051553\ttest: 0.7615163\tbest: 0.7615163 (797)\ttotal: 15m 19s\tremaining: 3m 48s\n",
      "820:\tlearn: 0.8068913\ttest: 0.7622244\tbest: 0.7622244 (819)\ttotal: 15m 42s\tremaining: 3m 25s\n",
      "840:\tlearn: 0.8091456\ttest: 0.7634537\tbest: 0.7634537 (840)\ttotal: 16m 5s\tremaining: 3m 2s\n",
      "860:\tlearn: 0.8094660\ttest: 0.7631579\tbest: 0.7634537 (840)\ttotal: 16m 28s\tremaining: 2m 39s\n",
      "880:\tlearn: 0.8107917\ttest: 0.7628619\tbest: 0.7634537 (840)\ttotal: 16m 51s\tremaining: 2m 16s\n",
      "900:\tlearn: 0.8113674\ttest: 0.7631579\tbest: 0.7634537 (840)\ttotal: 17m 13s\tremaining: 1m 53s\n",
      "920:\tlearn: 0.8118252\ttest: 0.7629754\tbest: 0.7634537 (840)\ttotal: 17m 36s\tremaining: 1m 30s\n",
      "940:\tlearn: 0.8125252\ttest: 0.7629063\tbest: 0.7634537 (840)\ttotal: 17m 59s\tremaining: 1m 7s\n",
      "960:\tlearn: 0.8131547\ttest: 0.7642704\tbest: 0.7642704 (958)\ttotal: 18m 22s\tremaining: 44.7s\n",
      "980:\tlearn: 0.8138938\ttest: 0.7647901\tbest: 0.7654498 (965)\ttotal: 18m 45s\tremaining: 21.8s\n",
      "999:\tlearn: 0.8144719\ttest: 0.7644953\tbest: 0.7654498 (965)\ttotal: 19m 6s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7654497733\n",
      "bestIteration = 965\n",
      "\n",
      "Shrink model to first 966 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x25085274b50>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model_tf1 = CatBoostClassifier(random_state=42, verbose=20, eval_metric='F1')\n",
    "cat_model_tf1.fit(X_train_tf, y_train, eval_set=(X_valid_tf, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сбалансированные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.101529\n",
      "0:\tlearn: 0.5122760\ttest: 0.5215189\tbest: 0.5215189 (0)\ttotal: 1.27s\tremaining: 21m 14s\n",
      "20:\tlearn: 0.7659913\ttest: 0.7736408\tbest: 0.7736408 (20)\ttotal: 25.4s\tremaining: 19m 43s\n",
      "40:\tlearn: 0.8048163\ttest: 0.8089702\tbest: 0.8091229 (39)\ttotal: 49.1s\tremaining: 19m 7s\n",
      "60:\tlearn: 0.8247869\ttest: 0.8253434\tbest: 0.8253434 (60)\ttotal: 1m 12s\tremaining: 18m 36s\n",
      "80:\tlearn: 0.8377229\ttest: 0.8404927\tbest: 0.8404927 (80)\ttotal: 1m 36s\tremaining: 18m 9s\n",
      "100:\tlearn: 0.8484599\ttest: 0.8524703\tbest: 0.8524703 (100)\ttotal: 1m 59s\tremaining: 17m 43s\n",
      "120:\tlearn: 0.8598209\ttest: 0.8587048\tbest: 0.8587048 (120)\ttotal: 2m 22s\tremaining: 17m 17s\n",
      "140:\tlearn: 0.8686854\ttest: 0.8628691\tbest: 0.8631256 (139)\ttotal: 2m 46s\tremaining: 16m 53s\n",
      "160:\tlearn: 0.8751079\ttest: 0.8683874\tbest: 0.8683874 (160)\ttotal: 3m 9s\tremaining: 16m 28s\n",
      "180:\tlearn: 0.8806486\ttest: 0.8714021\tbest: 0.8717302 (178)\ttotal: 3m 33s\tremaining: 16m 4s\n",
      "200:\tlearn: 0.8847461\ttest: 0.8740297\tbest: 0.8744793 (194)\ttotal: 3m 56s\tremaining: 15m 39s\n",
      "220:\tlearn: 0.8902364\ttest: 0.8768593\tbest: 0.8768593 (220)\ttotal: 4m 19s\tremaining: 15m 15s\n",
      "240:\tlearn: 0.8945707\ttest: 0.8793079\tbest: 0.8796670 (239)\ttotal: 4m 42s\tremaining: 14m 50s\n",
      "260:\tlearn: 0.8982186\ttest: 0.8805943\tbest: 0.8812009 (256)\ttotal: 5m 6s\tremaining: 14m 26s\n",
      "280:\tlearn: 0.9012038\ttest: 0.8834098\tbest: 0.8834540 (278)\ttotal: 5m 29s\tremaining: 14m 2s\n",
      "300:\tlearn: 0.9049395\ttest: 0.8845356\tbest: 0.8845576 (298)\ttotal: 5m 52s\tremaining: 13m 38s\n",
      "320:\tlearn: 0.9082067\ttest: 0.8850056\tbest: 0.8853619 (317)\ttotal: 6m 15s\tremaining: 13m 14s\n",
      "340:\tlearn: 0.9100650\ttest: 0.8853869\tbest: 0.8854752 (322)\ttotal: 6m 38s\tremaining: 12m 50s\n",
      "360:\tlearn: 0.9137232\ttest: 0.8868152\tbest: 0.8875720 (353)\ttotal: 7m 2s\tremaining: 12m 27s\n",
      "380:\tlearn: 0.9152023\ttest: 0.8871486\tbest: 0.8876383 (376)\ttotal: 7m 25s\tremaining: 12m 4s\n",
      "400:\tlearn: 0.9173057\ttest: 0.8882366\tbest: 0.8884149 (394)\ttotal: 7m 48s\tremaining: 11m 40s\n",
      "420:\tlearn: 0.9197762\ttest: 0.8899688\tbest: 0.8899688 (420)\ttotal: 8m 11s\tremaining: 11m 16s\n",
      "440:\tlearn: 0.9216118\ttest: 0.8895692\tbest: 0.8903012 (431)\ttotal: 8m 34s\tremaining: 10m 52s\n",
      "460:\tlearn: 0.9238823\ttest: 0.8898804\tbest: 0.8903012 (431)\ttotal: 8m 57s\tremaining: 10m 28s\n",
      "480:\tlearn: 0.9260108\ttest: 0.8889259\tbest: 0.8903012 (431)\ttotal: 9m 21s\tremaining: 10m 5s\n",
      "500:\tlearn: 0.9282696\ttest: 0.8886815\tbest: 0.8903012 (431)\ttotal: 9m 44s\tremaining: 9m 41s\n",
      "520:\tlearn: 0.9296552\ttest: 0.8887036\tbest: 0.8903012 (431)\ttotal: 10m 7s\tremaining: 9m 18s\n",
      "540:\tlearn: 0.9309555\ttest: 0.8896364\tbest: 0.8903012 (431)\ttotal: 10m 30s\tremaining: 8m 54s\n",
      "560:\tlearn: 0.9327902\ttest: 0.8895922\tbest: 0.8903012 (431)\ttotal: 10m 53s\tremaining: 8m 31s\n",
      "580:\tlearn: 0.9342806\ttest: 0.8895471\tbest: 0.8903012 (431)\ttotal: 11m 16s\tremaining: 8m 7s\n",
      "600:\tlearn: 0.9353045\ttest: 0.8896135\tbest: 0.8903012 (431)\ttotal: 11m 39s\tremaining: 7m 44s\n",
      "620:\tlearn: 0.9365588\ttest: 0.8909657\tbest: 0.8911871 (619)\ttotal: 12m 2s\tremaining: 7m 20s\n",
      "640:\tlearn: 0.9384500\ttest: 0.8911428\tbest: 0.8911871 (619)\ttotal: 12m 25s\tremaining: 6m 57s\n",
      "660:\tlearn: 0.9397460\ttest: 0.8910764\tbest: 0.8914085 (641)\ttotal: 12m 48s\tremaining: 6m 34s\n",
      "680:\tlearn: 0.9406662\ttest: 0.8897012\tbest: 0.8914085 (641)\ttotal: 13m 11s\tremaining: 6m 10s\n",
      "700:\tlearn: 0.9419337\ttest: 0.8895012\tbest: 0.8914085 (641)\ttotal: 13m 35s\tremaining: 5m 47s\n",
      "720:\tlearn: 0.9426978\ttest: 0.8889004\tbest: 0.8914085 (641)\ttotal: 13m 58s\tremaining: 5m 24s\n",
      "740:\tlearn: 0.9435557\ttest: 0.8906772\tbest: 0.8914085 (641)\ttotal: 14m 21s\tremaining: 5m 1s\n",
      "760:\tlearn: 0.9449073\ttest: 0.8895004\tbest: 0.8914085 (641)\ttotal: 14m 44s\tremaining: 4m 37s\n",
      "780:\tlearn: 0.9461061\ttest: 0.8897891\tbest: 0.8914085 (641)\ttotal: 15m 7s\tremaining: 4m 14s\n",
      "800:\tlearn: 0.9473256\ttest: 0.8898334\tbest: 0.8914085 (641)\ttotal: 15m 30s\tremaining: 3m 51s\n",
      "820:\tlearn: 0.9482528\ttest: 0.8897005\tbest: 0.8914085 (641)\ttotal: 15m 53s\tremaining: 3m 27s\n",
      "840:\tlearn: 0.9488387\ttest: 0.8899005\tbest: 0.8914085 (641)\ttotal: 16m 16s\tremaining: 3m 4s\n",
      "860:\tlearn: 0.9493259\ttest: 0.8900778\tbest: 0.8914085 (641)\ttotal: 16m 39s\tremaining: 2m 41s\n",
      "880:\tlearn: 0.9505841\ttest: 0.8911871\tbest: 0.8914085 (641)\ttotal: 17m 1s\tremaining: 2m 18s\n",
      "900:\tlearn: 0.9512495\ttest: 0.8917411\tbest: 0.8917411 (900)\ttotal: 17m 25s\tremaining: 1m 54s\n",
      "920:\tlearn: 0.9526263\ttest: 0.8917633\tbest: 0.8919847 (905)\ttotal: 17m 47s\tremaining: 1m 31s\n",
      "940:\tlearn: 0.9539319\ttest: 0.8914088\tbest: 0.8920291 (922)\ttotal: 18m 9s\tremaining: 1m 8s\n",
      "960:\tlearn: 0.9549402\ttest: 0.8915863\tbest: 0.8920291 (922)\ttotal: 18m 32s\tremaining: 45.1s\n",
      "980:\tlearn: 0.9559877\ttest: 0.8911205\tbest: 0.8920291 (922)\ttotal: 18m 54s\tremaining: 22s\n",
      "999:\tlearn: 0.9569596\ttest: 0.8902097\tbest: 0.8920291 (922)\ttotal: 19m 15s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8920290686\n",
      "bestIteration = 922\n",
      "\n",
      "Shrink model to first 923 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x25085274d30>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model_tf2 = CatBoostClassifier(random_state=42,\n",
    "                                   verbose=20,\n",
    "                                   eval_metric='F1',\n",
    "                                   auto_class_weights='Balanced')\n",
    "cat_model_tf2.fit(X_train_tf, y_train, eval_set=(X_valid_tf, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшенная выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.067492\n",
      "0:\tlearn: 0.4956677\ttest: 0.4879068\tbest: 0.4879068 (0)\ttotal: 342ms\tremaining: 5m 41s\n",
      "20:\tlearn: 0.8003557\ttest: 0.3786462\tbest: 0.5501271 (1)\ttotal: 6.55s\tremaining: 5m 5s\n",
      "40:\tlearn: 0.8096810\ttest: 0.6355004\tbest: 0.6397481 (37)\ttotal: 12.7s\tremaining: 4m 55s\n",
      "60:\tlearn: 0.8256263\ttest: 0.6582418\tbest: 0.6582418 (60)\ttotal: 18.8s\tremaining: 4m 49s\n",
      "80:\tlearn: 0.8446550\ttest: 0.6777939\tbest: 0.6777939 (80)\ttotal: 24.8s\tremaining: 4m 41s\n",
      "100:\tlearn: 0.8524702\ttest: 0.6874547\tbest: 0.6876364 (98)\ttotal: 30.9s\tremaining: 4m 35s\n",
      "120:\tlearn: 0.8587810\ttest: 0.6852248\tbest: 0.6882459 (106)\ttotal: 37s\tremaining: 4m 28s\n",
      "140:\tlearn: 0.8665646\ttest: 0.6916919\tbest: 0.6916919 (140)\ttotal: 43s\tremaining: 4m 22s\n",
      "160:\tlearn: 0.8730249\ttest: 0.6971794\tbest: 0.6971794 (160)\ttotal: 49.2s\tremaining: 4m 16s\n",
      "180:\tlearn: 0.8783841\ttest: 0.7017296\tbest: 0.7030946 (177)\ttotal: 55.2s\tremaining: 4m 9s\n",
      "200:\tlearn: 0.8857479\ttest: 0.7046815\tbest: 0.7055918 (198)\ttotal: 1m 1s\tremaining: 4m 3s\n",
      "220:\tlearn: 0.8886065\ttest: 0.7049755\tbest: 0.7062346 (207)\ttotal: 1m 7s\tremaining: 3m 57s\n",
      "240:\tlearn: 0.8938626\ttest: 0.7033159\tbest: 0.7062346 (207)\ttotal: 1m 13s\tremaining: 3m 51s\n",
      "260:\tlearn: 0.8970781\ttest: 0.7094524\tbest: 0.7094524 (260)\ttotal: 1m 19s\tremaining: 3m 44s\n",
      "280:\tlearn: 0.9017795\ttest: 0.7117995\tbest: 0.7117995 (276)\ttotal: 1m 25s\tremaining: 3m 38s\n",
      "300:\tlearn: 0.9055954\ttest: 0.7150313\tbest: 0.7150313 (300)\ttotal: 1m 31s\tremaining: 3m 32s\n",
      "320:\tlearn: 0.9077975\ttest: 0.7174935\tbest: 0.7174935 (320)\ttotal: 1m 37s\tremaining: 3m 26s\n",
      "340:\tlearn: 0.9104166\ttest: 0.7155232\tbest: 0.7177700 (322)\ttotal: 1m 43s\tremaining: 3m 20s\n",
      "360:\tlearn: 0.9130717\ttest: 0.7151767\tbest: 0.7177700 (322)\ttotal: 1m 50s\tremaining: 3m 14s\n",
      "380:\tlearn: 0.9162580\ttest: 0.7164850\tbest: 0.7197352 (374)\ttotal: 1m 56s\tremaining: 3m 8s\n",
      "400:\tlearn: 0.9182890\ttest: 0.7194594\tbest: 0.7201668 (392)\ttotal: 2m 2s\tremaining: 3m 2s\n",
      "420:\tlearn: 0.9198706\ttest: 0.7211073\tbest: 0.7212320 (419)\ttotal: 2m 8s\tremaining: 2m 56s\n",
      "440:\tlearn: 0.9216420\ttest: 0.7238327\tbest: 0.7248089 (434)\ttotal: 2m 15s\tremaining: 2m 51s\n",
      "460:\tlearn: 0.9237366\ttest: 0.7225583\tbest: 0.7248089 (434)\ttotal: 2m 21s\tremaining: 2m 45s\n",
      "480:\tlearn: 0.9264137\ttest: 0.7227123\tbest: 0.7248089 (434)\ttotal: 2m 28s\tremaining: 2m 40s\n",
      "500:\tlearn: 0.9277762\ttest: 0.7239709\tbest: 0.7248089 (434)\ttotal: 2m 34s\tremaining: 2m 34s\n",
      "520:\tlearn: 0.9299463\ttest: 0.7220690\tbest: 0.7248089 (434)\ttotal: 2m 41s\tremaining: 2m 28s\n",
      "540:\tlearn: 0.9313194\ttest: 0.7231989\tbest: 0.7248089 (434)\ttotal: 2m 47s\tremaining: 2m 21s\n",
      "560:\tlearn: 0.9333394\ttest: 0.7218407\tbest: 0.7248089 (434)\ttotal: 2m 53s\tremaining: 2m 15s\n",
      "580:\tlearn: 0.9348294\ttest: 0.7222794\tbest: 0.7248089 (434)\ttotal: 2m 59s\tremaining: 2m 9s\n",
      "600:\tlearn: 0.9365595\ttest: 0.7196166\tbest: 0.7248089 (434)\ttotal: 3m 5s\tremaining: 2m 3s\n",
      "620:\tlearn: 0.9383055\ttest: 0.7205606\tbest: 0.7248089 (434)\ttotal: 3m 12s\tremaining: 1m 57s\n",
      "640:\tlearn: 0.9392154\ttest: 0.7205330\tbest: 0.7248089 (434)\ttotal: 3m 18s\tremaining: 1m 51s\n",
      "660:\tlearn: 0.9409402\ttest: 0.7182546\tbest: 0.7248089 (434)\ttotal: 3m 25s\tremaining: 1m 45s\n",
      "680:\tlearn: 0.9422279\ttest: 0.7177310\tbest: 0.7248089 (434)\ttotal: 3m 31s\tremaining: 1m 39s\n",
      "700:\tlearn: 0.9432259\ttest: 0.7180010\tbest: 0.7248089 (434)\ttotal: 3m 38s\tremaining: 1m 33s\n",
      "720:\tlearn: 0.9445052\ttest: 0.7194686\tbest: 0.7248089 (434)\ttotal: 3m 44s\tremaining: 1m 26s\n",
      "740:\tlearn: 0.9454943\ttest: 0.7211997\tbest: 0.7248089 (434)\ttotal: 3m 50s\tremaining: 1m 20s\n",
      "760:\tlearn: 0.9463139\ttest: 0.7209540\tbest: 0.7248089 (434)\ttotal: 3m 57s\tremaining: 1m 14s\n",
      "780:\tlearn: 0.9476654\ttest: 0.7208589\tbest: 0.7248089 (434)\ttotal: 4m 3s\tremaining: 1m 8s\n",
      "800:\tlearn: 0.9487086\ttest: 0.7204082\tbest: 0.7248089 (434)\ttotal: 4m 9s\tremaining: 1m 2s\n",
      "820:\tlearn: 0.9496409\ttest: 0.7195516\tbest: 0.7248089 (434)\ttotal: 4m 15s\tremaining: 55.8s\n",
      "840:\tlearn: 0.9501658\ttest: 0.7183840\tbest: 0.7248089 (434)\ttotal: 4m 22s\tremaining: 49.6s\n",
      "860:\tlearn: 0.9515374\ttest: 0.7185751\tbest: 0.7248089 (434)\ttotal: 4m 28s\tremaining: 43.3s\n",
      "880:\tlearn: 0.9525279\ttest: 0.7184005\tbest: 0.7248089 (434)\ttotal: 4m 34s\tremaining: 37.1s\n",
      "900:\tlearn: 0.9536466\ttest: 0.7187130\tbest: 0.7248089 (434)\ttotal: 4m 41s\tremaining: 30.9s\n",
      "920:\tlearn: 0.9546094\ttest: 0.7186338\tbest: 0.7248089 (434)\ttotal: 4m 47s\tremaining: 24.6s\n",
      "940:\tlearn: 0.9552374\ttest: 0.7177324\tbest: 0.7248089 (434)\ttotal: 4m 53s\tremaining: 18.4s\n",
      "960:\tlearn: 0.9563445\ttest: 0.7176113\tbest: 0.7248089 (434)\ttotal: 4m 59s\tremaining: 12.2s\n",
      "980:\tlearn: 0.9569313\ttest: 0.7171972\tbest: 0.7248089 (434)\ttotal: 5m 6s\tremaining: 5.93s\n",
      "999:\tlearn: 0.9571202\ttest: 0.7166891\tbest: 0.7248089 (434)\ttotal: 5m 12s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7248088951\n",
      "bestIteration = 434\n",
      "\n",
      "Shrink model to first 435 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x25085274b20>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model_tf3 = CatBoostClassifier(random_state=42, verbose=20, eval_metric='F1')\n",
    "cat_model_tf3.fit(X_train_down_tf, y_train_down, eval_set=(X_valid_down_tf, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения f1 модели CatBoost  \n",
    "\n",
    "Данные| F1| iteration|\n",
    ":-----|:--|:---------|\n",
    "CountVectorizer| 0.72| 882|\n",
    "CountVectorizer_balanced| 0.88| 940|\n",
    "CountVectorizer_downsample| 0.71| 375|\n",
    "TfidfVectorizer| 0.75| 907|\n",
    "TfidfVectorizer_balanced| 0.89| 935|\n",
    "TfidfVectorizer_downsample| 0.71| 428|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBMClissifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_func(X_train, y_train, X_valid, y_valid, class_weight):\n",
    "    model = lgb.LGBMClassifier(objective=\"binary\", \n",
    "                               random_state=42, \n",
    "                               verbosity=20,\n",
    "                              class_weight=class_weight)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_valid)\n",
    "    f1 = f1_score(y_valid, pred)\n",
    "    return model, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11330, number of negative: 100174\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.997644\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.997644\n",
      "[LightGBM] [Debug] init for col-wise cost 1.841167 seconds, init for row-wise cost 1.955342 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.962122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 46590\n",
      "[LightGBM] [Info] Number of data points in the train set: 111504, number of used features: 10695\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101611 -> initscore=-2.179455\n",
      "[LightGBM] [Info] Start training from score -2.179455\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n"
     ]
    }
   ],
   "source": [
    "lgb_model_vect1, lgb_f1_vect1 = lgb_func(X_train_vect.astype('float'),\n",
    "                                         y_train, \n",
    "                                         X_valid_vect.astype('float'), \n",
    "                                         y_valid, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение f1 0.75\n"
     ]
    }
   ],
   "source": [
    "print(f'Значение f1 {lgb_f1_vect1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сбалансированные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11330, number of negative: 100174\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.997644\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.997644\n",
      "[LightGBM] [Debug] init for col-wise cost 1.974267 seconds, init for row-wise cost 1.890505 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.981207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 46590\n",
      "[LightGBM] [Info] Number of data points in the train set: 111504, number of used features: 10695\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n"
     ]
    }
   ],
   "source": [
    "lgb_model_vect2, lgb_f1_vect2 = lgb_func(X_train_vect.astype('float'),\n",
    "                                         y_train, \n",
    "                                         X_valid_vect.astype('float'), \n",
    "                                         y_valid, 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение f1 0.76\n"
     ]
    }
   ],
   "source": [
    "print(f'Значение f1 {lgb_f1_vect2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшенная выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11330, number of negative: 10017\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.994612\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.994612\n",
      "[LightGBM] [Debug] init for col-wise cost 0.109674 seconds, init for row-wise cost 0.109748 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 13462\n",
      "[LightGBM] [Info] Number of data points in the train set: 21347, number of used features: 3460\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.530754 -> initscore=0.123170\n",
      "[LightGBM] [Info] Start training from score 0.123170\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n"
     ]
    }
   ],
   "source": [
    "lgb_model_vect3, lgb_f1_vect3 = lgb_func(X_train_down_vect.astype('float'), \n",
    "                                         y_train_down,\n",
    "                                         X_valid_down_vect.astype('float'),\n",
    "                                         y_valid, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение f1 0.72\n"
     ]
    }
   ],
   "source": [
    "print(f'Значение f1 {lgb_f1_vect3:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11330, number of negative: 100174\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.997644\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.997644\n",
      "[LightGBM] [Debug] init for col-wise cost 1.931295 seconds, init for row-wise cost 1.909262 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.054442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 569538\n",
      "[LightGBM] [Info] Number of data points in the train set: 111504, number of used features: 10695\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101611 -> initscore=-2.179455\n",
      "[LightGBM] [Info] Start training from score -2.179455\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n"
     ]
    }
   ],
   "source": [
    "lgb_model_tf1, lgb_f1_tf1 = lgb_func(X_train_tf, y_train, X_valid_tf, y_valid, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение f1 0.76\n"
     ]
    }
   ],
   "source": [
    "print(f'Значение f1 {lgb_f1_tf1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сбалансированные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11330, number of negative: 100174\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.997644\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.997644\n",
      "[LightGBM] [Debug] init for col-wise cost 1.871253 seconds, init for row-wise cost 1.990715 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.993854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 569538\n",
      "[LightGBM] [Info] Number of data points in the train set: 111504, number of used features: 10695\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n"
     ]
    }
   ],
   "source": [
    "lgb_model_tf2, lgb_f1_tf2 = lgb_func(X_train_tf, y_train, X_valid_tf, y_valid, 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение f1 0.75\n"
     ]
    }
   ],
   "source": [
    "print(f'Значение f1 {lgb_f1_tf2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшенная выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11330, number of negative: 10017\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.994612\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.994612\n",
      "[LightGBM] [Debug] init for col-wise cost 0.153387 seconds, init for row-wise cost 0.129377 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.172415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 123137\n",
      "[LightGBM] [Info] Number of data points in the train set: 21347, number of used features: 3460\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.530754 -> initscore=0.123170\n",
      "[LightGBM] [Info] Start training from score 0.123170\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n"
     ]
    }
   ],
   "source": [
    "lgb_model_tf3, lgb_f1_tf3 = lgb_func(X_train_down_tf, y_train_down, X_valid_down_tf, y_valid, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение f1 0.72\n"
     ]
    }
   ],
   "source": [
    "print(f'Значение f1 {lgb_f1_tf3:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['CountVectorizer', 'CountVectorizer_balanced', 'CountVectorizer_downsample',\n",
    "         'TfidfVectorizer', 'TfidfVectorizer_balanced', 'TfidfVectorizer_downsample']\n",
    "data = {'f1': [lgb_f1_vect1, lgb_f1_vect2, lgb_f1_vect3,\n",
    "               lgb_f1_tf1, lgb_f1_tf2, lgb_f1_tf3]}\n",
    "lgb_values = pd.DataFrame(data=data, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения f1 на модели LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CountVectorizer</th>\n",
       "      <td>0.749880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer_balanced</th>\n",
       "      <td>0.756593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer_downsample</th>\n",
       "      <td>0.719480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer</th>\n",
       "      <td>0.755992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer_balanced</th>\n",
       "      <td>0.749577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer_downsample</th>\n",
       "      <td>0.719958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  f1\n",
       "CountVectorizer             0.749880\n",
       "CountVectorizer_balanced    0.756593\n",
       "CountVectorizer_downsample  0.719480\n",
       "TfidfVectorizer             0.755992\n",
       "TfidfVectorizer_balanced    0.749577\n",
       "TfidfVectorizer_downsample  0.719958"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyZlXLsqiop8"
   },
   "source": [
    "**Вывод:**  \n",
    "Самое высокое значение f1 (0.89) у модели CatBoost на данных сбалансированных и преобразованных с помощью TfidfVectorizer. Ее и протестируем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6NxwzJnQaO6"
   },
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtOQs5jrUzc0"
   },
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7682346219767663"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_predict = cat_model_tf2.predict(X_test_tf)\n",
    "total_f1 = f1_score(y_test, total_predict)\n",
    "total_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dl3ib2gTiALV"
   },
   "source": [
    "**Вывод:**  \n",
    "На тесте модель показала значение f1 0.76, что выше значения в поставленной задаче (0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cTgEHfTV1MY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 4,
    "start_time": "2022-06-19T09:10:44.555Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-19T09:10:44.562Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-19T09:10:44.569Z"
   },
   {
    "duration": 3422,
    "start_time": "2022-06-19T09:10:44.580Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.006Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.007Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.009Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.011Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.012Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.014Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.016Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.018Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.020Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.021Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.023Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.053Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.054Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.055Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.056Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.058Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.059Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.060Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.061Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.063Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.064Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.065Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.066Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.067Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.069Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.070Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.072Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.073Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.075Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.077Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.078Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.080Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.081Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.082Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.083Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.084Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.085Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.086Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.088Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.089Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.091Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.153Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.154Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.155Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.156Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.157Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.158Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.159Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.160Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.161Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.162Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.163Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.165Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.166Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.167Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.168Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.169Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.170Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.171Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.173Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.174Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.175Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.176Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.177Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.178Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.179Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.180Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.182Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.183Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.184Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.184Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.186Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.188Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-19T09:10:48.189Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-19T09:11:32.778Z"
   },
   {
    "duration": 6016,
    "start_time": "2022-06-19T09:11:32.786Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-19T09:11:38.804Z"
   },
   {
    "duration": 2123,
    "start_time": "2022-06-19T09:11:38.808Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-19T09:11:40.932Z"
   },
   {
    "duration": 112,
    "start_time": "2022-06-19T09:11:40.936Z"
   },
   {
    "duration": 2248,
    "start_time": "2022-06-19T09:11:41.050Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-19T09:11:43.301Z"
   },
   {
    "duration": 383,
    "start_time": "2022-06-19T09:11:43.306Z"
   },
   {
    "duration": 5324,
    "start_time": "2022-06-19T09:11:43.692Z"
   },
   {
    "duration": 39898,
    "start_time": "2022-06-19T09:11:49.019Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-19T09:12:28.919Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-19T09:12:28.952Z"
   },
   {
    "duration": 443,
    "start_time": "2022-06-19T09:12:28.974Z"
   },
   {
    "duration": 3967,
    "start_time": "2022-06-19T09:12:29.418Z"
   },
   {
    "duration": 7397,
    "start_time": "2022-06-19T09:12:33.387Z"
   },
   {
    "duration": 36,
    "start_time": "2022-06-19T09:12:40.788Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-19T09:12:40.825Z"
   },
   {
    "duration": 52,
    "start_time": "2022-06-19T09:12:40.833Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-19T09:12:40.889Z"
   },
   {
    "duration": 35,
    "start_time": "2022-06-19T09:12:40.909Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-19T09:12:40.946Z"
   },
   {
    "duration": 2982,
    "start_time": "2022-06-19T09:12:40.990Z"
   },
   {
    "duration": 48,
    "start_time": "2022-06-19T09:52:33.921Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-19T09:52:45.619Z"
   },
   {
    "duration": 2048,
    "start_time": "2022-06-19T09:52:45.623Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-19T09:52:47.673Z"
   },
   {
    "duration": 2431,
    "start_time": "2022-06-19T09:52:47.678Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-19T09:52:50.111Z"
   },
   {
    "duration": 117,
    "start_time": "2022-06-19T09:52:50.115Z"
   },
   {
    "duration": 2060,
    "start_time": "2022-06-19T09:52:50.233Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-19T09:52:52.294Z"
   },
   {
    "duration": 387,
    "start_time": "2022-06-19T09:52:52.301Z"
   },
   {
    "duration": 3818,
    "start_time": "2022-06-19T09:52:52.690Z"
   },
   {
    "duration": 34784,
    "start_time": "2022-06-19T09:52:56.510Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-19T09:53:31.296Z"
   },
   {
    "duration": 40,
    "start_time": "2022-06-19T09:53:31.320Z"
   },
   {
    "duration": 415,
    "start_time": "2022-06-19T09:53:31.362Z"
   },
   {
    "duration": 3732,
    "start_time": "2022-06-19T09:53:31.779Z"
   },
   {
    "duration": 6268,
    "start_time": "2022-06-19T09:53:35.513Z"
   },
   {
    "duration": 33,
    "start_time": "2022-06-19T09:53:41.783Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-19T09:53:41.817Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-19T09:53:41.821Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-19T09:53:41.833Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-19T09:53:41.854Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-19T09:53:41.885Z"
   },
   {
    "duration": 2676,
    "start_time": "2022-06-19T09:53:41.912Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-19T09:53:44.591Z"
   },
   {
    "duration": 2483,
    "start_time": "2022-06-19T09:54:17.035Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-19T09:54:19.520Z"
   },
   {
    "duration": 102,
    "start_time": "2022-06-19T09:54:21.053Z"
   },
   {
    "duration": 2067,
    "start_time": "2022-06-19T09:54:23.217Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-19T09:54:25.687Z"
   },
   {
    "duration": 356,
    "start_time": "2022-06-19T09:54:29.158Z"
   },
   {
    "duration": 3847,
    "start_time": "2022-06-19T09:54:31.655Z"
   },
   {
    "duration": 35331,
    "start_time": "2022-06-19T09:54:35.504Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-19T09:55:10.837Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-19T09:55:10.862Z"
   },
   {
    "duration": 394,
    "start_time": "2022-06-19T09:55:10.876Z"
   },
   {
    "duration": 3580,
    "start_time": "2022-06-19T09:55:11.272Z"
   },
   {
    "duration": 6274,
    "start_time": "2022-06-19T09:55:14.854Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-19T09:55:21.130Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-19T09:55:21.170Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-19T09:55:21.174Z"
   },
   {
    "duration": 28,
    "start_time": "2022-06-19T09:55:21.181Z"
   },
   {
    "duration": 25,
    "start_time": "2022-06-19T09:55:21.210Z"
   },
   {
    "duration": 2792,
    "start_time": "2022-06-19T09:55:21.921Z"
   },
   {
    "duration": 785,
    "start_time": "2022-06-19T14:20:55.104Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-19T14:21:06.248Z"
   },
   {
    "duration": 267,
    "start_time": "2022-06-19T14:21:07.078Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-19T14:21:16.704Z"
   },
   {
    "duration": 5188,
    "start_time": "2022-06-19T14:23:48.474Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-19T14:23:54.548Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-19T14:23:55.889Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-19T14:24:06.872Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-19T14:24:14.379Z"
   },
   {
    "duration": 34309,
    "start_time": "2022-06-19T14:24:54.918Z"
   },
   {
    "duration": 40,
    "start_time": "2022-06-19T14:25:29.229Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-19T14:25:29.271Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-19T14:42:37.612Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-19T14:42:41.301Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-19T14:42:43.412Z"
   },
   {
    "duration": 5503,
    "start_time": "2022-06-19T14:43:13.241Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-19T14:44:26.200Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-19T14:44:40.405Z"
   },
   {
    "duration": 746,
    "start_time": "2022-06-19T14:45:00.933Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-19T14:45:18.215Z"
   },
   {
    "duration": 45,
    "start_time": "2022-06-19T14:48:46.160Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-19T14:48:49.462Z"
   },
   {
    "duration": 93,
    "start_time": "2022-06-19T14:49:55.404Z"
   },
   {
    "duration": 63506,
    "start_time": "2022-06-19T14:50:12.579Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-19T14:51:16.088Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-19T14:53:41.258Z"
   },
   {
    "duration": 32,
    "start_time": "2022-06-19T15:02:27.813Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-19T15:02:48.171Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-19T15:02:55.124Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-19T15:03:26.775Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-19T15:03:55.452Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-19T15:03:59.575Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-19T15:05:12.263Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-19T15:05:17.470Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-19T15:05:39.526Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-19T15:05:41.851Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-19T15:05:47.516Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-19T15:09:29.122Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-19T15:11:23.664Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-19T15:11:46.975Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-19T15:12:50.920Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-19T15:13:56.179Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-19T15:14:04.312Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-19T15:21:16.996Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-19T15:21:23.204Z"
   },
   {
    "duration": 267,
    "start_time": "2022-06-19T15:22:48.807Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-19T15:22:53.059Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-19T15:23:13.661Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-19T15:23:17.812Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-19T15:24:04.850Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-19T15:24:10.907Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-19T15:24:53.499Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-19T15:27:11.565Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-19T15:27:20.804Z"
   },
   {
    "duration": 77,
    "start_time": "2022-06-23T12:35:54.504Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-23T12:48:33.342Z"
   },
   {
    "duration": 7728,
    "start_time": "2022-06-23T12:48:33.347Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-23T12:48:41.077Z"
   },
   {
    "duration": 2996,
    "start_time": "2022-06-23T12:48:41.083Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-23T12:48:44.081Z"
   },
   {
    "duration": 45,
    "start_time": "2022-06-23T12:48:44.086Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-23T12:48:44.132Z"
   },
   {
    "duration": 2334,
    "start_time": "2022-06-23T12:48:44.174Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-23T12:48:46.510Z"
   },
   {
    "duration": 292,
    "start_time": "2022-06-23T12:48:46.516Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-23T12:48:46.810Z"
   },
   {
    "duration": 91897,
    "start_time": "2022-06-23T12:48:46.822Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-23T12:50:18.721Z"
   },
   {
    "duration": 393,
    "start_time": "2022-06-23T12:50:18.741Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-23T12:50:19.138Z"
   },
   {
    "duration": 108,
    "start_time": "2022-06-23T12:50:19.143Z"
   },
   {
    "duration": 4928,
    "start_time": "2022-06-23T12:50:19.253Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-23T12:50:24.183Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-23T12:50:24.188Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-23T12:50:24.197Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-23T12:50:24.236Z"
   },
   {
    "duration": 1910,
    "start_time": "2022-06-23T12:50:24.243Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-23T12:50:26.155Z"
   },
   {
    "duration": 5024,
    "start_time": "2022-06-23T12:50:26.161Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-23T12:50:31.187Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-23T12:50:31.193Z"
   },
   {
    "duration": 1972,
    "start_time": "2022-06-23T12:50:31.221Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-23T12:50:33.195Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-23T12:50:33.201Z"
   },
   {
    "duration": 47731,
    "start_time": "2022-06-23T12:50:33.213Z"
   },
   {
    "duration": 202,
    "start_time": "2022-06-23T12:51:20.945Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.148Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.150Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.151Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.152Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.153Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.154Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.155Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.155Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.156Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.157Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.158Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.159Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.160Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.161Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.162Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.163Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.165Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.166Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.167Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.168Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.169Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.170Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.172Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.172Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.174Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.175Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.176Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-23T12:51:21.224Z"
   }
  ],
  "colab": {
   "collapsed_sections": [],
   "name": "text_comments.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
